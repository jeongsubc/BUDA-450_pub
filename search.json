[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Business Data Mining and Visualization",
    "section": "",
    "text": "Welcome!\nThis website is for the lecture notes of { BUDA-450 Business Data Mining and Visualization }, and it will be updated with the development of the course.\nThe materials aim to introduce to Data Mining and Visualization with Python Programming basics. The content of the course will be given with the following software and brief introductions.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#conventions",
    "href": "index.html#conventions",
    "title": "Business Data Mining and Visualization",
    "section": "Conventions",
    "text": "Conventions\nThe lecture notes are compiled using Quarto.\n\nItalic, Bold, and ItalicBold texts are used to highlight concepts or items being discussed.\ntypewriter font is used for function, inline code, and file names, pertaining to software use.\nThe following code blocks are used to show codes (and results) in Python:\n\n\na = 2\nb = 5\nprint(\"a plus b is equal to\", a+b)\n\na plus b is equal to 7\n\n\n\nSome blocks will show the code (without the result for exercise) when you click:\n\n\n\nShow the code for 3 to the 4th\nc = 3\nd = 4\nprint(\"3 to the 4th is equal to\", c ** d)\n\n\n\nThe following blocks are used to draw extra attention based on the five types below:\n\n\n\n\n\n\n\n\n\nNoteNote\n\n\n\nFor additional or extra topics.\n\n\n\n\n\n\n\n\n\n\nWarningWarning\n\n\n\nFor practical issues or warnings.\n\n\n\n\n\n\n\n\n\n\nImportantImportant\n\n\n\nFor key information and takeaways.\n\n\n\n\n\n\n\n\n\n\nTipTip\n\n\n\nFor useful or extra techniques.\n\n\n\n\n\n\n\n\n\n\nCautionExercise\n\n\n\nFor practice or exercise problems.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Business Data Mining and Visualization",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThe main references of this book are:\n\nData Analysis and Visualization in Python for Ecologists developed by The Carpentries\nIntroduction to R & Data developed by Research Data Management Support at Utrecht University.\n\nThese materials were developed for the IMT/LIS 511: Introduction to Programming for Data Science and Visualization courses taught at the University of Washington Information School; (The “INFX” in the URL title was the original prefix for these courses). However, this book has been structured to be an online resource for anyone who wishes to learn programming. Some chapters of this book have been developed in conjunction with Technical Foundations of Informatics, by Freeman and Ross.\n\n\nsite\n\ntarget format/structure of book: https://www.albany.edu/spatial/GIS4SS/lecture/",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction to Course",
    "section": "",
    "text": "1.1 Overview\nThe materials in this website are for more than one course. The following list is the recommended path for each course.\nWe begin our journey into data mining with a brief introduction—what it is, why it matters, and how it’s applied in practice. Throughout this course, we’ll learn both the theory and the practical tools to uncover patterns and insights from data. My goal is to help you build both conceptual understanding and hands-on skills that you can use in real business and analytical contexts.\nHere’s our roadmap for this introduction:\nThink of this as a high-level overview of the field before we dive into deeper technical details in later classes.”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Course</span>"
    ]
  },
  {
    "objectID": "intro.html#overview",
    "href": "intro.html#overview",
    "title": "1  Introduction to Course",
    "section": "",
    "text": "First, we’ll define what data mining is.\nThen, we’ll explore why it is used and where it’s most impactful.\nWe’ll talk about situations and industries where data mining becomes essential.\nNext, we’ll discuss how it is used—the processes and methodologies involved.\nFinally, we’ll look at who actually uses data mining.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Course</span>"
    ]
  },
  {
    "objectID": "intro.html#what-is-data-mining",
    "href": "intro.html#what-is-data-mining",
    "title": "1  Introduction to Course",
    "section": "1.2 What is Data Mining?",
    "text": "1.2 What is Data Mining?\n\n1.2.1 Fuels for the Information Age\nTo understand data mining, let’s first start by answering the question What exactly is data mining? There is a famous analogy from “Clive Humby, a British mathematician and entrepreneur, that said, ‘Data is the new oil.’ This analogy helps us understand why data mining is such a crucial process in the modern information age.\nWhat does that mean? Just like crude oil, raw data on its own isn’t very useful. Crude oil has to be refined into products like gasoline, plastic, or jet fuel to be valuable. Similarly, data has to be refined—through cleaning, processing, and analysis—before it generates value.\nThe Information Age has been built on this process. In the past, major waves of development were driven by steam, electricity, and oil. Now, computers, networks, and data form the foundation of progress. Think about it: every time you use Google Maps, watch Netflix, or buy something on Amazon, you’re experiencing data as fuel. Those companies don’t just store data—they refine it into insights: recommending the next show, predicting traffic, or suggesting products.\n\n\n1.2.2 Data Mining in Simple Terms\nAt its simplest, data mining means turning raw data into value. You can think of it as a process of discovering hidden patterns and relationships from data. In the process,\n\nData is the raw material. Think of sales receipts, website clicks, or medical records.\nMining is the process—digging into that data to find useful patterns. Just like miners dig into rock to find gold, we dig into data to find knowledge.\nValue is the outcome, as insights that help us make a difference such as better decisions, efficiency improvement, or predictions.\n\nHere’s a business example: imagine a supermarket chain. They have massive amounts of checkout data. By itself, it’s just numbers. But when mined, it might reveal that customers who buy diapers also buy beer. That insight has value—it can influence store layout or promotions.\nSo whenever you hear the term data mining, think: data goes in, and actionable value comes out. In short: data in, value out.\n\n\n\n\n\n\nNote\n\n\n\nThink of a situation: You’ve got tons of information, but it’s just sitting there. What’s one example where mining that information could turn it into value?\n\n\n\n\n1.2.3 Definition of Data Mining\nData mining is the knowledge discovery from data. It’s the process of extracting interesting patterns or knowledge from huge datasets.\nLet’s highlight a few key parts of that definition: - Interesting means non-trivial—it’s not something obvious. - It should be previously unknown. If everyone already knows it, it’s not knowledge discovery. - And it should be useful—either for making predictions, guiding strategy, or saving resources.\nData mining goes by other names too: knowledge discovery in databases (KDD), knowledge extraction, business intelligence, information harvesting. Besides, there are many but similar and related definitions of data mining, like data analysis and data dredging.\nBut, here, the important distinction is this: data mining is not about finding any pattern—it’s about finding meaningful and valid patterns.\n\n\n\n\n\n\nNote\n\n\n\nIf you notice that every morning the sun rises in the east, does that count as data mining? Why or why not? (Hint: it’s not new or unknown!)\n\n\n\n\n1.2.4 Foundations of Data Mining\nWe just started studying Data mining in this course, but data mining is not a brand-new discipline—it borrows from several established fields. Here are three major fields.\n\nDatabase systems and computing: Without advances in storing and managing large amounts of data, mining would not be possible. Think about SQL databases or distributed systems like Hadoop.\nStatistics: This provides the foundation for measurement, inference, and testing. For example, probability theory underlies many mining methods.\nArtificial Intelligence (AI) and Machine Learning (ML): These give us algorithms that learn patterns from data, like decision trees, clustering, and neural networks.\n\nNow, we may have one following question: why do we need something beyond traditional statistics or databases? Because modern data has new challenges:\n\nIt’s complex—your task may involve not only well-structured tabular format but also, text, video, images, not just numbers. The traditional methods often are not suitable for data mining tasks with such complex data.\nSimilarly, modern data are often heterogeneous—as it may consist of different formats and sources.\nIn addition, data for your tasks may be at a large-scale with millions or billions of records, and high-dimensional with thousands of variables.\nFurthermore, data can be distributed as stored across many servers and locations.\n\nTraditional techniques simply weren’t built to handle this. Data mining techniques evolved to tackle exactly these challenges.\n\n\n\n\n\n\nNote\n\n\n\nCan you think of one dataset you’ve encountered—maybe in your work, studies, or even social media—that seems too big or too complex to handle with just Excel or basic statistics?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Course</span>"
    ]
  },
  {
    "objectID": "intro.html#why-is-data-mining-used",
    "href": "intro.html#why-is-data-mining-used",
    "title": "1  Introduction to Course",
    "section": "1.3 Why is data mining used?",
    "text": "1.3 Why is data mining used?\n\n1.3.1 Data and its Explosive Growth\nHere’s the big driver behind why data mining matters: the sheer explosion of data. Data is everywhere, and it keeps growing faster than we can imagine. This growth is driven by advances in:\n\nData generation – Every second, people are generating posts, clicks, videos, GPS pings, and transactions.\nData collection – Sensors, apps, and platforms record nearly everything.\nData storage – Cloud computing now makes it cheap to keep almost unlimited amounts of data.\n\nWe’ve moved from terabytes (10¹² bytes) to petabytes, exabytes, and now zettabytes (10¹⁸ bytes). To give you perspective, one zettabyte is a billion terabytes.\nThe sources of this data are diverse:\n\nBusiness: Online purchases, stock trades, loyalty cards.\nSociety: Social media posts, news feeds, YouTube uploads.\nScience: Remote sensing data from satellites, DNA sequencing, simulation models.\n\nLike these, nowadays, we can collect data nearly everywhere. Here, the reality is–—we’re in an era where we generate more data than we can manually process. That’s why data mining isn’t optional anymore; it’s necessary to make sense of the flood of information.\nExample: Domo’s annual Data Never Sleeps report shows that in just one minute, millions of emails are sent, hundreds of thousands of dollars are spent on e-commerce, and hours of video are uploaded to YouTube. This highlights the nonstop pace of data growth.\n\n\n\n\n\n\nNote\n\n\n\n‘Think about your own life for a moment—your phone, your social media, your browsing history. How much data do you think you generate in a single day? Is most of it being used, or just stored?’”\n\n\n\n\n1.3.2 Value from Data and Data Mining\nNow, here’s the critical point: while data is everywhere, value is not. Collecting data doesn’t guarantee it will be useful to create value. Keep in mind that our goal of data mining here is not to create data, but to create value. To achieve it, we can consider two main ways:\n\nFor its intended purpose.\n\nExample: a hospital records patient vital signs so doctors can monitor health.\n\nFor a new, unanticipated purpose.\n\nExample: analyzing purchase data not just for receipts, but to build customer recommendation systems.\n\n\nData mining is the bridge that transforms massive raw data into valuable insights. Then, what makes this possible today?\n\nFirst, we have now cheaper and more powerful computing. Cloud platforms and GPUs let us crunch massive datasets quickly.\nAt the same time, there are competitive pressure. Companies must use their data to stay ahead—think of how Netflix, Amazon, or Spotify personalize services to keep customers engaged.\n\nReal-world example: Netflix doesn’t just track what you watch; it tracks when you pause, when you stop, how often you binge, and even the time of day you watch. By do data mining, that raw data becomes insights that guide personalized recommendations and even influence what original shows they invest in. So the real message here is: without mining, data is just overhead. However, with data mining, it can become a strategic asset.\n\n\n\n\n\n\nNote\n\n\n\nHere’s a question: Can you think of an example where you know a company is using your data to give you personalized value—like a recommendation, an offer, or an alert? Did it feel helpful or a little creepy?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Course</span>"
    ]
  },
  {
    "objectID": "intro.html#whenwhere-is-data-mining-needed",
    "href": "intro.html#whenwhere-is-data-mining-needed",
    "title": "1  Introduction to Course",
    "section": "1.4 When/where is data mining needed?",
    "text": "1.4 When/where is data mining needed?\n\n1.4.1 Process for DM\nData mining isn’t just one single action—it’s part of a larger process that requires careful planning and execution. At its core, data mining means examining large datasets to identify patterns and then using those patterns to generate valuable business insights. But if we just jump into modeling without structure, we risk wasting time or drawing wrong conclusions.\nThat’s why a systematic approach is critical. In industry, there are established standards with clearly defined steps, the two most popular being: - CRISP-DM (Cross-Industry Standard Process for Data Mining) - KDD (Knowledge Discovery in Databases) process\nBoth provide a roadmap, ensuring that projects move from messy raw data to actionable insights in a repeatable and reliable way.\nAlso, remember that data mining is part of a broader data analytics ecosystem that includes machine learning, statistical analysis, and business intelligence tools.\n\n\n\n\n\n\nNote\n\n\n\nImagine you’re hired by a company that wants to reduce customer churn. What could go wrong if you just start building a model without following a systematic process?\n\n\n\n\n1.4.2 Cross-Industry Standard Process for Data Mining (CRISP-DM)\nCRISP-DM is one of the most widely used frameworks for data mining. It consists of six iterative steps:\n\nBusiness understanding – First, we define the context and objectives. What problem are we solving? For example: predicting loan defaults.\nData understanding – Collect raw data and perform preliminary analysis. What data do we have? What’s missing? What hypotheses are emerging?\nData preparation – Clean, transform, and preprocess data. This includes removing errors, handling missing values, and selecting useful variables.\nModeling – Apply appropriate data mining techniques, like classification, clustering, or regression.\nEvaluation – Assess the models. Are the results valid? Do they answer the business question? If not, we loop back.\nDeployment – Translate results into actionable insights or strategies. For example: build a dashboard, send alerts, or automate decision rules.\n\nIt’s important to note that CRISP-DM is not linear. Analysts often move back and forth between stages as new discoveries are made.\n\n\n\n\n\n\nNote\n\n\n\n‘Looking at these six steps, which do you think might take the most time in a real project: modeling or data preparation?’ (Hint: in practice, data preparation usually eats up the majority of time!)”\n\n\n\n\n1.4.3 Knowledge Discovery (KDD) Process\nThe KDD process is another structured framework, often discussed in academic and research communities, especially those focused on databases and data warehousing. The KDD steps look very similar to CRISP-DM but are framed slightly differently: - Data selection – From large databases, choose relevant subsets. - Preprocessing – Clean and prepare the data. - Transformation – Reduce dimensions, select features, normalize variables. - Data mining – Apply algorithms to extract patterns. - Interpretation and evaluation – Translate patterns into useful knowledge.\nSo while CRISP-DM is popular in business practice, KDD is the more theoretical backbone you would often see in academic papers.\n\n\n\n\n\n\nNote\n\n\n\nWhy do you think industry and academia developed slightly different process models for the same overall idea?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Course</span>"
    ]
  },
  {
    "objectID": "intro.html#how-can-data-mining-be-used",
    "href": "intro.html#how-can-data-mining-be-used",
    "title": "1  Introduction to Course",
    "section": "1.5 How can data mining be used?",
    "text": "1.5 How can data mining be used?\nLet’s look at the typical tasks of data mining.\nHere’s a sample dataset—things like refund status, marital status, income, and whether someone cheats on taxes. From a dataset like this, what kinds of tasks might we perform?\n\nPredictive modeling: Can we predict whether someone is likely to cheat, given their attributes?\nClustering: Can we group taxpayers into categories—like high risk, medium risk, low risk—without labels?\nAnomaly detection: Can we find cases that look suspiciously different from the rest?\nAssociation rules: Can we uncover relationships—for example, divorced individuals with high income are more or less likely to cheat?\n\nEach of these tasks aligns with a type of real-world decision problem.\n\n\n\n\n\n\nNote\n\n\n\n‘Looking at this small tax dataset, what question would you want to ask first? Prediction, clustering, or anomaly detection?’”\n\n\n\n1.5.1 Predictive Modeling\n“redictive modeling is one of the most powerful applications of data mining. The idea is simple: we use training data—examples where the outcomes are known—to build a model that captures the relationship between inputs (features) and outputs (labels). Then, we apply that model to new, unseen data to predict outcomes.\nThis applies across many domains: - In finance: predicting loan defaults. - In marketing: predicting customer churn. - In healthcare: predicting disease risk.\nWe’ll focus on two main branches:\n\nClassification – when outcomes are categorical.\nRegression – when outcomes are numerical.\n\n\n\n\n\n\n\nNote\n\n\n\nCan you think of a business scenario where we would want to predict a number, and another where we’d want to predict a category?\n\n\n\n1.5.1.1 Predictive Modeling: Classification\nClassification is about predicting non-numerical categorical labels.\nExample: Think about a bank monitoring transactions. Classification models flag suspicious transactions as ‘fraud’ or ‘not fraud.’\nThere are many methods: decision trees, naïve Bayes, support vector machines, neural networks, logistic regression, and rule-based approaches.\n\n\n\n\n\n\nNote\n\n\n\n‘How many of you have had a credit card transaction declined because the bank thought it was suspicious? That’s classification in action—sometimes right, sometimes wrong!’”\n\n\n\n\n1.5.1.2 Predictive Modeling: Regression\nRegression is similar to classification, but here the outcome is numerical. We use regression when we want to predict values like:\n\nFuture sales for a product.\nThe price of a house.\nThe index of a stock market.\n\nExample: A real estate company might use regression to predict house prices based on features like square footage, neighborhood, and number of bedrooms.\nMethods include multiple linear regression, Poisson regression, kernel regression, and support vector regression.\n\n\n\n\n\n\nNote\n\n\n\n‘If Amazon wants to predict how many units of a new product will sell next month, is that classification or regression?’”\n\n\n\n\n\n1.5.2 Clustering\nClustering is about grouping data points into clusters without prior labels. Unlike predictive models where labels are predefined and given for training, clustering discovers categories automatically. Applications include:\n\nMarket segmentation: Grouping customers by behavior or preferences.\nDocument clustering: Grouping related news articles.\nStock market analysis: Grouping stocks with similar trends.\nSummarization: Reducing large datasets into manageable categories.\n\nMethods include k-means, hierarchical clustering, and density-based clustering.\nExample: A retailer could use clustering to identify customer segments—like bargain hunters, premium buyers, or occasional shoppers—without knowing those groups beforehand.\n\n\n\n\n\n\nNote\n\n\n\nThink about Spotify or Apple Music. How do you think clustering helps them group songs or users?\n\n\n\n\n1.5.3 Anomaly Detection\nAnomaly detection is about identifying outliers—cases that deviate significantly from normal patterns. This is incredibly important in practice: - Fraud detection: spotting unusual credit card transactions. - Cybersecurity: detecting intrusions or abnormal network activity. - Healthcare: identifying abnormal patient vitals that signal a problem.\nMethods include statistical tests, clustering-based detection (points far from any cluster), and machine learning methods like one-class support vector machines and neural networks.\nExample: If a customer normally spends $50–$100 per purchase, but suddenly makes a $10,000 purchase in another country, that’s flagged as an anomaly.\n\n\n\n\n\n\nNote\n\n\n\n‘If your Netflix account suddenly started watching cartoons all night long—would that be an anomaly worth investigating?’”\n\n\n\n\n1.5.4 Association Rule Analysis\nAssociation rule analysis is about discovering dependencies between items.\nThe classic example is market-basket analysis: - Rule: {Diapers, Milk} → {Beer}. - This means customers who buy diapers and milk are likely to also buy beer.\nMethods include Apriori algorithm and pattern discovery approaches. Applications extend beyond retail: Telecom: Diagnosing alarms based on combinations of error codes.; Healthcare: Identifying co-occurrence of symptoms or treatments.; E-commerce: Powering recommendation engines (‘People who bought this also bought…’).\nExample: On Amazon, when you see ‘Frequently Bought Together,’ that’s association rule mining in action.\n\n\n\n\n\n\nNote\n\n\n\n‘Think about your own online shopping. Has an item ever been recommended to you that felt spot-on? That’s association rules at work.’”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Course</span>"
    ]
  },
  {
    "objectID": "intro.html#users-of-dm",
    "href": "intro.html#users-of-dm",
    "title": "1  Introduction to Course",
    "section": "1.6 Users of DM?",
    "text": "1.6 Users of DM?\nWe have one last question to ask: who actually uses data mining? The short answer is: almost everyone. For example,\n\nAnalysts in various fields: Business analysts, data analysts, and market researchers use mining to guide decisions.\nScientists and engineers: They apply it in areas like bioinformatics, astronomy, materials science, and engineering simulations.\nBusinesses: Companies mine customer data to personalize services, detect fraud, and optimize operations.\nGovernments: For public policy, fraud detection, and even security monitoring.\nComputers and AI systems: Increasingly, automated pipelines powered by machine learning algorithms mine data in real time—think recommendation systems or self-driving cars.\n\nIn practice, much of this happens behind the scenes, through automation. For example, Google’s search engine mines billions of webpages continuously, and Netflix constantly mines viewing data to refine recommendations.\nAnd let’s not forget—you! As students in this class, you’re training to become the next generation of professionals who will design, interpret, and apply these data mining techniques.\n\n\n\n\n\n\nNote\n\n\n\n‘Quick brainstorm: Can you name one profession or industry that you think will rely even more on data mining in the next 5–10 years?’”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to Course</span>"
    ]
  },
  {
    "objectID": "BP/BP-Front.html",
    "href": "BP/BP-Front.html",
    "title": "Basics with Python Programming",
    "section": "",
    "text": "Overview\nThis chapter introduces Python basics:",
    "crumbs": [
      "Basics with Python Programming"
    ]
  },
  {
    "objectID": "BP/BP-Front.html#overview",
    "href": "BP/BP-Front.html#overview",
    "title": "Basics with Python Programming",
    "section": "",
    "text": "Installation\n\nAnaconda\nPython\nJupiter Notebook\n\nCoding\nPython Basics 1\n\nBasic concepts and syntax\nData in Python",
    "crumbs": [
      "Basics with Python Programming"
    ]
  },
  {
    "objectID": "BP/BP-Front.html#related-reading",
    "href": "BP/BP-Front.html#related-reading",
    "title": "Basics with Python Programming",
    "section": "Related Reading",
    "text": "Related Reading\nThis chapter has benefited from the excellent Python Programming for Data Science book by Tomas Beuzen.\n\nChapters in the course textbook\n\nchapter 2 of Business Analytics - Communicating with numbers\n\nWebsites for R textbook\n\nSection 3.3, 3.4, 3.5 of An Introduction to R\nSections 7 of Beginning Computer Science with R",
    "crumbs": [
      "Basics with Python Programming"
    ]
  },
  {
    "objectID": "BP/BP-Install.html",
    "href": "BP/BP-Install.html",
    "title": "2  Installation",
    "section": "",
    "text": "2.1 Overview\nThis section provides you with a basic idea about this course’s main tool, Python, and a brief instruction of setting up the computational environment (e.g., Python version, libraries, etc.).",
    "crumbs": [
      "Basics in Python Programming",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "BP/BP-Install.html#preliminaries",
    "href": "BP/BP-Install.html#preliminaries",
    "title": "2  Installation",
    "section": "2.2 Preliminaries",
    "text": "2.2 Preliminaries\n\n2.2.1 Why Python?\nIn business analytics, learning a programming language is extremely valuable (often essential) since many tasks are more efficiently done with computer and code. Once you become familiar with a programming language and its core concepts (like variables, loops, data structures), learning other languages often becomes easier, though each has its own syntax and paradigm-specific features.\nOnce you become familiar with a language, learning other languages (including ones, like R or C++, specialized to specific tasks) becomes much easier, where most of the programming concepts similarly apply across most languages.\n\n\n\nZDNet’s programming language popularity index as of 2024 (Image source link).\n\n\nHere, Python is one of the most popular programming languages nowadays.\nIt’s one of the easiest to learn. Its simplicity and readability make it a common first language for students, while its deep ecosystem of libraries makes it suitable for advanced tasks.\nAlso, Python is a general-purpose language, meaning it’s highly versatile as it can handle tasks ranging from basic calculations to advanced machine learning (e.g., large language models in ChatGPT) in diverse domains, including data science, web development, automation, engineering, etc., and accordingly across the industry, academia, and the public sector.\nThis combination is why people often say Python has a “low floor and high ceiling.”\nBesides, Python also shines in cloud computing environments, thanks to strong support from cloud providers and its rich ecosystem of open-source packages.\nIn summary, Python is an outstanding language for analytics, data science, and various applications in business. It’s no surprise that it consistently ranks among the most popular programming languages in the world!\n\n\n2.2.2 Related Concepts\nBefore diving into coding, it’s important to understand a computational environment as the setup that allows you to write and run Python code. In this section, let’s briefly understand the key elements of a computational environment for coding.\nA computational environment typically includes elements that together define where and how your code will run:\n\nThe operating system you’re working on (e.g., macOS Catalina)\nThe version of the programming language (e.g., Python 3.11)\nInstalled packages or libraries (e.g., pandas 2.1.0)\n\nTo set up a working Python environment, you’ll need:\n\nA computer with an operating system (e.g., Windows, macOS, Linux, or a cloud-based platform)\nAn installation of Python, the programming language that enables the computer to interpret and execute the code\nVarious packages that extend Python’s capabilities for various tasks\nAnd, an Integrated Development Environment (IDE) that is a tool to write and execute code (in a convient way)\n\nLet’s walk through each of these in more detail.\n\n2.2.2.1 Operating System\nAn operating system (OS) is the core software that manages everything on your computer. It acts like a middleman between your hardware (like CPU, memory, keyboard, etc.) and the applications you use (like a web browser or software). In the context of a Python environment, the OS is the foundation that everything else runs on. It affects how Python is installed, how packages behave, and even how your code interacts with files, memory, and other system resources. To be specific, the OS does the following for Python:\n\nRuns the Python interpreter: The OS loads and executes the Python program when you run a script.\nHandles file paths and directories: Python uses OS-specific paths (e.g., C:\\folder\\file.txt on Windows and /home/user/file.txt on Linux).\nManages packages and dependencies: Some Python packages have OS-specific versions or behaviors.\nSupports external tools: Tools like compilers or system libraries that Python may depend on are managed by the OS.\n\n\n\n\n2.2.2.2 Python interpreter\nA Python interpreter is the program that reads and runs your Python code.\nWhen you write code in Python—like print(\"Hello\"), you’re writing instructions in a human-readable way. But your computer doesn’t understand Python directly. That’s where the interpreter comes in.\nhttps://www.geeksforgeeks.org/python/internal-working-of-python/\nYou write a Python code, and run it. Then, a Python interpreter processes and runs the instructions in your code. To execute Python code, a computer needs , which\nPython is both a programming language that humans can read, and a language that computers can read, interpret, and then carry out instructions based on. For a computer to be able to read and execute Python code, it needs to have a Python interpreter installed. There are lots of ways to install a Python “interpreter” on your own computer, this book recommends the uv distribution of Python for its flexibility, simplicity, and features. Cloud services often come with a Python interpreter installed, and we’ll see shortly how to install one on your own computer.\nIn the box below, you can see which version of Python was used to compile this book:\n\nimport sys\nprint(\"Compiled with Python version:\", sys.version)\n\nCompiled with Python version: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]\n\n\nThink of it like a translator:\n\nYou (the programmer) write instructions in Python.\nThe interpreter translates those instructions into something the computer can understand and act on.\nThe computer then follows those instructions to do things—like print messages, do math, or analyze data.\nThere are different types of Python interpreters, like:\n\nCPython (the standard and most common one),\nPyPy (faster in some cases),\nor ones that run inside other environments (like Jupyter Notebooks or cloud platforms).\n\n\nWhen you install Python on your computer, you’re actually installing the interpreter along with tools to help you write and run Python programs. Without the interpreter, Python code is just text—the computer wouldn’t know what to do with it.\n\n\n2.2.2.3 Integrated Development Environment (IDE)\nAn integrated development environment (IDE) is a software application that helps you write, test, and debug your code more easily.\nThe most important of these is a way to write the code itself! IDEs are not the only way to programme, but they are perhaps the most useful.\nIf you have used Stata or Matlab, you may not have realised it, but these analytical tools bundle the interpreter and the IDE together. But they are separate things: the interpreter is a way of processing your instructions, the IDE is where you write those instructions.\nThere are a lot of integrated development environments (IDEs) out there, including PyCharm, IDLE, Visual Studio Code. In this course, Jupyter will be used as it works on all major operating systems and is one of the most popular.\nImagine you’re writing a story—an IDE is like a smart writing tool that not only lets you type but also checks your spelling, suggests words, helps you organize chapters, and even lets you publish the book when you’re done. For coding, an IDE does something similar.\nHere’s what an IDE typically includes:\n\nCode editor: where you type your code (like a fancy text editor).\nSyntax highlighting: colors and styles that make your code easier to read.\nAutocomplete: suggests code as you type, helping you write faster and with fewer errors.\nDebugger: lets you pause and inspect your code when something goes wrong.\nTerminal or console: to run your code and see results directly.\n\nSome popular Python IDEs are:\n\nJupyter Notebook: great for data analysis and visualization.\nPyCharm: powerful and feature-rich, good for large projects.\nVisual Studio Code: lightweight, customizable, and widely used.\nIDLE: a simple IDE that comes with Python by default.\n\nIn short, an IDE makes coding more convenient and productive by bringing all the tools you need into one place.\n\n\n2.2.2.4 Python Packages\nA Python package (also called library) is a collection of tools (typically for one-themed topic/goal) such as functions, classes, data, and documentation that help you do specific tasks more easily, without having to write everything from scratch, like a toolbox that has ready-made tools for specific jobs.\nYou may prepare a toolbox and take it out on your workbench when the tools are needed. Similarly, you will install a package and add the package to the setup in your code. By doing so, they give you useful tools that others have already written and tested, so you can focus on solving your problem instead of reinventing the wheel. Eventually, saving your time and effort, you can easily extend the capabilities of an installed basic Python on your computer.\nYou can use Python with extra packages for various tasks such as doing math, analyzing data, making graphs, building websites, or training machine learning models. For example, the math package has functions like math.sqrt() to calculate square roots; the pandas package helps you work with tables of data (like spreadsheets); the matplotlib package is used to make plots and charts; the scikit-learn package offers tools for machine learning.\n\n\n\n2.2.2.5 Typical workflow\nThe typical workflow for analysis with code might be something like this:\n\nOpen up your integrated development environment (IDE)\nWrite some code in a script (a text file with code in) in your IDE\nIf necessary for the analysis that you’re doing, install any extra packages\nUse the IDE to send bits of code from the script, or the entire script, to be executed by Python and add-on packages, and to display results\n(once the project is complete) ensure the script can be run from top to bottom to re-produce your analysis\n\nWe’ll see two ways to achieve this workflow:\n\nInstalling an IDE, a Python interpreter, and any extra Python packages on your own computer\nUsing a computer in the cloud that you access through your internet browser. Cloud computers often have an IDE and Python built-in, and you can easily install extra packages in them too. However, you should be aware that the cloud service we recommend has a 60 hours / month free tier. Beyond this you’ll need to pay for extra hours.\n\nYou should pick whichever you’re more comfortable with! Eventually, you’ll probably try both.",
    "crumbs": [
      "Basics in Python Programming",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "BP/BP-Install.html#setting-your-own-computer",
    "href": "BP/BP-Install.html#setting-your-own-computer",
    "title": "2  Installation",
    "section": "2.3 Setting Your Own Computer",
    "text": "2.3 Setting Your Own Computer\nThe following instruction is for a python environment on your own computer. The overall installation is as follow:\n\nInstall Anaconda/Conda as a platform for virtual environments\nInstall Python in a virtual environment\nInstall Jupyter Notebook as an IDE in the virtual environment\n\n\n2.3.1 Installing Anaconda (or Conda)\n\n2.3.1.1 Virtual Environment\nDifferent projects often require different environment setups. That’s when a virtual environment comes in handy, which helps to work on isolated Python environments where you can freely create/delete them (with no risk of messing up your entire computer).\nAlso, considering rapid version updates, an easy way to manage a python environment for the compatibility of python and many packages is building it on a virtual environment.\n\n\n\n\n\n\nWhy Use Conda to Install Python?\n\n\n\n\nInstalling Python through Conda (via Anaconda or Miniconda) is highly recommended for this course, especially for users working with data science and analytics tools.\nHere’s why:\n\nIsolated Environments: Conda allows you to create separate environments for different projects. Each environment can have its own version of Python and packages—preventing version conflicts.\nBetter Package Management: Unlike pip (Python’s default package manager), Conda can install not just Python packages but also system-level dependencies like C or Fortran libraries. This is especially helpful for scientific packages like numpy, scipy, and pytorch.\nCross-Platform Compatibility: Conda works consistently across Windows, macOS, and Linux. It is also used by most cloud data science environments, helping ensure reproducibility.\nFast Setup with Anaconda: The Anaconda distribution includes over 250 pre-installed data science packages (e.g., pandas, matplotlib, scikit-learn, jupyterlab), making it ideal for beginners and fast onboarding.\nScientific Computing Support: Many data science and machine learning tools depend on optimized compiled libraries. Conda handles these dependencies more reliably than pip.\nReproducible, portable environments that “just work,” especially in data science: Conda is the most robust choice.\n\n\n\nAnaconda is a popular software for that.\nhttps://www.anaconda.com/docs/getting-started/getting-started\nhttps://www.anaconda.com/docs/getting-started/anaconda/install\n\n\n\n2.3.2 Installing Python in Virtual Environment through Conda\nhttps://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html\nTo install Python, we’re going to use the command-line interface (CLI), because it’s simple to lightly handle environments, packages, and version control via the terminal.\nKnowing a little bit about it is really useful for coding (and more)\n\n\n\n\n\n\nThe Terminal in Brief\n\n\n\nThe command-line interface (also known as the command-line  and sometimes the command prompt) is a text-based interface that allows users to interact with the system (software) via command, each of which is formatted as a line of text, to your computer. In there, a command interpreter (also known as a command-line interpreter, command processor, or shell) is a program that implements a user’s commands via a CLI, acting like a bridge between the user and the operating system’s internal functions.\nMost OS’s (Linux, Mac, and Windows) have a built-in command-line program:\n\nthe PowerShell on Windows.\n\nSearch PowerShell and open it (without activating a conda environment which will be discussed below).\nOr, install PowerShell Prompt in Anaconda and run it in the virtual environment (activating it).\n\nthe Terminal on macOS\n\nSearch “Terminal” and open it\nTerminal User Guide\n\nthe Terminal on Linux\n\nSearch “Terminal” (the default Bash and open it\nThe Linux command line for beginners\nUsingTheTerminal - Ubuntu documantation\n\n\n\n\n\n\n2.3.2.1 Installing Python in Conda Environments\nfollowing command in the terminal, and hit y to proceed\nconda create --name env_buda450 python=3.11\nIn the command, you can replace env_buda450 with the name you want for the environment. By including programs/packages (and its versions) in the command, you can install them together when the environment is created (e.g., python version 3.11).\nCheck more details from Creating an environment with commands.\nThen, let’s activate the created environment env_buda450 by hitting in your terminal.\nconda activate env_buda450\nthen, install python. For a specific version of python (e.g., python 3.13),\nconda install python=3.13\n\n\n2.3.2.2 Installing Python Packages\nPython packages are typically not written by the core developers/maintainers of the Python language, but by anyone, enthusiasts, firms, researchers, academics, and you where anyone can make one, and so they don’t come built-in (by definition) in the Python. Therefore, you need to additionally install them and then import them into your scripts when you use them in a script.\nWithin the Python environment (e.g., after activating your conda environment), you can install a package by executing a commend in your computer terminal.\nFor example, let’s install the numpy package, which provides comprehensive numerical, mathematical operations as a basis of many advanced data science packages, by entering the following commend into the command line in your terminal.\nconda install numpy\nWhen you hit yes y (after the install command), it will automatically download the package (and its required dependent packages) from the internet and install in the appropriate place on your computer.\n\n\n\n\n\n\nNote\n\n\n\nIn this course, we will use conda to install packages because it’s relatively more generic and convenient for tasks dealing with environments and complex dependencies, compared with pip. See the explanation in link for more details.\n\n\nSimilarly, let’s install two other Python packages: pandas for data analysis and manipulation and matplotlib for creating static, animated, and interactive visualizations. To install them together, the packages can be listed with commas:\nconda install pandas, matplotlib\n\n\n\n\n\n\nWarning\n\n\n\nSometimes, the name of a package for installation may differ from its full name or for import.\nFor example, scikit-learn is a package for data mining and machine learning tasks. To install it, we use the name scikit-learn:\nconda install scikit-learn\nHowever, the package is called sklearn.\n\nimport sklearn\nprint(sklearn.__version__)\n\n1.6.1\n\n\nSo, it’s recommended to always check the exact instruction from the original website (e.g., pandas and matplotlib).\n\n\n\n\n\n2.3.3 Installing Jupyter Notebook\n\n2.3.3.1 Other IDEs\nVisual Studio Code is a free and open source IDE from Microsoft that is available on all major operating systems. Just like Python itself, Visual Studio can be extended with packages, and it is those packages, called extensions in this case, that make it so useful. As well as Python, Visual Studio Code supports a ton of other languages.\nThese instructions are for if you wish to code in the cloud rather than on your own computer. There are many ways to do data science in the cloud, but we’re going to share with you the absolute simplest.\nYou can run the code online through a few other options. The first is the easiest to get started with.\n\nGithub Codespaces. Github owned by Microsoft provides a range of services, including a way to back-up code on the cloud, and cloud computing. Github Codespaces is an online cloud computer that you connect to from your browser window. For this, you will need to sign up for a Github Account.\nGoogle Colab notebooks. Free for most use. You can launch most pages in this book interactively by using the ‘Colab’ button under the rocket symbol at the top of most pages in this book. It will be in the form of a notebook (which mixes code and text) rather than a script (.py file) but the code you write is the same. Note that Colab doesn’t use Visual Studio Code.",
    "crumbs": [
      "Basics in Python Programming",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "PB/PB-Front.html",
    "href": "PB/PB-Front.html",
    "title": "Basics with Python Programming",
    "section": "",
    "text": "This chapter introduces Python basics:\n\nGetting Started\n\nPython\nSetting Python Development Environment\n\nConcepts and Syntax\n\nExpression and Operators\nStatements and Variables\nIndentation\nComments\n\nData Types\n\nBuilt-in Data Types\nNumbers\nStrings\nBoolean Values\nLists\nDictionaries\n\nFunctions and Packages\n\nFunctions\nModules and Packages\n\n(Optional) Classes and Methods\n\nClasses\nMethods",
    "crumbs": [
      "Python Basics"
    ]
  },
  {
    "objectID": "PB/PB-Front.html#overview",
    "href": "PB/PB-Front.html#overview",
    "title": "Basics with Python Programming",
    "section": "",
    "text": "Getting Started\n\nPython\nSetting Python Development Environment\n\nConcepts and Syntax\n\nExpression and Operators\nStatements and Variables\nIndentation\nComments\n\nData Types\n\nBuilt-in Data Types\nNumbers\nStrings\nBoolean Values\nLists\nDictionaries",
    "crumbs": [
      "Basics with Python Programming"
    ]
  },
  {
    "objectID": "PB/PB-Front.html#related-reading",
    "href": "PB/PB-Front.html#related-reading",
    "title": "Basics with Python Programming",
    "section": "Related Reading",
    "text": "Related Reading\nThis chapter has benefited from the excellent Python Programming for Data Science book by Tomas Beuzen.\n\nChapters in the course textbook\n\nchapter 2 of Business Analytics - Communicating with numbers\n\nWebsites for R textbook\n\nSection 3.3, 3.4, 3.5 of An Introduction to R\nSections 7 of Beginning Computer Science with R",
    "crumbs": [
      "Basics with Python Programming"
    ]
  },
  {
    "objectID": "PB/PB-Install.html",
    "href": "PB/PB-Install.html",
    "title": "2  Getting Started",
    "section": "",
    "text": "2.1 Overview\nThis section provides you with a basic idea about this course’s main tool, Python, and a brief instruction of setting up the computational environment (e.g., Python version, libraries, etc.).",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PB/PB-Install.html#preliminaries",
    "href": "PB/PB-Install.html#preliminaries",
    "title": "2  Installation",
    "section": "2.2 Preliminaries",
    "text": "2.2 Preliminaries\n\n2.2.1 Why Python?\nIn business analytics, learning a programming language is extremely valuable (often essential) since many tasks are more efficiently done with computer and code. Once you become familiar with a programming language and its core concepts (like variables, loops, data structures), learning other languages often becomes easier, though each has its own syntax and paradigm-specific features.\nOnce you become familiar with a language, learning other languages (including ones, like R or C++, specialized to specific tasks) becomes much easier, where most of the programming concepts similarly apply across most languages.\n\n\n\nZDNet’s programming language popularity index as of 2024 (Image source link).\n\n\nHere, Python is one of the most popular programming languages nowadays.\nIt’s one of the easiest to learn. Its simplicity and readability make it a common first language for students, while its deep ecosystem of libraries makes it suitable for advanced tasks.\nAlso, Python is a general-purpose language, meaning it’s highly versatile as it can handle tasks ranging from basic calculations to advanced machine learning (e.g., large language models in ChatGPT) in diverse domains, including data science, web development, automation, engineering, etc., and accordingly across the industry, academia, and the public sector.\nThis combination is why people often say Python has a “low floor and high ceiling.”\nBesides, Python also shines in cloud computing environments, thanks to strong support from cloud providers and its rich ecosystem of open-source packages.\nIn summary, Python is an outstanding language for analytics, data science, and various applications in business. It’s no surprise that it consistently ranks among the most popular programming languages in the world!\n\n\n2.2.2 Related Concepts\nBefore diving into coding, it’s important to understand a computational environment as the setup that allows you to write and run Python code. In this section, let’s briefly understand the key elements of a computational environment for coding.\nA computational environment typically includes elements that together define where and how your code will run:\n\nThe operating system you’re working on (e.g., macOS)\nThe version of the programming language (e.g., Python 3.11)\nInstalled packages or libraries (e.g., pandas 2.1.0)\n\nTo set up a working Python environment, you’ll need:\n\nA computer with an operating system (e.g., Windows, macOS, Linux, or a cloud-based platform)\nAn installation of Python, the programming language that enables the computer to interpret and execute the code\nVarious packages that extend Python’s capabilities for various tasks\nAnd, an Integrated Development Environment (IDE) that is a tool to write and execute code (in a convient way)\n\nLet’s walk through each of these in more detail.\n\n2.2.2.1 Operating System\nAn operating system (OS) is the core software that manages everything on your computer. It acts like a middleman between your hardware (like CPU, memory, keyboard, etc.) and the applications you use (like a web browser or software). In the context of a Python environment, the OS is the foundation that everything else runs on. It affects how Python is installed, how packages behave, and even how your code interacts with files, memory, and other system resources. To be specific, the OS does the following for Python:\n\nRuns the Python interpreter: The OS loads and executes the Python program when you run a script.\nHandles file paths and directories: Python uses OS-specific paths (e.g., C:\\folder\\file.txt on Windows and /home/user/file.txt on Linux).\nManages packages and dependencies: Some Python packages have OS-specific versions or behaviors.\nSupports external tools: Tools like compilers or system libraries that Python may depend on are managed by the OS.\n\n\n\n\n2.2.2.2 Python interpreter\nA Python interpreter is the program that reads and runs your Python code.\nWhen you write code in Python—like print(\"Hello\"), you’re writing instructions in a human-readable way. But your computer doesn’t understand Python directly. That’s where the interpreter comes in.\nhttps://www.geeksforgeeks.org/python/internal-working-of-python/\nYou write a Python code, and run it. Then, a Python interpreter processes and runs the instructions in your code. To execute Python code, a computer needs , which\nPython is both a programming language that humans can read, and a language that computers can read, interpret, and then carry out instructions based on. For a computer to be able to read and execute Python code, it needs to have a Python interpreter installed. There are lots of ways to install a Python “interpreter” on your own computer, this book recommends the uv distribution of Python for its flexibility, simplicity, and features. Cloud services often come with a Python interpreter installed, and we’ll see shortly how to install one on your own computer.\nIn the box below, you can see which version of Python was used to compile this book:\n\nimport sys\nprint(\"Compiled with Python version:\", sys.version)\n\nCompiled with Python version: 3.11.13 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:03:15) [MSC v.1929 64 bit (AMD64)]\n\n\nThink of it like a translator:\n\nYou (the programmer) write instructions in Python.\nThe interpreter translates those instructions into something the computer can understand and act on.\nThe computer then follows those instructions to do things—like print messages, do math, or analyze data.\nThere are different types of Python interpreters, like:\n\nCPython (the standard and most common one),\nPyPy (faster in some cases),\nor ones that run inside other environments (like Jupyter Notebooks or cloud platforms).\n\n\nWhen you install Python on your computer, you’re actually installing the interpreter along with tools to help you write and run Python programs. Without the interpreter, Python code is just text—the computer wouldn’t know what to do with it.\n\n\n2.2.2.3 Integrated Development Environment (IDE)\nAn integrated development environment (IDE) is a software application that helps you write, test, and debug your code more easily.\nThe most important of these is a way to write the code itself! IDEs are not the only way to programme, but they are perhaps the most useful.\nIf you have used Stata or Matlab, you may not have realised it, but these analytical tools bundle the interpreter and the IDE together. But they are separate things: the interpreter is a way of processing your instructions, the IDE is where you write those instructions.\nThere are a lot of integrated development environments (IDEs) out there, including PyCharm, IDLE, Visual Studio Code. In this course, Jupyter will be used as it works on all major operating systems and is one of the most popular.\nImagine you’re writing a story—an IDE is like a smart writing tool that not only lets you type but also checks your spelling, suggests words, helps you organize chapters, and even lets you publish the book when you’re done. For coding, an IDE does something similar.\nHere’s what an IDE typically includes:\n\nCode editor: where you type your code (like a fancy text editor).\nSyntax highlighting: colors and styles that make your code easier to read.\nAutocomplete: suggests code as you type, helping you write faster and with fewer errors.\nDebugger: lets you pause and inspect your code when something goes wrong.\nTerminal or console: to run your code and see results directly.\n\nSome popular Python IDEs are:\n\nJupyter Notebook: great for data analysis and visualization.\nPyCharm: powerful and feature-rich, good for large projects.\nVisual Studio Code: lightweight, customizable, and widely used.\nIDLE: a simple IDE that comes with Python by default.\n\nIn short, an IDE makes coding more convenient and productive by bringing all the tools you need into one place.\n\n\n2.2.2.4 Python Packages\nA Python package (also called library) is a collection of tools (typically for one-themed topic/goal) such as functions, classes, data, and documentation that help you do specific tasks more easily, without having to write everything from scratch, like a toolbox that has ready-made tools for specific jobs.\nYou may prepare a toolbox and take it out on your workbench when the tools are needed. Similarly, you will install a package and add the package to the setup in your code. By doing so, they give you useful tools that others have already written and tested, so you can focus on solving your problem instead of reinventing the wheel. Eventually, saving your time and effort, you can easily extend the capabilities of an installed basic Python on your computer.\nYou can use Python with extra packages for various tasks such as doing math, analyzing data, making graphs, building websites, or training machine learning models. For example, the math package has functions like math.sqrt() to calculate square roots; the pandas package helps you work with tables of data (like spreadsheets); the matplotlib package is used to make plots and charts; the scikit-learn package offers tools for machine learning.\n\n\n\n2.2.2.5 Typical workflow\nThe typical workflow for analysis with code might be something like this:\n\nOpen up your integrated development environment (IDE)\nWrite some code in a script (a text file with code in) in your IDE\nIf necessary for the analysis that you’re doing, install any extra packages\nUse the IDE to send bits of code from the script, or the entire script, to be executed by Python and add-on packages, and to display results\n(once the project is complete) ensure the script can be run from top to bottom to re-produce your analysis\n\nWe’ll see two ways to achieve this workflow:\n\nInstalling an IDE, a Python interpreter, and any extra Python packages on your own computer\nUsing a computer in the cloud that you access through your internet browser. Cloud computers often have an IDE and Python built-in, and you can easily install extra packages in them too. However, you should be aware that the cloud service we recommend has a 60 hours / month free tier. Beyond this you’ll need to pay for extra hours.\n\nYou should pick whichever you’re more comfortable with! Eventually, you’ll probably try both.",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Installation</span>"
    ]
  },
  {
    "objectID": "PB/PB-Install.html#setting-your-own-computer",
    "href": "PB/PB-Install.html#setting-your-own-computer",
    "title": "2  Getting Started",
    "section": "2.3 Setting Your Own Computer",
    "text": "2.3 Setting Your Own Computer\nThe following instruction is for a python environment on your own computer. The overall installation is as follow:\n\nInstall Anaconda/Conda as a platform for virtual environments\nInstall Python in a virtual environment\nInstall Jupyter Notebook as an IDE in the virtual environment\n\n\n2.3.1 Installing Anaconda (or Conda)\n\n2.3.1.1 Virtual Environment\nDifferent projects often require different environment setups. That’s when a virtual environment comes in handy, which helps to work on isolated Python environments where you can freely create/delete them (with no risk of messing up your entire computer).\nAlso, considering rapid version updates, an easy way to manage a python environment for the compatibility of python and many packages is building it on a virtual environment.\n\n\n\n\n\n\nWhy Use Conda to Install Python?\n\n\n\nInstalling Python through Conda (via Anaconda or Miniconda) is highly recommended for this course, especially for users working with data science and analytics tools.\nHere’s why:\n\nIsolated Environments: Conda allows you to create separate environments for different projects. Each environment can have its own version of Python and packages—preventing version conflicts.\nBetter Package Management: Unlike pip (Python’s default package manager), Conda can install not just Python packages but also system-level dependencies like C or Fortran libraries. This is especially helpful for scientific packages like numpy, scipy, and pytorch.\nCross-Platform Compatibility: Conda works consistently across Windows, macOS, and Linux. It is also used by most cloud data science environments, helping ensure reproducibility.\nFast Setup with Anaconda: The Anaconda distribution includes over 250 pre-installed data science packages (e.g., pandas, matplotlib, scikit-learn, jupyterlab), making it ideal for beginners and fast onboarding.\nScientific Computing Support: Many data science and machine learning tools depend on optimized compiled libraries. Conda handles these dependencies more reliably than pip.\nReproducible, portable environments that “just work,” especially in data science: Conda is the most robust choice.\n\n\n\nAnaconda is a popular software for that.\nhttps://www.anaconda.com/docs/getting-started/getting-started\nhttps://www.anaconda.com/docs/getting-started/anaconda/install\n\n\n\n2.3.2 Installing Python in Virtual Environment through Conda\nhttps://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html\nTo install Python, we’re going to use the command-line interface (CLI), because it’s simple to lightly handle environments, packages, and version control via the terminal.\nKnowing a little bit about it is really useful for coding (and more)\n\n\n\n\n\n\nThe Terminal in Brief\n\n\n\nThe command-line interface (also known as the command-line  and sometimes the command prompt) is a text-based interface that allows users to interact with the system (software) via command, each of which is formatted as a line of text, to your computer. In there, a command interpreter (also known as a command-line interpreter, command processor, or shell) is a program that implements a user’s commands via a CLI, acting like a bridge between the user and the operating system’s internal functions.\nMost OS’s (Linux, Mac, and Windows) have a built-in command-line program:\n\nthe PowerShell on Windows.\n\nSearch PowerShell and open it (without activating a conda environment which will be discussed below).\nOr, install PowerShell Prompt in Anaconda and run it in the virtual environment (activating it).\n\nthe Terminal on macOS\n\nSearch “Terminal” and open it\nTerminal User Guide\n\nthe Terminal on Linux\n\nSearch “Terminal” (the default Bash and open it\nThe Linux command line for beginners\nUsingTheTerminal - Ubuntu documantation\n\n\n\n\n\n\n2.3.2.1 Installing Python in Conda Environments\nfollowing command in the terminal, and hit y to proceed\nconda create --name env_buda450 python=3.11\nIn the command, you can replace env_buda450 with the name you want for the environment. By including programs/packages (and its versions) in the command, you can install them together when the environment is created (e.g., python version 3.11).\nCheck more details from Creating an environment with commands.\nThen, let’s activate the created environment env_buda450 by hitting in your terminal.\nconda activate env_buda450\nthen, install python. For a specific version of python (e.g., python 3.13),\nconda install python=3.11\n\n\n2.3.2.2 Installing Python Packages\nPython packages are typically not written by the core developers/maintainers of the Python language, but by anyone, enthusiasts, firms, researchers, academics, and you where anyone can make one, and so they don’t come built-in (by definition) in the Python. Therefore, you need to additionally install them and then import them into your scripts when you use them in a script.\nWithin the Python environment (e.g., after activating your conda environment), you can install a package by executing a commend in your computer terminal.\nFor example, let’s install the numpy package, which provides comprehensive numerical, mathematical operations as a basis of many advanced data science packages, by entering the following commend into the command line in your terminal.\nconda install numpy\nWhen you hit yes y (after the install command), it will automatically download the package (and its required dependent packages) from the internet and install in the appropriate place on your computer.\n\n\n\n\n\n\nNote\n\n\n\nIn this course, we will use conda to install packages because it’s relatively more generic and convenient for tasks dealing with environments and complex dependencies, compared with pip. See the explanation in link for more details.\n\n\nSimilarly, let’s install two other Python packages: pandas for data analysis and manipulation and matplotlib for creating static, animated, and interactive visualizations. To install them together, the packages can be listed with commas:\nconda install pandas, matplotlib\n\n\n\n\n\n\nWarning\n\n\n\nSometimes, the name of a package for installation may differ from its full name or for import.\nFor example, scikit-learn is a package for data mining and machine learning tasks. To install it, we use the name scikit-learn:\nconda install scikit-learn\nHowever, the package is called sklearn.\n\nimport sklearn\nprint(sklearn.__version__)\n\n1.6.1\n\n\nSo, it’s recommended to always check the exact instruction from the original website (e.g., pandas and matplotlib).\n\n\n\n\n\n2.3.3 Installing JupyterLab (and Notebook)\n\n2.3.3.1 Other IDEs\nVisual Studio Code is a free and open source IDE from Microsoft that is available on all major operating systems. Just like Python itself, Visual Studio can be extended with packages, and it is those packages, called extensions in this case, that make it so useful. As well as Python, Visual Studio Code supports a ton of other languages.\nThese instructions are for if you wish to code in the cloud rather than on your own computer. There are many ways to do data science in the cloud, but we’re going to share with you the absolute simplest.\nYou can run the code online through a few other options. The first is the easiest to get started with.\n\nGithub Codespaces. Github owned by Microsoft provides a range of services, including a way to back-up code on the cloud, and cloud computing. Github Codespaces is an online cloud computer that you connect to from your browser window. For this, you will need to sign up for a Github Account.\nGoogle Colab notebooks. Free for most use. You can launch most pages in this book interactively by using the ‘Colab’ button under the rocket symbol at the top of most pages in this book. It will be in the form of a notebook (which mixes code and text) rather than a script (.py file) but the code you write is the same. Note that Colab doesn’t use Visual Studio Code.",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PB/PB-Install.html#running-codes",
    "href": "PB/PB-Install.html#running-codes",
    "title": "2  Getting Started",
    "section": "2.4 Running Codes",
    "text": "2.4 Running Codes\nThere are several ways of running Python code, depending on your environment, use case, and preferences. Below is a categorized list, grounded in factual, well-documented sources (Python official docs, Jupyter docs, etc.):\n\n2.4.1 Local Execution Methods\n\n2.4.1.1 Interactive Interpreter (REPL)\nRead–eval–print loop You can run Python interactively in a terminal or command prompt:\npython\nThis method allows you to type and execute code line by line.\n\nPros\n\nInstant feedback — good for learning and testing snippets.\nNo need to create files.\nLightweight and fast.\n\nCons\n\nNo code persistence (unless manually saved).\nNot ideal for large programs or projects.\n\n\n\n\n2.4.1.2 .py Script Execution in Terminal\nWrite Python code in a .py file and run it from the command line:\npython script_name.py\n\nPros\n\nStandard way to run Python programs.\nSupports larger, modular projects.\nEasily used in automation and pipelines.\n\nCons\n\nNo graphical feedback.\nErrors halt the script unless handled explicitly.\n\n\n\n\n2.4.1.3 Integrated Development Environments (IDEs)\nPopular IDEs for Python include VS Code, PyCharm, Spyder\nFeatures typically include debugging, linting, autocompletion, and project management.\n\nPros\n\nRich development features (debugging, autocomplete, version control).\nSyntax highlighting and linting support.\nSuitable for professional development and large projects.\n\nCons\n\nCan be resource-heavy.\nSteeper learning curve for beginners.\nRequires installation and setup.\n\n\n\n\n2.4.1.4 IDLE (Python’s Built-in GUI)\nIDLE comes with the standard Python installation and provides a basic GUI for editing and running code.\n\nPros\n\nSimple and beginner-friendly.\nComes pre-installed with Python.\nGUI interface for editing and execution.\n\nCons\n\nLacks advanced development features.\nNot ideal for large projects or modern workflows.\n\n\n\n\n2.4.1.5 Jupyter Notebooks\nRun Python code in cells with inline outputs:\njupyter notebook\nIdeal for data analysis and visualization.\n\nPros\n\nGreat for interactive data analysis and visualization.\nSupports markdown, LaTeX, and inline plots.\nCode can be executed in chunks (cells).\n\nCons\n\nNot suitable for production code or software packaging.\nHarder to version control due to JSON notebook format.\nLong-running notebooks can become difficult to manage.\n\n\n\n\n\n2.4.2 Online & Cloud-Based Execution\n\n2.4.2.1 Google Colab\nA browser-based Jupyter-like environment with free GPU access.\n\nPros\n\nFree access to GPUs and TPUs.\nCloud-based — no installation required.\nEasy sharing via Google Drive.\n\nCons\n\nRequires internet access.\nLimited control over environment and execution timeouts.\nPrivacy concerns with sensitive data.\n\n\n\n\n2.4.2.2 Replit\nFull-featured online IDE for Python and other languages.\n\nPros\n\nFull IDE in the browser.\nGreat for collaboration and quick testing.\nSupports multiple languages and real-time editing.\n\nCons\n\nRequires account login.\nLimited compute resources on free tier.\nLess customizable than local environments.\n\n\n\n\n2.4.2.3 Other Online Runners\nExamples: PythonAnywhere, Trinket\n\nPros\n\nVery easy setup.\nGood for teaching or demonstrating code.\nNo local configuration needed.\n\nCons\n\nLimited functionality and compute power.\nMay lack support for packages or files.\nOften ad-supported or limited on free plans.",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html",
    "href": "App/App_Markdown.html",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "",
    "text": "A.1 Keyboard shortcuts for cell types in Jupyter Notebook & Lab\nThis notebook is based on Markdown cheat sheet to provide a quick overview of the Markdown syntax elements. The elements introduced in this notebook are supported by many other Markdown applications. For more detailed, comprehensive information, refer to the reference guides from basic syntax and extended syntax or Tutorials.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#keyboard-shortcuts-for-cell-types-in-jupyter-notebook-lab",
    "href": "App/App_Markdown.html#keyboard-shortcuts-for-cell-types-in-jupyter-notebook-lab",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "",
    "text": "y Change to Code Cell Type\nm Change to Markdown Cell Type and\nr Change to Raw Cell Type",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#h2",
    "href": "App/App_Markdown.html#h2",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "C.1 H2",
    "text": "C.1 H2\n\nC.1.1 H3\n\nC.1.1.1 H4\n\nH5\n\nH6",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#emoji",
    "href": "App/App_Markdown.html#emoji",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "D.1 Emoji",
    "text": "D.1 Emoji\nSo funny! :joy: (See also Copying and Pasting Emoji)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#ordered-list",
    "href": "App/App_Markdown.html#ordered-list",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "E.1 Ordered List",
    "text": "E.1 Ordered List\n\nFirst item\nSecond item\nThird item",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#unordered-list",
    "href": "App/App_Markdown.html#unordered-list",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "E.2 Unordered List",
    "text": "E.2 Unordered List\n\nFirst item\nSecond item\nThird item",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#task-list",
    "href": "App/App_Markdown.html#task-list",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "E.3 Task List",
    "text": "E.3 Task List\n\nFirst item\nSecond item\nThird item",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#horizontal-rule",
    "href": "App/App_Markdown.html#horizontal-rule",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "H.1 Horizontal Rule",
    "text": "H.1 Horizontal Rule\nThe same horizontal line from different symbols:\n\nor\n\nor",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#link",
    "href": "App/App_Markdown.html#link",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "H.2 Link",
    "text": "H.2 Link\nNo space between the bracket and the paranthesis.\nMarkdown Guide",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#image",
    "href": "App/App_Markdown.html#image",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "H.3 Image",
    "text": "H.3 Image\nNo space between the exclamation mark and the bracket, and between the bracket and the paranthesis.\n\n\n\nalt text",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#table",
    "href": "App/App_Markdown.html#table",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "H.4 Table",
    "text": "H.4 Table\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#heading-1",
    "href": "App/App_Markdown.html#heading-1",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "I.1 Heading",
    "text": "I.1 Heading\n\nH1\n\n\nH2\n\n\nH3",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#emphasis-1",
    "href": "App/App_Markdown.html#emphasis-1",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "I.2 Emphasis",
    "text": "I.2 Emphasis\nItalic Bold Strikethrough Bold italic Mark",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#lists-1",
    "href": "App/App_Markdown.html#lists-1",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "I.3 Lists",
    "text": "I.3 Lists\nOrdered list\n\n\nItem 1\n\n\nItem 2\n\n\nItem 3\n\n\nUnordered list\n\n\nItem 1\n\n\nItem 2\n\n\nItem 3",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App_Markdown.html#code-1",
    "href": "App/App_Markdown.html#code-1",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "I.4 Code",
    "text": "I.4 Code\n Example of code",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "PB/PB-Install.html#python",
    "href": "PB/PB-Install.html#python",
    "title": "2  Getting Started",
    "section": "2.2 Python",
    "text": "2.2 Python\nIn business analytics, learning a programming language is valuable (often essential) since many tasks are more efficiently done with computer and code. Once you become familiar with a programming language and its core concepts (like variables, loops, data structures), learning other languages often becomes easier, though each has its own syntax and paradigm-specific features. Once you become familiar with a language, learning other languages (including ones, like R or C++, specialized to specific tasks) becomes much easier, where most of the programming concepts similarly apply across most languages.\n\n2.2.1 What is Python?\nPython is a high-level, interpreted programming language created in 1991 by Guido van Rossum.\n\nBeing high-level means it abstracts away many of the low-level details of computer operation, such as memory management, so that programmers can focus on problem-solving rather than machine instructions.\nIt is also an interpreted language, which means Python code does not need to be compiled before execution. Instead, the Python interpreter reads and executes the code line by line, making it highly flexible for testing and development.\nA key feature of Python is its emphasis on simplicity and readability. Its syntax is designed to resemble plain English, which makes programs easier to write, understand, and maintain. This characteristic has made Python a very accessible language for beginners, while still powerful enough for advanced applications.\nPython is also cross-platform. It runs consistently on Windows, macOS, and Linux, and it integrates well with other languages such as C, C++, and Java. This versatility has contributed significantly to its widespread adoption.\nFinally, Python is open-source and supported by a global community. Anyone can contribute to its development, expand its libraries, and share tools. As a result, Python has evolved into one of the most widely used and versatile programming languages today.\n\n\n\n2.2.2 Why Python?\nPython has become one of the most popular programming languages in the world, especially for data science, machine learning, and business analytics.\n\n\n\nZDNet’s programming language popularity index as of 2024 (Image source link).\n\n\nThe reasons include:\n\nPython has an extensive ecosystem of libraries and frameworks. These libraries are ready-made toolkits that extend Python’s core capabilities. For example, pandas allows efficient handling of tabular data, numpy provides fast numerical computations, matplotlib and seaborn enable data visualization, and scikit-learn supports machine learning. This broad set of tools makes Python highly adaptable to tasks in business analytics, data mining, and visualization.\nPython offers high productivity. Its simple and readable syntax allows users to express ideas in fewer lines of code compared to many other programming languages. This reduces development time and makes it easier to test and debug. The interpreted nature of Python also enables interactive development, where code can be tested incrementally without needing to compile full programs.\nPython benefits from a strong and active global community. Because it is open-source, the language is constantly improved and expanded. Documentation, tutorials, and Q&A forums are widely available, meaning that support is easily accessible. This strong community ensures that Python stays relevant and up to date with evolving technologies.\n\nIn summary, Python is popular because it combines power and flexibility with accessibility. These qualities make it an excellent language for exploring data, performing analysis, and creating clear, visual insights.\n\n\n2.2.3 Where to Use Python?\nPython is a general-purpose programming language, which means it can be applied across a wide variety of domains. Some common uses1 include:\n\nWeb development: Creating websites and web applications using frameworks such as Django and Flask.\nData analysis and visualization: Working with structured and unstructured data, cleaning it, analyzing patterns, and presenting results visually with libraries like pandas, matplotlib, and seaborn.\nMachine learning and artificial intelligence: Building predictive models, natural language processing systems, and intelligent applications with libraries such as scikit-learn, TensorFlow, or PyTorch.\nScientific computing: Performing simulations, optimization, and large-scale computations in research and engineering.\nAutomation and scripting: Writing scripts to automate repetitive tasks, system processes, or business workflows.\nDesktop and GUI applications: Developing standalone tools or user-friendly applications with interfaces.\n\n\n\n2.2.4 Online Materials for Python\nThere are many resources available online for learning and troubleshooting Python. - The Python Documentation is one of the great sources for the information, which includes explanations, examples, and reference material for every part of the language. - The Python Wiki provides curated information including Beginner’s Guide separately for non-programmers and those with prior programming experience. - Beyond that, platforms such as Stack Overflow, Real Python, Geeks for Geeks, and various tutorials offer practical examples and solutions.\n\n\n\n\n\n\nTutorials and beginner guides\n\n\n\nFrom the Python Software Foundation and Python Wiki.\n\nFor nonprogrammer\nFor programmer (know other programming languages)\n\n\n\n\n\n2.2.5 Python Versions\nPython exists in two major versions2 — Python 2 and Python 3.\n\nPython 2 was widely used for many years but reached its official end-of-life in January 2020. This means it no longer receives updates, bug fixes, or security patches. Some legacy codebases may still use Python 2, but it is no longer recommended for new development.\nPython 3 is the current and actively maintained version of the language. All modern libraries and tools are built for Python 3, and this is the version we will use throughout this course. Specifically, we will rely on Python 3.11, which is stable, well-supported, and compatible with the libraries we need for data mining and visualization.\n\n\n\n\n\n\n\nTip\n\n\n\nWhen you encounter tutorials or examples online, you may still see some written for Python 2. The syntax and behavior can differ in subtle but important ways, so always confirm that the code is written for the version you are using.\n\n\n\n\n2.2.6 Python Environment\nBefore diving into coding, it’s important to understand a Python (development) environment3 as the setup that allows you to write and run Python code. Often, you cannot even use Python without a proper development environment.\nThere are a number of ways to build development environments for python with various programs. At this time, let’s learn one way for building a properly configured environment to ensure that your code runs consistently, both on your machine and on others’.\nA Python environment typically includes core components that together define where and how your code will run:\n\nOperating system (OS) you’re working on (e.g., macOS) with a computer\nProgramming language (e.g., Python 3.11) that enables the computer to interpret and execute the code\nPackages that extend Python’s capabilities for various tasks\n\nTo set up a efficient Python environment, you can additionally consider:\n\nAn Integrated Development Environment (IDE) that is a tool to write and execute code (in a convenient way)\nVirtual environments that enables the development separately by project in isolated setups",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PB/PB-Install.html#footnotes",
    "href": "PB/PB-Install.html#footnotes",
    "title": "2  Getting Started",
    "section": "",
    "text": "https://www.python.org/about/apps/↩︎\nMany versions documented in Python Documentation by Version.↩︎\nA Python environment consists of all the tools and configurations that allow you to write, run, and manage Python programs efficiently.↩︎",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PB/PB-Install.html#setting-python-development-environment-local",
    "href": "PB/PB-Install.html#setting-python-development-environment-local",
    "title": "2  Getting Started",
    "section": "2.3 Setting Python Development Environment (Local)",
    "text": "2.3 Setting Python Development Environment (Local)\nThe following instruction is for a python environment on your own computer. The overall installation is as follow:\n\nInstall Anaconda/Conda as a platform for virtual environments\nInstall Python in a virtual environment\nInstall Jupyter Notebook as an IDE in the virtual environment\n\n\n2.3.1 Installing Anaconda (and Conda)\nDifferent projects often require different environment setups. That’s when a virtual environment comes in handy, which helps to work on isolated Python environments where you can freely create/delete them (with no risk of messing up your entire computer).\n\n2.3.1.1 Virtual Environment\nA virtual environment allows you to create a self-contained workspace where Python and all required libraries are stored separately from the system-wide installation.\nAnaconda/Conda is a popular software to manage virtual environments. To manage Python environments, we will use Anaconda/Conda.\n\nConda\n\nA package as the environment manager that creates isolated environments and installs packages (Python, R, C/Fortran libs, CUDA toolkits, etc.).\nWorks with any “distribution” (Anaconda, Miniconda, Miniforge).\n\nAnaconda\n\nA bundled distribution that includes conda, Python, Anaconda Navigator (GUI), and hundreds of prebuilt packages and Jupyter—all in one installer.\nBig install (~GBs), great for offline or “everything ready” setups.\n\n\n\n\n\n\n\n\nWhy Use Conda to Install Python?\n\n\n\nInstalling Python through Conda (via Anaconda or Miniconda—minimal version of Anaconda) is highly recommended for this course, especially for users working with data science and analytics tools.\nHere’s why:\n\nIsolated Environments: Conda allows you to create separate environments for different projects. Each environment can have its own version of Python and packages—preventing version conflicts.\nBetter Package Management: Unlike pip (Python’s default package manager), Conda can install not just Python packages but also system-level dependencies like C or Fortran libraries. This is especially helpful for scientific packages like numpy, scipy, and pytorch.\nCross-Platform Compatibility: Conda works consistently across Windows, macOS, and Linux. It is also used by most cloud data science environments, helping ensure reproducibility.\nFast Setup with Anaconda: The Anaconda distribution includes over 250 pre-installed data science packages (e.g., pandas, matplotlib, scikit-learn, jupyterlab), making it ideal for beginners and fast onboarding.\nScientific Computing Support: Many data science and machine learning tools depend on optimized compiled libraries. Conda handles these dependencies more reliably than pip.\nReproducible, portable environments that “just work,” especially in data science: Conda is the most robust choice.\n\n\n\n\n\n\n2.3.2 Installing Python in Virtual Environment through Conda\nTo install Python, we’re going to use the command-line interface (CLI), because it’s simple to lightly handle environments, packages, and version control via the terminal.\n\n\n\n\n\n\nThe Terminal in Brief\n\n\n\nThe command-line interface (also known as the command-line  and sometimes the command prompt) is a text-based interface that allows users to interact with the system (software) via command, each of which is formatted as a line of text, to your computer. In there, a command interpreter (also known as a command-line interpreter, command processor, or shell) is a program that implements a user’s commands via a CLI, acting like a bridge between the user and the operating system’s internal functions.\nMost OS’s (Linux, Mac, and Windows) have a built-in command-line program:\n\nthe PowerShell on Windows.\n\nSearch PowerShell and open it (without activating a conda environment which will be discussed below).\nOr, install PowerShell Prompt in Anaconda and run it in the virtual environment (activating it).\n\nthe Terminal on macOS\n\nSearch “Terminal” and open it\nTerminal User Guide\n\nthe Terminal on Linux\n\nSearch “Terminal” (the default Bash and open it\nThe Linux command line for beginners\nUsingTheTerminal - Ubuntu documantation\n\n\n\n\n\n\n2.3.2.1 Installing Anaconda\nInstalling Anaconda Distribution is the official website for the installation, in which the step-by-step procedure is documented well.\n\n\n2.3.2.2 Creating a Virtual Environment\nOnce you open the installed Anaconda on your computer, you start the Anaconda GUI on the base environment where your OS directly interact and that it is recommended not to use for projects. Instead of working on the base, let’s create a new one.\nTo do that, let’s open a terminal\n\nIn Windows, any prompt on the Anaconda GUI (e.g., Powershell Prompt, CMD.exe Prompt, or anaconda_prompt) — Not directly from Windows\nIn macOS/Linux, the OS’s terminal\n\nIn the terminal’s prompt, you should have (base) that indicates the current environment.\nA new environment with a name buda450_py311 can be created with the following command:\nconda create --name buda450_py311\nIn the command, you can replace buda450_py311 with the name you want for the environment. After completing the creation, the environment can be activated with the following command:\nconda activate buda450_py311\nCheck more details from Managing environments and about other Commands .\n\n\n2.3.2.3 Installing Python and Programs/Packages\nThen, Python can be installed through the following command.\nconda install python=3.11\nHere, Python’s version is specified (i.e., python 3.11). Without the version specification like conda install python, Python will be installed based on the conda’s default version.\n\n\n\n\n\n\nCreating an environment with python installation\n\n\n\nBy including programs/packages (and its versions) in the command, you can install them together when the environment is created.\nconda create --name buda450_py311 python=3.11\n\n\nSimilarly, some programs useful for Python can be installed in Conda environments.\nThe following command installs Jupyter’s Notebook and JupyterLab together.\nconda install notebook jupyterlab\n\n\n\n\n\n\nNote\n\n\n\nIn this course, we will use conda to install packages because it’s relatively more generic and convenient for tasks dealing with environments and complex dependencies, compared with pip. See the explanation in link for more details.\n\n\nSimilarly, you can install packages by executing a commend. For example, let’s install three pacakges\n\nnumpy for comprehensive numerical, mathematical operations as a basis of many advanced data science packages, by entering the following commend into the command line in your terminal.\npandas for data analysis and manipulation\nmatplotlib for creating static, animated, and interactive visualizations.\n\nconda install numpy pandas matplotlib\n\n\n\n\n\n\nWarning\n\n\n\nSometimes, the name of a package for installation may differ from its full name or for import.\nFor example, scikit-learn is a package for data mining and machine learning tasks. To install it, we use the name scikit-learn:\nconda install scikit-learn\nHowever, the package is called sklearn.\n\nimport sklearn\nprint(sklearn.__version__)\n\n1.6.1\n\n\nSo, it’s recommended to always check the exact commands from the original website (e.g., pandas) and repositories (e.g., anaconda’s Python Package Index (PyPi)).",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PB/PB-GetStarted.html",
    "href": "PB/PB-GetStarted.html",
    "title": "2  Getting Started",
    "section": "",
    "text": "2.1 Overview\nThis section provides you with a basic idea about this course’s main tool, Python, and a brief instruction of setting up the computational environment (e.g., Python version, libraries, etc.).",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PB/PB-GetStarted.html#python",
    "href": "PB/PB-GetStarted.html#python",
    "title": "2  Getting Started",
    "section": "2.2 Python",
    "text": "2.2 Python\nIn business analytics, learning a programming language is valuable (often essential) since many tasks are more efficiently done with computer and code. Once you become familiar with a programming language and its core concepts (like variables, loops, data structures), learning other languages often becomes easier, though each has its own syntax and paradigm-specific features. Once you become familiar with a language, learning other languages (including ones, like R or C++, specialized to specific tasks) becomes much easier, where most of the programming concepts similarly apply across most languages.\n\n2.2.1 What is Python?\nPython is a high-level, interpreted programming language created in 1991 by Guido van Rossum.\n\nBeing high-level means it abstracts away many of the low-level details of computer operation, such as memory management, so that programmers can focus on problem-solving rather than machine instructions.\nIt is also an interpreted language, which means Python code does not need to be compiled before execution. Instead, the Python interpreter reads and executes the code line by line, making it highly flexible for testing and development.\nA key feature of Python is its emphasis on simplicity and readability. Its syntax is designed to resemble plain English, which makes programs easier to write, understand, and maintain. This characteristic has made Python a very accessible language for beginners, while still powerful enough for advanced applications.\nPython is also cross-platform. It runs consistently on Windows, macOS, and Linux, and it integrates well with other languages such as C, C++, and Java. This versatility has contributed significantly to its widespread adoption.\nFinally, Python is open-source and supported by a global community. Anyone can contribute to its development, expand its libraries, and share tools. As a result, Python has evolved into one of the most widely used and versatile programming languages today.\n\n\n\n2.2.2 Why Python?\nPython has become one of the most popular programming languages in the world, especially for data science, machine learning, and business analytics.\n\n\n\nZDNet’s programming language popularity index as of 2024 (Image source link).\n\n\nThe reasons include:\n\nPython has an extensive ecosystem of libraries and frameworks. These libraries are ready-made toolkits that extend Python’s core capabilities. For example, pandas allows efficient handling of tabular data, numpy provides fast numerical computations, matplotlib and seaborn enable data visualization, and scikit-learn supports machine learning. This broad set of tools makes Python highly adaptable to tasks in business analytics, data mining, and visualization.\nPython offers high productivity. Its simple and readable syntax allows users to express ideas in fewer lines of code compared to many other programming languages. This reduces development time and makes it easier to test and debug. The interpreted nature of Python also enables interactive development, where code can be tested incrementally without needing to compile full programs.\nPython benefits from a strong and active global community. Because it is open-source, the language is constantly improved and expanded. Documentation, tutorials, and Q&A forums are widely available, meaning that support is easily accessible. This strong community ensures that Python stays relevant and up to date with evolving technologies.\n\nIn summary, Python is popular because it combines power and flexibility with accessibility. These qualities make it an excellent language for exploring data, performing analysis, and creating clear, visual insights.\n\n\n2.2.3 Where to Use Python?\nPython is a general-purpose programming language, which means it can be applied across a wide variety of domains. Some common uses1 include:\n\nWeb development: Creating websites and web applications using frameworks such as Django and Flask.\nData analysis and visualization: Working with structured and unstructured data, cleaning it, analyzing patterns, and presenting results visually with libraries like pandas, matplotlib, and seaborn.\nMachine learning and artificial intelligence: Building predictive models, natural language processing systems, and intelligent applications with libraries such as scikit-learn, TensorFlow, or PyTorch.\nScientific computing: Performing simulations, optimization, and large-scale computations in research and engineering.\nAutomation and scripting: Writing scripts to automate repetitive tasks, system processes, or business workflows.\nDesktop and GUI applications: Developing standalone tools or user-friendly applications with interfaces.\n\n\n\n2.2.4 Online Materials for Python\nThere are many resources available online for learning and troubleshooting Python. - The Python Documentation is one of the great sources for the information, which includes explanations, examples, and reference material for every part of the language. - The Python Wiki provides curated information including Beginner’s Guide separately for non-programmers and those with prior programming experience. - Beyond that, platforms such as Stack Overflow, Real Python, Geeks for Geeks, and various tutorials offer practical examples and solutions.\n\n\n\n\n\n\nNoteTutorials and beginner guides\n\n\n\nFrom the Python Software Foundation and Python Wiki.\n\nFor nonprogrammer\nFor programmer (know other programming languages)\n\n\n\n\n\n2.2.5 Python Versions\nPython exists in two major versions2 — Python 2 and Python 3.\n\nPython 2 was widely used for many years but reached its official end-of-life in January 2020. This means it no longer receives updates, bug fixes, or security patches. Some legacy codebases may still use Python 2, but it is no longer recommended for new development.\nPython 3 is the current and actively maintained version of the language. All modern libraries and tools are built for Python 3, and this is the version we will use throughout this course. Specifically, we will rely on Python 3.11, which is stable, well-supported, and compatible with the libraries we need for data mining and visualization.\n\n\n\n\n\n\n\nTip\n\n\n\nWhen you encounter tutorials or examples online, you may still see some written for Python 2. The syntax and behavior can differ in subtle but important ways, so always confirm that the code is written for the version you are using.\n\n\n\n\n2.2.6 Python Environment\nBefore diving into coding, it’s important to understand a Python (development) environment3 as the setup that allows you to write and run Python code. Often, you cannot even use Python without a proper development environment.\nThere are a number of ways to build development environments for python with various programs. At this time, let’s learn one way for building a properly configured environment to ensure that your code runs consistently, both on your machine and on others’.\nA Python environment typically includes core components that together define where and how your code will run:\n\nOperating system (OS) you’re working on (e.g., macOS) with a computer\nProgramming language (e.g., Python 3.11) that enables the computer to interpret and execute the code\nPackages that extend Python’s capabilities for various tasks\n\nTo set up a efficient Python environment, you can additionally consider:\n\nAn Integrated Development Environment (IDE) that is a tool to write and execute code (in a convenient way)\nVirtual environments that enables the development separately by project in isolated setups",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PB/PB-GetStarted.html#setting-python-development-environment-local",
    "href": "PB/PB-GetStarted.html#setting-python-development-environment-local",
    "title": "2  Getting Started",
    "section": "2.3 Setting Python Development Environment (Local)",
    "text": "2.3 Setting Python Development Environment (Local)\nThe following instruction is for a python environment on your own computer. The overall installation is as follow:\n\nInstall Anaconda/Conda as a platform for virtual environments\nInstall Python in a virtual environment\nInstall Jupyter Notebook as an IDE in the virtual environment\n\n\n2.3.1 Installing Anaconda (and Conda)\nDifferent projects often require different environment setups. That’s when a virtual environment comes in handy, which helps to work on isolated Python environments where you can freely create/delete them (with no risk of messing up your entire computer).\n\n2.3.1.1 Virtual Environment\nA virtual environment allows you to create a self-contained workspace where Python and all required libraries are stored separately from the system-wide installation.\nAnaconda/Conda is a popular software to manage virtual environments. To manage Python environments, we will use Anaconda/Conda.\n\nConda\n\nA package as the environment manager that creates isolated environments and installs packages (Python, R, C/Fortran libs, CUDA toolkits, etc.).\nWorks with any “distribution” (Anaconda, Miniconda, Miniforge).\n\nAnaconda\n\nA bundled distribution that includes conda, Python, Anaconda Navigator (GUI), and hundreds of prebuilt packages and Jupyter—all in one installer.\nBig install (~GBs), great for offline or “everything ready” setups.\n\n\n\n\n\n\n\n\nNoteWhy Use Conda to Install Python?\n\n\n\nInstalling Python through Conda (via Anaconda or Miniconda—minimal version of Anaconda) is highly recommended for this course, especially for users working with data science and analytics tools.\nHere’s why:\n\nIsolated Environments: Conda allows you to create separate environments for different projects. Each environment can have its own version of Python and packages—preventing version conflicts.\nBetter Package Management: Unlike pip (Python’s default package manager), Conda can install not just Python packages but also system-level dependencies like C or Fortran libraries. This is especially helpful for scientific packages like numpy, scipy, and pytorch.\nCross-Platform Compatibility: Conda works consistently across Windows, macOS, and Linux. It is also used by most cloud data science environments, helping ensure reproducibility.\nFast Setup with Anaconda: The Anaconda distribution includes over 250 pre-installed data science packages (e.g., pandas, matplotlib, scikit-learn, jupyterlab), making it ideal for beginners and fast onboarding.\nScientific Computing Support: Many data science and machine learning tools depend on optimized compiled libraries. Conda handles these dependencies more reliably than pip.\nReproducible, portable environments that “just work,” especially in data science: Conda is the most robust choice.\n\n\n\n\n\n\n2.3.2 Installing Python in Virtual Environment through Conda\nTo install Python, we’re going to use the command-line interface (CLI), because it’s simple to lightly handle environments, packages, and version control via the terminal.\n\n\n\n\n\n\nNoteThe Terminal in Brief\n\n\n\nThe command-line interface (also known as the command-line  and sometimes the command prompt) is a text-based interface that allows users to interact with the system (software) via command, each of which is formatted as a line of text, to your computer. In there, a command interpreter (also known as a command-line interpreter, command processor, or shell) is a program that implements a user’s commands via a CLI, acting like a bridge between the user and the operating system’s internal functions.\nMost OS’s (Linux, Mac, and Windows) have a built-in command-line program:\n\nthe PowerShell on Windows.\n\nSearch PowerShell and open it (without activating a conda environment which will be discussed below).\nOr, install PowerShell Prompt in Anaconda and run it in the virtual environment (activating it).\n\nthe Terminal on macOS\n\nSearch “Terminal” and open it\nTerminal User Guide\n\nthe Terminal on Linux\n\nSearch “Terminal” (the default Bash and open it\nThe Linux command line for beginners\nUsingTheTerminal - Ubuntu documantation\n\n\n\n\n\n\n2.3.2.1 Installing Anaconda\nInstalling Anaconda Distribution is the official website for the installation, in which the step-by-step procedure is documented well.\n\n\n2.3.2.2 Creating a Virtual Environment\nOnce you open the installed Anaconda on your computer, you start the Anaconda GUI on the base environment where your OS directly interact and that it is recommended not to use for projects. Instead of working on the base, let’s create a new one.\nTo do that, let’s open a terminal\n\nIn Windows, any prompt on the Anaconda GUI (e.g., Powershell Prompt, CMD.exe Prompt, or anaconda_prompt) — Not directly from Windows\nIn macOS/Linux, the OS’s terminal\n\nIn the terminal’s prompt, you should have (base) that indicates the current environment.\nA new environment with a name buda450_py311 can be created with the following command:\nconda create --name buda450_py311\nIn the command, you can replace buda450_py311 with the name you want for the environment. After completing the creation, the environment can be activated with the following command:\nconda activate buda450_py311\nCheck more details from Managing environments and about other Commands .\n\n\n2.3.2.3 Installing Python and Programs/Packages\nThen, Python can be installed through the following command.\nconda install python=3.11\nHere, Python’s version is specified (i.e., python 3.11). Without the version specification like conda install python, Python will be installed based on the conda’s default version.\n\n\n\n\n\n\nTipCreating an environment with python installation\n\n\n\nBy including programs/packages (and its versions) in the command, you can install them together when the environment is created.\nconda create --name buda450_py311 python=3.11\n\n\nSimilarly, some programs useful for Python can be installed in Conda environments.\nThe following command installs Jupyter’s Notebook and JupyterLab together.\nconda install notebook jupyterlab\n\n\n\n\n\n\nNote\n\n\n\nIn this course, we will use conda to install packages because it’s relatively more generic and convenient for tasks dealing with environments and complex dependencies, compared with pip. See the explanation in link for more details.\n\n\nSimilarly, you can install packages by executing a commend. For example, let’s install three pacakges\n\nnumpy for comprehensive numerical, mathematical operations as a basis of many advanced data science packages, by entering the following commend into the command line in your terminal.\npandas for data analysis and manipulation\nmatplotlib for creating static, animated, and interactive visualizations.\n\nconda install numpy pandas matplotlib\n\n\n\n\n\n\nWarning\n\n\n\nSometimes, the name of a package for installation may differ from its full name or for import.\nFor example, scikit-learn is a package for data mining and machine learning tasks. To install it, we use the name scikit-learn:\nconda install scikit-learn\nHowever, the package is called sklearn.\n\nimport sklearn\nprint(sklearn.__version__)\n\n1.6.1\n\n\nSo, it’s recommended to always check the exact commands from the original website (e.g., pandas) and repositories (e.g., anaconda’s Python Package Index (PyPi)).",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PB/PB-GetStarted.html#footnotes",
    "href": "PB/PB-GetStarted.html#footnotes",
    "title": "2  Getting Started",
    "section": "",
    "text": "https://www.python.org/about/apps/↩︎\nMany versions documented in Python Documentation by Version.↩︎\nA Python environment consists of all the tools and configurations that allow you to write, run, and manage Python programs efficiently.↩︎",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PB/PB-Basics.html",
    "href": "PB/PB-Basics.html",
    "title": "3  Concepts and Syntax",
    "section": "",
    "text": "3.1 Expressions and Operators\nThis section introduces fundamental concepts and syntax in python, including basic programming concepts and syntax, operators, and data types.\nAn expression is a piece of syntax which can be evaluated to some value. The detailed definitions are available in 6. Expressions (ver. 3.11).\nThe following expression is a simple expression for mathematical operation with the “addition” operator +:\n1 + 1\n\n2\nBy using a combination of multiple operators, an expression for complex computation can be computed.\n8**2 - 5%7\n\n59\nAs shown in this example, many different operators can be used in Python. Here are operators for arthmatic operations:\nSee more operators from https://www.w3schools.com/python/python_operators.asp\nWhen you run (i.e., evaluate) an expression, the operations in the expression are evaluated in the “PEMDAS” order:\nIn the previous example, if some elements and operations were in parentheses, the result becomes different:\n(8**2 - 5) % 7\n\n3",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PB/PB-Basics.html#expressions-and-operators",
    "href": "PB/PB-Basics.html#expressions-and-operators",
    "title": "3  Concepts and Syntax",
    "section": "",
    "text": "Operator\nOperation\nExample\nEvaluation\n\n\n\n\n+\nAddition\n4 + 3\n7\n\n\n-\nSubtraction\n18 - 4\n14\n\n\n*\nMultiplication\n7 * 8\n56\n\n\n/\nDivision\n30 / 6\n5\n\n\n%\nModulus/Remainder\n34 % 6\n4\n\n\n**\nExponent/Power\n3 ** 3\n27\n\n\n\n\n\n\nParentheses\nExponents\nMultiplication and Division (from left to right)\nAddition and Subtraction (from left to right)",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PB/PB-Basics.html#statements-and-variables",
    "href": "PB/PB-Basics.html#statements-and-variables",
    "title": "3  Concepts and Syntax",
    "section": "3.2 Statements and Variables",
    "text": "3.2 Statements and Variables\nA statement is part of a suite (a “block” of code) as a syntactic unit the interpreter executes.\nLet’s start with a simple statement for assignment. In Python terms, an assignment (re)binds a name to a value. In other words, we assign a value to a variable to bind a name to an object, where variables are containers for storing objects (e.g., data values).\nFor example, the following statement is about the assignment of a value (computed from an expression) to a variable result:\n\nresult = (8**2 - 5) % 7\n\nBy doing so, we can refer to the stored value later, reuse it, update program state, pass information between parts of a program, and make code clearer to humans.\nFor example, the stored value can be called by using print() function, which display the output, and can be reused:\n\nprint( result )\nprint( result + 4 )\n\n3\n7\n\n\nTo be specific, Python divides statements into - simple statements (single logical line, e.g., expression statements and assignment) - compound statements (control flow or definition blocks that contain other statements, e.g., if, for, while, try, with, and def) that contain (groups of) other statements.\nLater, we will revisit some of those that are helpful for our tasks. The detailed definitions are available in 7. Simple statements and 8. Compound statements (ver. 3.11).\n\n3.2.1 Output versus printing\nIn the examples above, the output was displayed below the cell either from the excution or through print(). When you run a code line by line in the interactive environment (e.g., the interactive interpreter and Jupyter notebook), the output will be displayed. But, it will not work when you have more lines.\nIn the example below we run two lines after two assignments. When not using the print(), only the output of the last operation in the cell is printed.\n\nfirst_value = 111\nsecond_value = 222\nfirst_value\nsecond_value\n\n222\n\n\nFurther, if the last operation is for some other (e.g., the assignment of a variable) rather than referring to a value, nothing will be printed.\n\nfirst_value\nsecond_value\nsomething_else = \"abc\"\n\nIn such situation, print() is used to print output to the screen.\n\nprint( first_value )\nprint( second_value )\nsomething_else = \"abc\"\n\n111\n222\n\n\nRule of thumb: - use the normal output for quick checking the output of an operation while developing in an interactive environment. - use print() for controling what is printed when, while developing more complicated codes (often in long codes or scripts).",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PB/PB-Basics.html#indentation",
    "href": "PB/PB-Basics.html#indentation",
    "title": "3  Concepts and Syntax",
    "section": "3.3 Indentation",
    "text": "3.3 Indentation\nIndentation refers to the spaces at the beginning of a code line. The indentation in Python is very important, while the indentation in code in other programming languages is for readability only.\nPython uses indentation to indicate a block of code. For example, the following is if statement (a compound statement) that contains a condition and a suite of two simple statements (excution of print() on two lines). This statement will return the result of the print() only if the condition is met.\n\nif 5 &gt; 2:\n    print(\"Is five greater than two?\")\n    print(\"Yes!\")\n\nIs five greater than two?\nYes!\n\n\nBased on the identation, your code may lead to a different result, as the suite for the statement is differently defined and interpreted by Python.\n\nif -7 &gt; 3:\n    print(\"Is five greater than two?\")\nprint(\"Yes!\")\n\nOn the other hand, Python will give you an error if the indentation is either omitted in a statemet that expects an indented suite:\n\nif 5 &gt; 2:\nprint(\"Is five greater than two?\")\nprint(\"Yes!\")\n\nAlso, you have to use the same level (number of spaces) in the same block of code, otherwise Python will give you an error:\n\nif 5 &gt; 2:\n    print(\"Is five greater than two?\")\n  print(\"Yes!\")",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PB/PB-Basics.html#comments",
    "href": "PB/PB-Basics.html#comments",
    "title": "3  Concepts and Syntax",
    "section": "3.4 Comments",
    "text": "3.4 Comments\nPython has commenting capability for the purpose of in-code documentation. Comments start with a sharp #, and Python will render the rest of the line, ignoring the rest of the line.\nComments can be added to your code in two typical ways. - a single-line comment can be placed for a one-liner note to explain the following lines:\n\n# This is a single-line comment. 1 + 1 will be NOT calculated by Python.\nprint(\"Hello, World!\")\n\nHello, World!\n\n\n\na inline comment can be placed right next to an expression to explain it:\n\n\nprint( 3 + 2 ) # addition\nprint( 3 - 2 ) # substraction\nprint( 3 * 2 ) # multiplication\nprint( 3 / 2 ) # division\n\n5\n1\n6\n1.5\n\n\nMany developers use comments for various purpose. You can check some best practices discussed in many online posts including How to Use Python Comments Effectively?.",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PB/PB-Basics.html#reference",
    "href": "PB/PB-Basics.html#reference",
    "title": "3  Concepts and Syntax",
    "section": "3.5 Reference",
    "text": "3.5 Reference\n\nhttps://uofsclibraries-drs.github.io\nhttps://www.w3schools.com/python-",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PB/PB-Data.html",
    "href": "PB/PB-Data.html",
    "title": "4  Data Types",
    "section": "",
    "text": "4.1 Built-in Data Types in Python\nThis section introduces built-in data types in Python.\nPython has various built-in data types, categorized as follows:\nAll expression evaluate to a single value. In the above examples, the expression evaluated to single numerical value. Numerical values come in two basic forms:",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PB/PB-Data.html#data-types",
    "href": "PB/PB-Data.html#data-types",
    "title": "4  Python Basics - Data Type",
    "section": "",
    "text": "Category\nData Type\nExample\n\n\n\n\nNumeric\nint\n20\n\n\nNumeric\nfloat\n20.5\n\n\nNumeric\ncomplex\n1j\n\n\nText\nstr\n\"Hello World\"\n\n\nSequence\nlist\n[\"apple\", \"banana\", \"cherry\"]\n\n\nSequence\ntuple\n(\"apple\", \"banana\", \"cherry\")\n\n\nSequence\nrange\nrange(6)\n\n\nMapping\ndict\n{\"name\": \"John\", \"age\": 36}\n\n\nSet\nset\n{\"apple\", \"banana\", \"cherry\"}\n\n\nSet\nfrozenset\nfrozenset({\"apple\", \"banana\", \"cherry\"})\n\n\nBoolean\nbool\nTrue\n\n\nBinary\nbytes\nb\"Hello\"\n\n\nBinary\nbytearray\nbytearray(5)\n\n\nBinary\nmemoryview\nmemoryview(bytes(5))\n\n\nNone\nNoneType\nNone",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Python Basics - Data Type</span>"
    ]
  },
  {
    "objectID": "PB/PB-Data.html#numbers",
    "href": "PB/PB-Data.html#numbers",
    "title": "4  Data Types",
    "section": "4.2 Numbers",
    "text": "4.2 Numbers\nThere are three numeric types in Python. Let’s enter each type in Python and check it by using the type() that returns the type of the specified object.\n\nint: Int, or integer, is a whole number, positive or negative, without decimals, of unlimited length.\n\n\n# int\nprint( 123 ) \nprint( type( 123 ) )\n\n123\n&lt;class 'int'&gt;\n\n\n\nfloat: Float, or “floating point number” is a number, positive or negative, containing one or more decimals.\n\n\nprint( 3.14 )\nprint( type( 3.14 ) )\n\n3.14\n&lt;class 'float'&gt;\n\n\n- Float can also be scientific numbers with an \"e\" to indicate the power of 10.\n\nprint( 987e5 )\nprint( 1.23e-3 )\n\n98700000.0\n0.00123\n\n\n\ncomplex: Complex numbers are written with a real number + a j as the imaginary part:\n\n\nprint( 1.5+4j )\nprint( type( 1.5+4j ) )\n\n(1.5+4j)\n&lt;class 'complex'&gt;\n\n\n\nint( 3.14 )\n\n3",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PB/PB-Data.html#strings",
    "href": "PB/PB-Data.html#strings",
    "title": "4  Data Types",
    "section": "4.3 Strings",
    "text": "4.3 Strings\nA snippet of text in Python is called a string. Strings in python are surrounded by either single quotation marks ', or double quotation marks \".\nFor example, 'hello' is the same as \"hello\". To evaluate whether two values are equal, we can use two equals signs == between them. The expression will evaluate to either True or False (see below for Boolean value).\n\n'hello' == \"hello\"\n\nTrue\n\n\nA string can contain letters, spaces, line breaks, and numbers. When a non-text value is embraced by quotation marks, it becomes a string, and Python treats it differently. For example, an integer 5 is converted to a string with quotation marks.\n\nprint( type(\"5\") )\n\n&lt;class 'str'&gt;\n\n\n\n# Compare an integer with the same meaning in other types\nprint( 5 == 5.0 )    # integer vs float\nprint( 5 == '5' )    # integer vs string \n\nTrue\nFalse\n\n\nThe distinction between each of these data types may seem unimportant, but it is. This is because an operator performs different operations, depending on the data type.\nFor example, the addition + for strings conbine two strings, called concatenation, exactly as they are in the order of the strings in the expression:\n\n# Combine the strings 'Hello' and 'World'\n'hello' + ' world'\n\n'hello world'\n\n\nHowever, using such operators may cause an error when the operators are applied to different types (e.g., numeric and non-numeric).\n\n# Try adding a string to an integer\n'5' + 7",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PB/PB-Data.html#boolean-values",
    "href": "PB/PB-Data.html#boolean-values",
    "title": "4  Data Types",
    "section": "4.4 Boolean Values",
    "text": "4.4 Boolean Values\nIn programming, you often need to know whether an expression is true or not. Booleans is a way to represent one of two possible values, True or False.\nIn Python, Boolean values can be handled by entering exactly True or False (case-sensitive).\n\nprint( False )\nprint( type(False) )\n\nFalse\n&lt;class 'bool'&gt;\n\n\nIn Python, the Boolean values True and False can be converted into numeric values 1 and 0, respectively.\n\nprint( int(True) )\nprint( float(False) )\n\n1\n0.0\n\n\n\n4.4.1 Comparison Operators\nComparison operators in Python are used to compare two values.\n\n\n\nOperator\nName\nExample\n\n\n\n\n==\nEqual\nx == y\n\n\n!=\nNot equal\nx != y\n\n\n&gt;\nGreater than\nx &gt; y\n\n\n&lt;\nLess than\nx &lt; y\n\n\n&gt;=\nGreater than or equal to\nx &gt;= y\n\n\n&lt;=\nLess than or equal to\nx &lt;= y\n\n\n\nAs shown in the example about strings, the == operator returns True if two values are equal to each other.\n\nprint( 5 == 5.0 )             # If the values are the same, an integer and a float are the same\nprint( 5 == \"five\" )          # A string cannot be equal to a float or an integer.\nprint( \"Five\" == \"five\" )     # Strings with different cases are not the same.\n\nTrue\nFalse\nFalse\n\n\n\n\n4.4.2 Logical Operators\nLogical operators are used to combine Boolean values (e.g., from conditional statements).\n\n\n\n\n\n\n\n\nOperator\nDescription\nExample\n\n\n\n\nand\nTrue if both statements are true\nx &lt; 5 and x &lt; 10\n\n\nor\nTrue if at least one statement is true\nx &lt; 5 or x &lt; 4\n\n\nnot\nReverses the result (Boolean negation)\nnot (x &lt; 5 and x &lt; 10)\n\n\n\nThe operation with a logical operator for two Boolean values returns a single Boolean value.\nFor example, when both statements are True, the and operator returns True\n\n# When (condition one is True) AND (condition two is True):\ncond1 = 1 &lt; 6\ncond2 = 4 &lt; 6\nprint( cond1 and cond2 )\nprint( True and True )\n\nTrue\nTrue\n\n\n\n# When (condition one is True) AND (condition two is False):\nprint( True and False )\n\nFalse\n\n\nConsidering two possible values of the statements, all possible combinations and their and results can be organized in a Truth table:\n\n\n\nCondition 1\nLogical operator\nCondition 2\nEvaluation\n\n\n\n\nTrue\nand\nTrue\nTrue\n\n\nTrue\nand\nFalse\nFalse\n\n\nFalse\nand\nTrue\nFalse\n\n\nFalse\nand\nFalse\nFalse\n\n\n\nSimilarly, create a Truth table that shows all possible results from or operator with two statements.\n\n\n\nCondition 1\nLogical operator\nCondition 2\nEvaluation\n\n\n\n\nTrue\nand\nTrue\nTrue\n\n\nTrue\nand\nFalse\nTrue\n\n\nFalse\nand\nTrue\nTrue\n\n\nFalse\nand\nFalse\nFalse\n\n\n\nLastly, the not operator only operates on a single expression for Boolean negation (i.e., flipping True to False or False to `True.\n\n# The not operator flips a True to False\nprint(not True)\nprint(not False)\n\nFalse\nTrue",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PB/PB-Data.html#lists",
    "href": "PB/PB-Data.html#lists",
    "title": "4  Data Types",
    "section": "4.5 Lists",
    "text": "4.5 Lists\nLists are one of four built-in data types that are used to store multiple items. Lists are created using square brackets [], and each item of any data type can be included with delimiter , in such ways of [item1, item2, item3, item4, ...].\n\n# A list of three integers \nint_list = [2, 4, 6, 8]\nprint( int_list )\nprint( type( int_list ) )\n\n[2, 4, 6, 8]\n&lt;class 'list'&gt;\n\n\n\n# A list of three mixed types \nmixed_list = [-0.2, 'car', False]\nprint( mixed_list )\nprint( type( mixed_list ) )\n\n[-0.2, 'car', False]\n&lt;class 'list'&gt;\n\n\n\n# An empty list\nempty_list = []\nprint( empty_list )\nprint( type( empty_list ) )\n\n[]\n&lt;class 'list'&gt;\n\n\n\n# A list of lists\nlists_list = [ int_list, mixed_list, empty_list] \nprint( lists_list )\nprint( type( lists_list ) )\n\n[[2, 4, 6, 8], [-0.2, 'car', False], []]\n&lt;class 'list'&gt;\n\n\nList items are presented in the order stored, and can be referred to by using the index.\n\nprint(int_list[0])     # first item of int_list\nprint(int_list[-1])     # the last item of int_list\n\n2\n8\n\n\nWe can change the value of any item in a list using an assignment statement that contains the item’s index number.\n\n# Changing the value of an item in a list\nAnimal = ['Cat', 'Dog', 'Bear']\nprint(Animal)\n\n['Cat', 'Dog', 'Bear']\n\n\n\n# Changing an item using an assignment state with index number\nAnimal[1] = 'Lion'\nprint(Animal)\n\n['Cat', 'Lion', 'Bear']",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PB/PB-Data.html#dictionaries",
    "href": "PB/PB-Data.html#dictionaries",
    "title": "4  Data Types",
    "section": "4.6 Dictionaries",
    "text": "4.6 Dictionaries\nDictionaries are another built-in data types storing multiple items. Dictionaries are created using curly brackets {}, and each item has a unique key paired with some value by : such that { key1 : value1, key2 : value2, key3 : value3, ...}\n\n# A dictionary of three integers \nint_dict = {\"Math\": 95, \"History\": 55, \"Art\": 70}\nprint( int_dict )\nprint( type( int_dict ) )\n\n{'Math': 95, 'History': 55, 'Art': 70}\n&lt;class 'dict'&gt;\n\n\n\n# A dictionary of mixed values\nmixed_dict = {\"Age\": 23, \"State\": \"WV\", \"Membership\": True, 'Ordered': [\"Shoes\", \"Socks\"]}\nprint( mixed_dict )\nprint( type( mixed_dict ) )\n\n{'Age': 23, 'State': 'WV', 'Membership': True, 'Ordered': ['Shoes', 'Socks']}\n&lt;class 'dict'&gt;\n\n\nDictionary items are presented in key:value pairs, and can be referred to by using the key name.\n\nprint(mixed_dict[\"Ordered\"])\n\n['Shoes', 'Socks']\n\n\nTo access a item of a list in the dictionary, an additional bracket with its index can be placed after the first indexing expression.\n\nprint(mixed_dict[\"Ordered\"][1])\n\nSocks",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PB/PB-Data.html#reference",
    "href": "PB/PB-Data.html#reference",
    "title": "4  Data Types",
    "section": "4.7 Reference",
    "text": "4.7 Reference\n\nhttps://uofsclibraries-drs.github.io\nhttps://www.w3schools.com/python-",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PB/PB-Data.html#built-in-data-types-in-python",
    "href": "PB/PB-Data.html#built-in-data-types-in-python",
    "title": "4  Data Types",
    "section": "",
    "text": "Category\nData Type\nExample\n\n\n\n\nNumeric\nint\n20\n\n\nNumeric\nfloat\n20.5\n\n\nNumeric\ncomplex\n1j\n\n\nText\nstr\n\"Hello World\"\n\n\nSequence\nlist\n[\"apple\", \"banana\", \"cherry\"]\n\n\nSequence\ntuple\n(\"apple\", \"banana\", \"cherry\")\n\n\nSequence\nrange\nrange(6)\n\n\nMapping\ndict\n{\"name\": \"John\", \"age\": 36}\n\n\nSet\nset\n{\"apple\", \"banana\", \"cherry\"}\n\n\nSet\nfrozenset\nfrozenset({\"apple\", \"banana\", \"cherry\"})\n\n\nBoolean\nbool\nTrue\n\n\nBinary\nbytes\nb\"Hello\"\n\n\nBinary\nbytearray\nbytearray(5)\n\n\nBinary\nmemoryview\nmemoryview(bytes(5))\n\n\nNone\nNoneType\nNone",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html",
    "href": "App/App-Markdown.html",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "",
    "text": "A.1 Keyboard Shortcuts for Cell Types in Jupyter\nThis notebook is based on Markdown cheat sheet to provide a quick overview of the Markdown syntax elements. The elements introduced in this notebook are supported by many other Markdown applications. For more detailed, comprehensive information, refer to the reference guides from basic syntax and extended syntax or Tutorials.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html#keyboard-shortcuts-for-cell-types-in-jupyter-notebook-lab",
    "href": "App/App-Markdown.html#keyboard-shortcuts-for-cell-types-in-jupyter-notebook-lab",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "",
    "text": "y Change to Code Cell Type\nm Change to Markdown Cell Type and\nr Change to Raw Cell Type",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html#heading",
    "href": "App/App-Markdown.html#heading",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "A.2 Heading",
    "text": "A.2 Heading\nMultiple levels…\n\n# H1\n## H2\n### H3\n#### H4\n##### H5\n###### H6\n\n\n\nShow the code in HTML\n&lt;h1&gt;H1&lt;/h1&gt;\n&lt;h2&gt;H2&lt;/h2&gt;\n&lt;h3&gt;H3&lt;/h3&gt;\n&lt;h4&gt;H4&lt;/h4&gt;\n&lt;h5&gt;H5&lt;/h5&gt;\n&lt;h6&gt;H6&lt;/h6&gt;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html#h2",
    "href": "App/App-Markdown.html#h2",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "B.1 H2",
    "text": "B.1 H2\n\nB.1.1 H3\n\nB.1.1.1 H4\n\nH5\n\nH6\n# H1\n## H2\n### H3\n#### H4\n##### H5\n###### H6",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html#emphasis",
    "href": "App/App-Markdown.html#emphasis",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "A.3 Emphasis",
    "text": "A.3 Emphasis\nitalicized text\nbold text\nBold italic\nBold italic\nBold italic\nStrikethrough\n\nblockquote\n\n\n*italicized text*\n\n_italicized text_\n\n**bold text**\n\n**_Bold italic_**\n\n***Bold italic***\n\n___Bold italic___\n\n~~Strikethrough~~\n\n&gt; blockquote\n\n\n\nShow the code in HTML\n&lt;em&gt;Italic&lt;/em&gt;\n\n&lt;strong&gt;Bold&lt;/strong&gt;\n\n&lt;strike&gt;Strikethrough&lt;/strike&gt;\n\n&lt;strong&gt;&lt;em&gt;Bold italic&lt;/em&gt;&lt;strong&gt;\n\n&lt;mark&gt;Mark&lt;/mark&gt;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html#lists",
    "href": "App/App-Markdown.html#lists",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "A.4 Lists",
    "text": "A.4 Lists\n\nA.4.1 Ordered List\n\nFirst item\nSecond item\nThird item\n\n\n1. First item\n2. Second item\n3. Third item\n\n\n\nShow the code in HTML\n&lt;ol&gt;\n    &lt;li&gt;First item&lt;/li&gt;\n    &lt;li&gt;Second item&lt;/li&gt;\n    &lt;li&gt;Third item&lt;/li&gt;\n&lt;/ol&gt;\n\n\n\n\nA.4.2 Unordered List\n\nFirst item\nSecond item\nThird item\n\n\n- First item\n- Second item\n- Third item\n\n\n\nShow the code in HTML\n&lt;ul&gt;\n    &lt;li&gt;First item&lt;/li&gt;\n    &lt;li&gt;Second item&lt;/li&gt;\n    &lt;li&gt;Third item&lt;/li&gt;\n&lt;/ul&gt;\n\n\n\n\nA.4.3 Task List\n\nFirst item\nSecond item\nThird item\n\n\n- [x] First item\n- [ ] Second item\n- [x] Third item",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html#code",
    "href": "App/App-Markdown.html#code",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "A.5 Code",
    "text": "A.5 Code\nThis is a in-line code, which is typed as `code`.\n\n\nShow the code in HTML\nThis is a in-line `code`.\n\n\nA fenced code block is for the whole space of the line.\n```  dict_ = {  “firstName”: “Jeongsub”,  “lastName”: “Choi”,  “age”: 18  }  ```\n\n\nShow the code in HTML\n&lt;code&gt; &lt;a&gt;\ndict_ = {\n  \"firstName\": \"Jeongsub\",\n  \"lastName\": \"Choi\",\n  \"age\": 18\n}\n&lt;/a&gt; &lt;/code&gt;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html#mathematical-symbols",
    "href": "App/App-Markdown.html#mathematical-symbols",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "A.6 Mathematical symbols",
    "text": "A.6 Mathematical symbols\nThis is a in-line mathematical symbols \\(X_i = \\alpha^3\\), which is typed as $X_i = \\alpha^3$.\nAnd, a fenced equation block is for the whole space of the line.\n\\[\n\\sum_{i=1}^{3}{X_i}\n\\]\n\n$$\n\\sum_{i=1}^{3}{X_i} \n$$",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html#other-elements",
    "href": "App/App-Markdown.html#other-elements",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "A.7 Other elements",
    "text": "A.7 Other elements\n\nA.7.1 Horizontal Rule\nThe same horizontal line from different symbols:\n\nor\n\nor\n\n\n---\n\nor\n\n***\n\nor\n\n___\n\n\n\nShow the code in HTML\n&lt;hr&gt;\n\n\n\n\nA.7.2 Link\nNo space between the bracket and the paranthesis.\nMarkdown Guide\n\n[Markdown Guide](https://www.markdownguide.org)\n\n\n\nShow the code in HTML\n&lt;a href=\"https://www.markdownguide.org\" target=\"_blank\"&gt;Markdown Guide&lt;/a&gt;\n\n\n\n\nA.7.3 Image\nNo space between the exclamation mark and the bracket, and between the bracket and the paranthesis.\n\n\n\nalt text\n\n\n\n![alt text](https://www.markdownguide.org/assets/images/tux.png)\n\n\n\nShow the code in HTML\n&lt;img src=\"https://www.markdownguide.org/assets/images/tux.png\"/&gt;\n\n\n\n\nA.7.4 Table\n\n\n\nSyntax\nDescription\n\n\n\n\nHeader\nTitle\n\n\nParagraph\nText\n\n\n\n\n| Syntax | Description |\n| ----------- | ----------- |\n| Header | Title |\n| Paragraph | Text |\n\n\n\nShow the code in HTML\n&lt;table class=\"demo\"&gt;\n&lt;thead&gt;\n    &lt;tr&gt;\n        &lt;th&gt;Syntax&lt;/th&gt;\n        &lt;th&gt;Description&lt;/th&gt;\n    &lt;/tr&gt;\n    &lt;/thead&gt;\n    &lt;tbody&gt;\n    &lt;tr&gt;\n        &lt;td&gt;Header&lt;/td&gt;\n        &lt;td&gt;Title&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;Paragraph&lt;/td&gt;\n        &lt;td&gt;Text&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;/tbody&gt;\n&lt;/table&gt;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html#html",
    "href": "App/App-Markdown.html#html",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "A.8 HTML",
    "text": "A.8 HTML\nMany similar and advanced syntax can be made through HTML.\n\nA.8.1 Heading\n&lt;h1&gt;H1&lt;/h1&gt;\n&lt;h2&gt;H2&lt;/h2&gt;\n&lt;h3&gt;H3&lt;/h3&gt;\n\n\nA.8.2 Emphasis\n&lt;em&gt;Italic&lt;/em&gt;\n&lt;strong&gt;Bold&lt;/strong&gt;\n&lt;strike&gt;Strikethrough&lt;/strike&gt;\n&lt;strong&gt;&lt;em&gt;Bold italic&lt;/em&gt;&lt;strong&gt;\n&lt;mark&gt;Mark&lt;/mark&gt;\n\n\nA.8.3 Lists\nOrdered list\n&lt;ol&gt;\n    &lt;li&gt;Item 1&lt;/li&gt;\n    &lt;li&gt;Item 2&lt;/li&gt;\n    &lt;li&gt;Item 3&lt;/li&gt;\n&lt;/ol&gt;\nUnordered list\n&lt;ul&gt;\n    &lt;li&gt;Item 1&lt;/li&gt;\n    &lt;li&gt;Item 2&lt;/li&gt;\n    &lt;li&gt;Item 3&lt;/li&gt;\n&lt;/ul&gt;\n\n\nA.8.4 Code\nCode\n&lt;code&gt; &lt;a&gt;Example of code&lt;/a&gt; &lt;/code&gt;\n\n\nA.8.5 Other elements\nHorizontal rule\n&lt;hr&gt;\nLink\n&lt;a href=\"https://www.wvu.edu/\" target=\"_blank\"&gt;External link - WVU&lt;/a&gt;\nImage\n&lt;img src=\"https://ccdam.wvu.edu/scm-main/university-seal-280x280.png\" /&gt; &lt;br /&gt;\n&lt;style&gt;\n.demo { border:1px solid #C0C0C0; border-collapse:collapse; padding:5px; }\n.demo th { border:1px solid #C0C0C0; padding:5px; background:#F0F0F0;}\n.demo td { border:1px solid #C0C0C0; padding:5px;}\n&lt;/style&gt;\nTable\n&lt;table class=\"demo\"&gt;\n&lt;thead&gt;\n    &lt;tr&gt;\n        &lt;th&gt;Column1&lt;/th&gt;\n        &lt;th&gt;Column2&lt;/th&gt;\n    &lt;/tr&gt;\n    &lt;/thead&gt;\n    &lt;tbody&gt;\n    &lt;tr&gt;\n        &lt;td&gt;Item 1.1&lt;/td&gt;\n        &lt;td&gt;Item 1.2&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;Item 2.1&lt;/td&gt;\n        &lt;td&gt;Item 2.2&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;/tbody&gt;\n&lt;/table&gt;",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "App/App-Markdown.html#keyboard-shortcuts-for-cell-types-in-jupyter",
    "href": "App/App-Markdown.html#keyboard-shortcuts-for-cell-types-in-jupyter",
    "title": "Appendix A — Markdown Cheat Sheet",
    "section": "",
    "text": "y Change to Code Cell Type\nm Change to Markdown Cell Type and\nr Change to Raw Cell Type",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Markdown Cheat Sheet</span>"
    ]
  },
  {
    "objectID": "PB/PB-Fn-Pack.html",
    "href": "PB/PB-Fn-Pack.html",
    "title": "5  Functions and Packages",
    "section": "",
    "text": "5.1 Function\nThis section introduces functions and packages in Python.\nA function is a named block of reusable code that performs a specific task.\nPython functions take inputs (called arguments) and produce outputs (called return values) by executing a defined operation. Like mathematical functions, You can pass data, known as parameters, into a function that can return data as a result.\nFor example, a built-in function print() outputs text to the console (or to a specified file):\nprint(\"BUDA 450\")\n\nBUDA 450\nFunctions help improve code clarity, reduce redundancy, and support modular design.",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PB/PB-Fn-Pack.html#function",
    "href": "PB/PB-Fn-Pack.html#function",
    "title": "5  Functions and Packages",
    "section": "",
    "text": "5.1.1 Calling a Function\nTo call a function, you use its name, followed by parentheses (). Inside the parentheses, you may include arguments as the inputs if needed, separated by commas , if there are multiple.\nFor example, the sum() function accepts arguments for a list of numbers and a value to specify a starting value for the summation:\n\nodd_numbers = [1,3,5]\nsum(odd_numbers, start=10)\n\n19\n\n\nAs shown in this example, Python functions can accept two main types of arguments:\nPositional arguments\n\nArguments are assigned based on their position in the function call.\nTheir order matters as the position of each argument play a different role.\n\n\n# print() with two positional arguments\nWhom = \"World\"\nprint(\"Hello\", Whom)\n\nHello World\n\n\nKeyword arguments\n\nArguments are explicitly assigned using name = value syntax, like value assignments to objects.\nThis improves clarity and allows reordering or omitting optional parameters:\n\n\n# print with additional keyword argument for `sep` to specify the separator '__space__'\nprint(\"Hello\", Whom, sep='__space__') \n\nHello__space__World\n\n\nKeyword arguments often have default values, making them optional. For instance, the print() function uses a default space ' ' for sep (see the official documentation), unless it is overwritten by the user.\n\n\n\n\n\n\nTip\n\n\n\nParentheses () are what we can consider for a clear distinction between functions and variables. Even when no argument is needed for a function’s operation, empty parentheses are used, referring to a function name. Even if a function takes no arguments, always use parentheses () to call it. This distinguishes functions from variables.\n\nprint()   # calling it for its operation (display none)\n\n\n\n\n\nprint     # refers to the function object itself\n\n&lt;function print(*args, sep=' ', end='\\n', file=None, flush=False)&gt;\n\n\n\n\n\n5.1.1.1 Built-in Functions\nPython includes a rich set of built-in functions that are always available without extra external modules. These functions handle many basic tasks, from displaying output to performing calculations or type conversions.\nYou can explore the full list of built-in functions in the Python’s official library documentation1.\nHere are some other built-in function examples:\n\n# Convert a number to a string\nstr(598)                          # Output: \"598\"\n\n# Get the length of a string\nlen(\"python\")                     # Output: 6\n\n# Round a number to a specified precision\nround(3.1415, 2)                  # Output: 3.14\n\n# Find the smallest of several values\nmin(1, 6/8, 4/3)                  # Output: 0.75\n\n0.75\n\n\n\n\n\n\n\n\nWarning\n\n\n\nLearning to program in Python partly means becoming familiar with its built-in functions (and many other functions in other modules related to your tasks). You don’t need to memorize them—just be aware they exist and know how to look them up when needed, like you use a dictionary for your writing.\n\n\n\n\n5.1.1.2 Methods\nA method is a function that belongs to an object. So, a method is called on an object and is specific to the object’s type. To apply a method, you can call the method’s name (and arguments), following the name of the target object to call the method on and a period (dot) . , like object_name.method_name(arguments).\nFor example, consider a string-type class2 object my_string_object and a method lower() that can be applied to the object to make all letters in the string lowercase.\n\nmy_message = \"Hello World\"   # a string object\nprint(my_message.lower())           # a lowercase version of the string object\n\nhello world\n\n\nFor other methods available for strings, see the official documentation\n\n\n\n\n\n\nNote\n\n\n\nDot notation . is also used to access attributes of an object.\nFor instance, if the_person is a Person object with a name attribute and a say_name() method, you would use:\n\nthe_person.name for the person’s name\nthe_person.say_name() to invoke the behavior method()\n\nThink of the dot . like a possessive:\n\nthe_person.name means “the person’s name”;\nthe_person.say_name() means “the person’s say_name() action”.\n\n\n\n\n\n\n\n\n\nCautionExercise\n\n\n\nA method replace(first, second) is for replacing the values that are equal to the first argument in the object with the values in the second argument. Using this method, make my_message return \"Hi World\".\n\n\nShow the code\nmy_message.replace(\"Hello\", \"Hi\")\n\n\n\n\n\n\n\n5.1.2 Writing Functions\nWhile Python offers many built-in and third-party functions, one of the most powerful features of the language is the ability to write your own functions. Functions allow you to encapsulate reusable logic, helping you organize code into meaningful, manageable chunks.\nAs Downey puts it:\n\n“Their primary purpose is to help us organize programs into chunks that match how we think about the problem.”\n\nWhenever you find yourself repeating the same logic, or want to improve the clarity of your program, writing a function is the right move. It reduces repetition, lowers the risk of errors, and makes your code more modular and easier to debug.\nA new function can be defined with def. Here’s a simple example:\n\n# Define a function that takes two arguments and returns a full name\ndef make_full_name(first_name, last_name):\n    out = first_name + \" \" + last_name\n    print(out)\n\n# Call the function with two arguments\nmake_full_name(\"Laura\", \"Brown\")\n\nLaura Brown\n\n\n\n5.1.2.1 Components in a Function\nWriting a function in Python involves several key components. Each part plays a role in defining, organizing, and executing reusable code logic.\ndef keyword\n\nDefine a new function with the def keyword that signals to Python that what follows is a function definition.\n\nFunction name\n\nGive your function a meaningful name that reflects its purpose.\n\nOne good practice is naming functions using verbs (as they do something), and naming variables using nouns (as they represent data).\n\nNaming rules for general objects/variables also apply to functions (e.g., lowercase letters, underscores for separation).\n\nParentheses () and Parameters\n\nAttach parentheses () after the function name.\nInside the parentheses, you may include:\n\nPositional arguments: Required values, passed in order.\nKeyword arguments: Optional values, assigned with a default.\n\n\n\ndef greet_name(name, greeting=\"Hello\"):\n    out = greeting + ', ' + name + '!'\n    print(out)\n\nprint(greet_name(\"Emma\") )                \nprint(greet_name(\"Jason\", greeting=\"Hi\")) \n\nHello, Emma!\nNone\nHi, Jason!\nNone\n\n\n\n# Functions can also take no arguments—just use empty parentheses:\ndef greet(name=\"Everyone\", greeting=\"Hello\"):\n    greet_out = greeting + ', ' + name + '!'\n    print(greet_out)\n\ngreet()\n\nHello, Everyone!\n\n\nColon :\n\nEnd the function header line with a colon :, indicating that the body (block) of the function follows.\n\nFunction Body (Indented Block)\n\nKeep indentation (typically 4 spaces) for all the body of the function.\nIt contains the operations to execute when the function is called, which can include:\n\nVariable declarations\nOther function calls\nControl flow (if, for, etc.)\n\n\n(Optional) return statement\n\nUse the return keyword to specify the output of your function.\nWhen return is executed, the function ends and passes the value back to where it was called.\nThe return statement can be omitted if a function does not need to return a value.\n\n\n# Functions can also take no arguments—just use empty parentheses:\ndef greet_return(name=\"Everyone\", greeting=\"Hello\"):\n    greet_out = greeting + ', ' + name + '!'\n    print(greet_out)\n    return name   # return only the name used\n\nres = greet_return()\nprint(\"The output is\", res)\n\nHello, Everyone!\nThe output is Everyone\n\n\n\n\n5.1.2.2 Doc Strings\nFunctions are a way of abstracting behavior by organizing your code into meaningful, reusable parts. While good function and argument names help (def calc_rectangle_area(width, height) is better than def my_func(a, b, c)), naming alone isn’t always enough. To make your functions easy to understand and use (by yourself or others), it’s important to document them clearly.\nA doc string (documentation string) is a special multi-line string placed right below a function definition. typically describing:\n\nWhat the function does (at a high level), as a short abstraction (1~2 sentences);\nWhat inputs (arguments) it expects;\nWhat it returns (if anything).\n\nDoc strings are enclosed in triple quotes \"\"\" and are not assigned to any variable.\n\ndef to_celsius(degrees_fahrenheit):\n    \"\"\"Converts Fahrenheit to Celsius and returns the result.\"\"\"\n    return (degrees_fahrenheit - 32) * (5/9)\n\nIf a function contains doc strings, you can access this documentation using the built-in help() function with the function’s name:\n\nhelp(to_celsius)\n\nHelp on function to_celsius in module __main__:\n\nto_celsius(degrees_fahrenheit)\n    Converts Fahrenheit to Celsius and returns the result.\n\n\n\n\n\n\n\n\n\nCautionExercise\n\n\n\nCheck the doc string of a built-in function by calling help() with the function you choose from the official website.\n\n\nShow the code\nhelp(round)",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PB/PB-Fn-Pack.html#modules-and-packages-libraries",
    "href": "PB/PB-Fn-Pack.html#modules-and-packages-libraries",
    "title": "5  Functions and Packages",
    "section": "5.2 Modules and Packages (Libraries)",
    "text": "5.2 Modules and Packages (Libraries)\nWhile Python includes many built-in functions, additional functionality can be organized into modules and packages\n\nModule: an object that serves as an organizational unit of Python code.\nPackage: a Python module which can contain submodules or recursively, subpackages. Technically, a package is a Python module with a path attribute.\n\nFor example, Numpy is a fundamental package for many numerical operations in Python, and the package files can be found from its Github Page. In there, each .py file (e.g., numpy/numpy folder) contains functions and variables.\nTo use a function of a package’s module, you must first import it using the import keyword. This keeps the interpreter efficient by loading only the necessary tools into memory.\nFor example, math is a module that contains various useful mathematical functions. To make them available, run the import keyword with a space and module name.\n\n# Import the built-in math module\nimport math\n\nThis only needs to be done once per script execution, and so is normally done at the top of the script (in a Jupyter notebook, you can include an importing code cell, or import the module at the top of the cell in which you first need it). Then, we run the code in the module:\n\n# Call functions or access constants using dot notation\nmath.sqrt(25)      # 5.0\nprint(math.pi)     # 3.141592653589793\n\n3.141592653589793\n\n\nAs you may notice, Dot notation works here just as it does for object methods. That is, math.sqrt() means “the sqrt() function in the math module.”\n\n\n\n\n\n\nTipPackage’s calling name in your code\n\n\n\nWhen importing a package, its calling name can be customized (or shortened):\n\nimport math as m\nm.sqrt(25)\n\n5.0\n\n\n\n\n\n5.2.0.1 Importing from a Custom Module\nWith a .py file, you can manage objects (functions and/or variables). Such custom modules can be imported in the same way.\nFor example, let’s consider a my_module.py file in the same directory as your script. Then, you can import the module using the filename without .py extension, as the module name:\n\nimport my_module\nmy_module.greet_name(\"Lucas\")\n\nHello, Lucas!\n\n\n\n\n5.2.1 Importing Specific Functions\nYou can import specific functions or variables from a module directly, rather than importing the entire module. So, in the code, you don’t need to attach the module name.\n\n# import two objects (a function and a variable)\nfrom math import sqrt, pi\n\nsqrt(36)           # 6.0\nprint(pi)          # 3.141592653589793\n\n3.141592653589793\n\n\nOr you can import everything in the module:\n\nfrom math import *\n\n\n\n\n\n\n\nWarning\n\n\n\nImporting all in large or unfamiliar modules is typically not recommended because the name of some function or variable may overlap with other objects. In such cases, the previous objects are overwritten, so that you lose the objects.\n\n\n\n\n5.2.2 Standard Library vs. External Packages\nModules like math, random, and datetime are part of Python’s Standard Library (see all modules from the index. However, Python’s real power comes from thousands of additional libraries (or packages) developed by the community, such as pandas, numpy, and matplotlib.\nTo use these external libraries, you must first install them. If you’re using Anaconda, you can install packages with the conda command. For example, a package numpy can be installed by executing the following in the terminal:\nconda install numpy\nAfter installing the package to use, you can import it in the same way.\n\nimport numpy as np\n\ndata_list = [[1,2,3],[4,5,6]]  # data\nnp.array(data_list)         # a numpy ndarray object\n\narray([[1, 2, 3],\n       [4, 5, 6]])",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PB/PB-Fn-Pack.html#reference-and-resources",
    "href": "PB/PB-Fn-Pack.html#reference-and-resources",
    "title": "5  Functions and Packages",
    "section": "5.3 Reference and Resources",
    "text": "5.3 Reference and Resources\nmain - Functions (Ross)\naux - Functions (Sweigart) - Functions (Severance) - Fruitful Functions (Downey)",
    "crumbs": [
      "Basics with Python Programming",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PB/PB-Fn-Pack.html#footnotes",
    "href": "PB/PB-Fn-Pack.html#footnotes",
    "title": "5  Functions and Packages",
    "section": "",
    "text": "This course and materials are based on Python 3.11 (stable).↩︎\nSee the details about how the function in a class object works from the following section Classes and Methods.↩︎",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PB/PB-Fn-Pack.html#reference",
    "href": "PB/PB-Fn-Pack.html#reference",
    "title": "5  Functions and Packages",
    "section": "5.3 Reference",
    "text": "5.3 Reference\n\nhttps://infx511.github.io/functions.html\nhttps://www.w3schools.com/python/python_functions.asp",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PB/PB-Class-Method.html",
    "href": "PB/PB-Class-Method.html",
    "title": "6  Classes and Methods",
    "section": "",
    "text": "6.1 Classes\nThis section introduces classes and methods in python.\nFor example, a built-in function print() outputs text to the console (or to a specified file):\nPython is a language for object-oriented programming (OOP), allowing you to structure your code using classes and objects for better organization and reusability. It has advantages over other programming approaches:\nIn Python, a class is a blueprint for a type of objects, as it defines what an object should look like. And, an object is created based on that class as it inherits all the variables and functions defined inside that class.\nAlmost everything in Python is an object, with its properties and methods. You can create a class to store data attributes (also called the class properties) and/or methods, and use the class to handle objects of a type in a consistent and systematic way.\nFor example, you can define a class named MyCourse with an attribute named program, using class keyword:\n# Define a class\nclass MyCourse:\n    # data attribute\n    program = 'BUDA'          # class variable shared by all instances\nNow, you can create an object of the new class:\n# Create an object\nstudent_1 = MyCourse()\nprint(\"The program of student_1:\", student_1.program)\n\nThe program of student_1: BUDA\n# Add/modify an attribute and the value in the object \nstudent_1.course = \"BUDA 450\"    # a new attribute\nprint(\"The course code of student_1:\", student_1.course)\n\nThe course code of student_1: BUDA 450\nNow, you can create another object of the same class, which has the same attribute program:\n# Create another object\nstudent_2 = MyCourse()\nprint(\"The program of student_2:\", student_2.program)\n\nThe program of student_2: BUDA\nHowever, although their classes are the same, they are treated independently. So, this object student_2 doesn’t have the attribute course as it was added only to student_1. The following example returns an error message.\nprint(\"The course code of student_2:\", student_2.course)",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classes and Methods</span>"
    ]
  },
  {
    "objectID": "PB/PB-Class-Method.html#classes",
    "href": "PB/PB-Class-Method.html#classes",
    "title": "6  Classes and Methods",
    "section": "",
    "text": "Provides a clear structure to programs\nMakes code easier to maintain, reuse, and debug\nHelps keep your code DRY (Don’t Repeat Yourself)\nAllows you to build reusable applications with less code\n\n\n\n\n\nClass\nObjects\n\n\n\n\nFruit\nApple, Banana, Mango\n\n\nCar\nVolvo, Audi, Toyota\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.1.1 Method\nA method is a function that “belongs to” an object. So, a method is called on an object and is specific to the object’s type. To apply a method, you can call the method’s name (and arguments), following the name of the target object to call the method on and a period (dot) . , like object_name.method_name(arguments).\n\n# Define a class with method\nclass MyCourse:\n    # data attribute \n    program = 'BUDA'          # class variable shared by all instances\n    \n    # method\n    def add_course(self, course_code):\n        self.course = self.program + \" \" + course_code\n\nHere, self indicates the class object itself. That is, self.program call the program attribute of the object that is created through this class, locally within this class’ code block.\nAs a result, the function can utilize internally defined attribute that will be identically created in every MyCourse object.\nFor example, you can create two objects of MyCourse class, and use the same method with different arguments:\n\nstudent_3 = MyCourse()\nstudent_3.add_course(\"450\")\nprint(student_3.course)\n\nBUDA 450\n\n\n\nstudent_4 = MyCourse()\nstudent_4.add_course(\"455\")\nprint(student_4.course)\n\nBUDA 455\n\n\n\n6.1.1.1 The __init__() Method\nAlmost all classes have a built-in method called __init__(), which makes the classes much useful by having an initial setup for each object. The __init__() method is always executed when the class is being initiated — when an object of the class is created.\nFor example, the __init__() method can be used to assign initial values to object properties, or other operations that are necessary to do when the object is being created:\n\n# Define a class with __init__ method\nclass MyCourse_general:\n    def __init__(self, program):\n        self.program = program        # instance variable unique to each instance\n    \n    def add_course(self, course_code):\n        self.course = self.program + \" \" + course_code\n\nFor example, the MyCourse_general requires an argument for program attribute to initiate (i.e., create) an object. The following objects are created with different program names, while using the same method.\n\n# without the initial value, the object cannot be created\nstudent_5 = MyCourse_general(\"BUDA\")\nstudent_5.add_course(\"450\")\nprint(student_5.course)\n\nBUDA 450\n\n\n\nstudent_6 = MyCourse_general(\"MIST\")\nstudent_6.add_course(\"450\")\nprint(student_6.course)\n\nMIST 450",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classes and Methods</span>"
    ]
  },
  {
    "objectID": "BD/BD-Front.html",
    "href": "BD/BD-Front.html",
    "title": "Data Science with Python",
    "section": "",
    "text": "This chapter reviews fundamental skills for data science with Python.\n\nData Science Package - NumPy\nData Science Package - Pandas",
    "crumbs": [
      "Data Science with Python"
    ]
  },
  {
    "objectID": "BD/BD-Front.html#overview",
    "href": "BD/BD-Front.html#overview",
    "title": "Basics in Data Science with Python",
    "section": "",
    "text": "Data Science Package - NumPy\nData Science Package - Pandas",
    "crumbs": [
      "Data Science with Python"
    ]
  },
  {
    "objectID": "BD/BD-Front.html#related-reading",
    "href": "BD/BD-Front.html#related-reading",
    "title": "Basics in Data Science with Python",
    "section": "Related Reading",
    "text": "Related Reading\n\nChapters in the course textbook\n\nchapter 2 of Business Analytics - Communicating with numbers\n\nWebsites for R textbook\n\nSection 3.3, 3.4, 3.5 of An Introduction to R\nSections 7 of Beginning Computer Science with R",
    "crumbs": [
      "Basics in Data Science with Python"
    ]
  },
  {
    "objectID": "BD/BD-NumPy.html",
    "href": "BD/BD-NumPy.html",
    "title": "7  NumPy",
    "section": "",
    "text": "7.1 Creating ndarray\nThis section introduces NumPy, a core Python package widely used for numerical operations in data science and data mining.\nNumPy, which stands for numerical Python (hereafter, just numpy), is a package that supports numerical computations (even as a basis of computational operations for other advanced packages).\nThe basic data structure in numpy is a multi-dimensional array object called ndarray. Numpy provides a suite of functions that can efficiently manipulate elements of the ndarray.",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "BD/BD-NumPy.html#creating-ndarray",
    "href": "BD/BD-NumPy.html#creating-ndarray",
    "title": "7  NumPy",
    "section": "",
    "text": "7.1.1 From data objects\nAn ndarray can be created from a list. For example, a 1-dimensional numpy array (i.e., vector) can be defined in a oneDim_array object, using a list oneDim_list as follows.\n\n# import the package\nimport numpy as np\n\n# data from a list\noneDim_list = [1,2,3,4,5]\n\n# np array\noneDim_array = np.array(oneDim_list)        # a 1-dimensional array (vector)\n\nprint(oneDim_array)\nprint(type(oneDim_array))\n\n[1 2 3 4 5]\n&lt;class 'numpy.ndarray'&gt;\n\n\nThe basic information about the ndarray object can be retrieved from its attributes. Here are some attributes frequently used:\n\nprint(\"No. Dimensions    =\", oneDim_array.ndim)\nprint(\"Dimension         =\", oneDim_array.shape)\nprint(\"Size              =\", oneDim_array.size)\nprint(\"Array's data type =\", oneDim_array.dtype)\n\nNo. Dimensions    = 1\nDimension         = (5,)\nSize              = 5\nArray's data type = int64\n\n\nSimilarly, it is possible to create a multi-dimensional array, which can be created with a list of lists (a list of rows).\n\ntwoDim_list = [[1,2],[3,4],[5,6],[7,8]]          # a list of \"rows\"\ntwoDim_array = np.array(twoDim_list, dtype='f')  # a two-dimensional array (matrix) as a float type\n\nprint(twoDim_array)\n\nprint(\"No. Dimensions =\", twoDim_array.ndim)\nprint(\"Dimension      =\", twoDim_array.shape)\nprint(\"Size           =\", twoDim_array.size)\nprint(\"Array type     =\", twoDim_array.dtype)\n\n[[1. 2.]\n [3. 4.]\n [5. 6.]\n [7. 8.]]\nNo. Dimensions = 2\nDimension      = (4, 2)\nSize           = 8\nArray type     = float32\n\n\n\n\n\n7.1.2 From functions\nAn ndarray can be created as a result of the operation of a function in numpy. Here are some functions that output new 1-dim ndarray objects.\n\nprint('Array of integers between -10 and 10, with step size of 2')\nprint( np.arange(-10,10,2), '\\n')  # similar to range, but returns ndarray instead of list\n\nprint('Array of values between 0 and 1, split into 10 equally spaced values')\nprint( np.linspace(0,1,10), '\\n')  # split interval [0,1] into 10 equally separated values\n\nprint('Array of random numbers from a uniform distribution')\nprint( np.random.rand(5) )         # generating random numbers from a uniform distribution between [0,1]\n\nArray of integers between -10 and 10, with step size of 2\n[-10  -8  -6  -4  -2   0   2   4   6   8] \n\nArray of values between 0 and 1, split into 10 equally spaced values\n[0.         0.11111111 0.22222222 0.33333333 0.44444444 0.55555556\n 0.66666667 0.77777778 0.88888889 1.        ] \n\nArray of random numbers from a uniform distribution\n[0.76838823 0.68626965 0.56513746 0.0994116  0.11615344]\n\n\nAnd, here are some functions that output 2- or higher dimensional ndarray objects.\n\nprint('A 3 x 3 identity matrix:')\nprint( np.eye(3), '\\n')              # a 3 x 3 identity matrix\n\nprint('A 2 x 3 matrix of zeros:')\nprint( np.zeros([2,3]), '\\n')        # a matrix of zeros\n\nprint('A 3 x 2 x 3 tensor of ones:')\nprint( np.ones([3,2,3]))             # a 3rd rank tensor of ones\n\nA 3 x 3 identity matrix:\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]] \n\nA 2 x 3 matrix of zeros:\n[[0. 0. 0.]\n [0. 0. 0.]] \n\nA 3 x 2 x 3 tensor of ones:\n[[[1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]]]\n\n\n\n\n7.1.3 From data files\nLoading data from a text file is another way to create an ndarray. For that, you can use numpy.genfromtxt() that loads data by extracting each value distinguished by a delimiter from each line in a text file.\nQuite often, data are stored in a file formated with a single character that marks the separation between columns. For example, comma-separated values (CSV) files use a comma , or a semicolon ; as delimiter.\n\n# load data from a csv file\nfile_path_n_name = 'data_array.csv'\n\ndat = np.genfromtxt(file_path_n_name, delimiter=',')\nprint( dat )\n\n[[ 1.   2.   0.3]\n [ 3.   5.   0.1]\n [ 5.   9.  -0.1]\n [ 7.   nan -0.3]\n [ 9.  17.  -0.7]]\n\n\nHere, nan is a floating point representation of Not a Number in numpy.\nSimilarily, some numeric constants are considered with specific keywords:\n\nprint(\"The floating point representation of \")\nprint(\"   - Not a Number (NaN),    numpy.nan:  \", np.nan)\nprint(\"   - (positive) infinity,   numpy.inf:  \", np.inf)\nprint(\"   - Euler’s constant,      numpy.e:    \", np.e)\n\nThe floating point representation of \n   - Not a Number (NaN),    numpy.nan:   nan\n   - (positive) infinity,   numpy.inf:   inf\n   - Euler’s constant,      numpy.e:     2.718281828459045\n\n\n\n\n7.1.4 Reshaping an array\nYou can change the shape of an ndarray, using reshape():\n\nprint('Convert 1-dim into 2-dim array', '\\n')\noneDim_example = np.arange(12)\n\nprint('before reshape:')\nprint(oneDim_example, '\\n')\n\nprint('after reshape:')\nprint( np.reshape(oneDim_example, (3,4)) )   # reshape to a matrix  (no. rows, no. cols) \n\nConvert 1-dim into 2-dim array \n\nbefore reshape:\n[ 0  1  2  3  4  5  6  7  8  9 10 11] \n\nafter reshape:\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]]\n\n\n\n\n\n\n\n\nTipMethods in numpy\n\n\n\nUsing a method associated with ndarray, you can get the same result, but through a compact/intuitive code:\n\nprint('the classical function:')\nprint( np.reshape(oneDim_example, (3,4)), '\\n')  # using the reshape function\n\nprint('the method:')\nprint( oneDim_example.reshape(3,4) )             # using the reshape method\n\nthe classical function:\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]] \n\nthe method:\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]]\n\n\nCheck many methods available for the ndarray from its documentation.",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "BD/BD-NumPy.html#indexing-and-slicing",
    "href": "BD/BD-NumPy.html#indexing-and-slicing",
    "title": "7  NumPy",
    "section": "7.2 Indexing and Slicing",
    "text": "7.2 Indexing and Slicing\nThere are various ways to select and manage a subset of elements within a ndarray. To access elements of an ndarray, you can use indices (e.g., row or column numbers).\nThe following examples illustrate the indexing elements of 1-dim and 2-dim ndarrays.\n\n# 1-dim example\nmy1d_arr = np.array(\n    [0,1,2,3,4,5,6,7,8]\n)\nprint('my1d_arr[2]  =', my1d_arr[2])      # access the third element\nprint('my1d_arr[:2] =', my1d_arr[:2])    # access the first two elements\nprint('my1d_arr[2:] =', my1d_arr[2:])    # access all from the third element to the end\n\nmy1d_arr[2]  = 2\nmy1d_arr[:2] = [0 1]\nmy1d_arr[2:] = [2 3 4 5 6 7 8]\n\n\n\n# 2-dim example\nmy2d_arr = np.array(\n    [[1,2,3,4],\n     [5,6,7,8],\n     [9,10,11,12]]\n)\nprint('my2d_arr[2][:]  =', my2d_arr[2][:])       # access the third row\nprint('my2d_arr[:][2]  =', my2d_arr[:][2], '\\n') # access the third row (similar to 2d list)\n\nprint('my2d_arr[2,:]   =', my2d_arr[2,:])        # access the third row\nprint('my2d_arr[:,2]   =', my2d_arr[:,2])        # access the third column\nprint('my2d_arr[:2,2:] =\\n', my2d_arr[:2,2:])    # access the elements on the first two rows \n                                                 #  and the columns from the third to the end\n\nmy2d_arr[2][:]  = [ 9 10 11 12]\nmy2d_arr[:][2]  = [ 9 10 11 12] \n\nmy2d_arr[2,:]   = [ 9 10 11 12]\nmy2d_arr[:,2]   = [ 3  7 11]\nmy2d_arr[:2,2:] =\n [[3 4]\n [7 8]]\n\n\nAlso, indexing can be based on a list of direct element indices.\n\n# 1-dim example\nprint('my1d_arr =\\n', my1d_arr, '\\n')\n\nindices = [2,1,0,3]                                # element indices to be used for indexing\nprint('indices =\\n', indices, '\\n')\n\nprint('my1d_arr[indices] =\\n', my1d_arr[indices])  # this will shuffle the rows of my1d_arr\n\nmy1d_arr =\n [0 1 2 3 4 5 6 7 8] \n\nindices =\n [2, 1, 0, 3] \n\nmy1d_arr[indices] =\n [2 1 0 3]\n\n\n\n# 2-dim example\nprint('my2d_arr =\\n', my2d_arr, '\\n')\n\nrowIndex = [0,0,1,2,0]     # row index into my2d_arr\nprint('rowIndex =', rowIndex, '\\n')\n\ncolumnIndex = [0,2,0,1,2]  # column index into my2d_arr\nprint('columnIndex =', columnIndex, '\\n')\n\nprint('my2d_arr[rowIndex,columnIndex] =', my2d_arr[rowIndex,columnIndex])\n\nmy2d_arr =\n [[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]] \n\nrowIndex = [0, 0, 1, 2, 0] \n\ncolumnIndex = [0, 2, 0, 1, 2] \n\nmy2d_arr[rowIndex,columnIndex] = [ 1  3  5 10  3]\n\n\nBesides, ndarray supports Boolean (e.g., [True, False, True] to choose the 1st and 3rd in a list of three elements) indexing too.\n\n# 1-dim example\nprint('my1d_arr =\\n', my1d_arr, '\\n')\n\nmy1d_divBy3 = my1d_arr[my1d_arr % 3 == 0]\n\nprint('To return the elements of zero remainder:')\nprint('my1d_arr[ my1d_arr % 3 == 0 ] =\\n', my1d_divBy3)       # returns all the elements divisible by 3 in an ndarray\n\nmy1d_arr =\n [0 1 2 3 4 5 6 7 8] \n\nTo return the elements of zero remainder:\nmy1d_arr[ my1d_arr % 3 == 0 ] =\n [0 3 6]\n\n\n\n# 2-dim example\nprint('my2d_arr =\\n', my2d_arr)\n\nmy2d_divBy3 = my2d_arr[my2d_arr % 3 == 0]\nprint('\\nmy2d_arr[my2d_arr % 3 == 0]          =', my2d_divBy3)         # returns all the elements divisible by 3 in an ndarray\n\nmy2d_divBy3LastRow = my2d_arr[2:, my2d_arr[2,:] % 3 == 0]\nprint('\\nmy2d_arr[2:, my2d_arr[2,:] % 3 == 0] =', my2d_divBy3LastRow)   # returns elements in the last row divisible by 3\n\nmy2d_arr =\n [[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\nmy2d_arr[my2d_arr % 3 == 0]          = [ 3  6  9 12]\n\nmy2d_arr[2:, my2d_arr[2,:] % 3 == 0] = [[ 9 12]]\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAssigning an array (or a subset of its elements) to another variable will simply pass a reference to the array instead of copying its values. Therefore, when the modification of the values in the new variable (e.g., y in the following example) is linked to the modification of the values in the original variable (e.g., x).\n\nx = np.arange(-5,5)\nprint('Given x =', x)\n\ny = x[3:5]                    # y is a slice, i.e., pointer to a subarray in x\nprint('      y =', y, '\\n')\n\nprint('Modification in Y')\ny[:] = 777                    # assigning new values in y\nprint('  new y =', y)\nprint('      x =', x, '\\n')   # the new values in y will change x\n\nGiven x = [-5 -4 -3 -2 -1  0  1  2  3  4]\n      y = [-2 -1] \n\nModification in Y\n  new y = [777 777]\n      x = [ -5  -4  -3 777 777   0   1   2   3   4] \n\n\n\nTo create an ndarray that is independent of the orignial reference, you need to make a copy by explicitly calling the copy() function.\n\nz = x[3:5].copy()   # makes a copy of the subarray\nprint('Before: x =', x)\nprint('        z =', z, '\\n')\n\nz[:] = 500          # modifying the value of z will not affect x\nprint('After : z =', z)\nprint('        x =', x)\n\nBefore: x = [ -5  -4  -3 777 777   0   1   2   3   4]\n        z = [777 777] \n\nAfter : z = [500 500]\n        x = [ -5  -4  -3 777 777   0   1   2   3   4]",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "BD/BD-NumPy.html#element-wise-operations",
    "href": "BD/BD-NumPy.html#element-wise-operations",
    "title": "7  NumPy",
    "section": "7.3 Element-wise Operations",
    "text": "7.3 Element-wise Operations\nYou can apply standard arithmetic operators such as addition and multiplication on each element of the ndarray.\n\nx = np.array([1,2,3,4,5], dtype='f')\n\nprint('x      =', x, '\\n')\n\nprint('x + 1  =', x + 1)       # addition\nprint('x - 1  =', x - 1)       # subtraction\nprint('x * 2  =', x * 2)       # multiplication\nprint('x / 2  =', x / 2, '\\n') # division\n\nprint('x ** 2 =', x ** 2)      # square\nprint('x // 2 =', x // 2)      # integer division\nprint('x % 2  =', x % 2)       # modulo  \n\nx      = [1. 2. 3. 4. 5.] \n\nx + 1  = [2. 3. 4. 5. 6.]\nx - 1  = [0. 1. 2. 3. 4.]\nx * 2  = [ 2.  4.  6.  8. 10.]\nx / 2  = [0.5 1.  1.5 2.  2.5] \n\nx ** 2 = [ 1.  4.  9. 16. 25.]\nx // 2 = [0. 1. 1. 2. 2.]\nx % 2  = [1. 0. 1. 0. 1.]\n\n\nSuch operators can be applied to the operation between two ndarray objects when they have the same shape.\n\nx = np.array([2,4,6,8,10])\ny = np.array([1,2,3,3,3])\n\nprint('x      =', x)\nprint('y      =', y, '\\n')\n\nprint('x + y  =', x + y)       # element-wise addition\nprint('x - y  =', x - y)       # element-wise subtraction\nprint('x * y  =', x * y)       # element-wise multiplication \nprint('x / y  =', x / y, '\\n') # element-wise division\n\nprint('x ** y =', x ** y)      # element-wise exponentiation\nprint('x // y =', x // y)      # element-wise integer division\nprint('x % y  =', x % y)       # element-wise modulo operation \n\nx      = [ 2  4  6  8 10]\ny      = [1 2 3 3 3] \n\nx + y  = [ 3  6  9 11 13]\nx - y  = [1 2 3 5 7]\nx * y  = [ 2  8 18 24 30]\nx / y  = [2.         2.         2.         2.66666667 3.33333333] \n\nx ** y = [   2   16  216  512 1000]\nx // y = [2 2 2 2 3]\nx % y  = [0 0 0 2 1]",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "BD/BD-NumPy.html#reference",
    "href": "BD/BD-NumPy.html#reference",
    "title": "7  NumPy",
    "section": "7.6 Reference",
    "text": "7.6 Reference\n\nhttps://numpy.org/doc/stable/index.html\nhttps://www.w3schools.com/python/numpy/default.asp\nhttp://www.cse.msu.edu/~ptan/dmbook/tutorials/tutorial2/tutorial2.ipynb",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "BD/BD-NumPy.html#arithmetics-and-statistics",
    "href": "BD/BD-NumPy.html#arithmetics-and-statistics",
    "title": "7  NumPy",
    "section": "7.4 Arithmetics and Statistics",
    "text": "7.4 Arithmetics and Statistics\nnumpy provides various built-in mathematical functions available for manipulating elements of an ndarray.\nFirst, there are functions that return a single-value answer from the operation with the values in a ndarray:\n\nx = np.array([-1.452, 0.410, -3.287, 2.539])    \nprint('x          =', x, '\\n')\n\nprint(\"np.min(x)  =\", np.min(x))   # min \nprint(\"np.max(x)  =\", np.max(x))   # max \nprint(\"np.sum(x)  =\", np.sum(x))   # sum \nprint(\"np.mean(x) =\", np.mean(x))  # mean/average\nprint(\"np.std(x)  =\", np.std(x))   # standard deviation\n\nx          = [-1.452  0.41  -3.287  2.539] \n\nnp.min(x)  = -3.287\nnp.max(x)  = 2.539\nnp.sum(x)  = -1.7899999999999996\nnp.mean(x) = -0.4474999999999999\nnp.std(x)  = 2.163692965741674\n\n\nAlso, some other functions return an array of the same shape, applying element-wise operations:\n\nprint('x               =', x, '\\n')\n\nprint('np.sign(x)      =', np.sign(x))          # the sign of each element\nprint('np.abs(x)       =', np.abs(x))           # the absolute value of each element\nprint('np.sqrt(abs(x)) =', np.sqrt(abs(x)))     # the square root of each element\nprint('np.exp(x)       =', np.exp(x))           # the exponentiation\nprint('np.log(x)       =', np.log(abs(x)))      # the natural logarithm\nprint('np.sort(x)      =', np.sort(x))          # the sorting array\n\nx               = [-1.452  0.41  -3.287  2.539] \n\nnp.sign(x)      = [-1.  1. -1.  1.]\nnp.abs(x)       = [1.452 0.41  3.287 2.539]\nnp.sqrt(abs(x)) = [1.20498963 0.64031242 1.81300855 1.59342399]\nnp.exp(x)       = [ 0.23410162  1.50681779  0.03736578 12.66699764]\nnp.log(x)       = [ 0.37294192 -0.89159812  1.18997529  0.9317703 ]\nnp.sort(x)      = [-3.287 -1.452  0.41   2.539]\n\n\nIn addition, functions for many other mathematical operations are available:\n\ny = np.arange(2,6)\nprint('x                    =', x)\nprint('y                    =', y, '\\n')\n\nprint('np.add(x,y)          =', np.add(x,y))          # element-wise addition              x + y\nprint('np.subtract(x,y)     =', np.subtract(x,y))     # element-wise subtraction           x - y\nprint('np.multiply(x,y)     =', np.multiply(x,y))     # element-wise multiplication        x * y\nprint('np.divide(x,y)       =', np.divide(x,y), '\\n') # element-wise division        x / y\n\nprint('np.floor_divide(x,y) =', np.floor_divide(x,y)) # element-wise integer division      x // y\nprint('np.mod(x,y)          =', np.mod(x,y))          # element-wise division              x % y\nprint('np.power(x,y)        =', np.power(x,y), '\\n')  # element-wise exponentiation  x ** y\n\nprint('np.maximum(x,y)      =', np.maximum(x,y))      # element-wise maximum               max(x,y)\nprint('np.minimum(x,y)      =', np.minimum(x,y))      # element-wise minimum               min(x,y)\n\nx                    = [-1.452  0.41  -3.287  2.539]\ny                    = [2 3 4 5] \n\nnp.add(x,y)          = [0.548 3.41  0.713 7.539]\nnp.subtract(x,y)     = [-3.452 -2.59  -7.287 -2.461]\nnp.multiply(x,y)     = [ -2.904   1.23  -13.148  12.695]\nnp.divide(x,y)       = [-0.726       0.13666667 -0.82175     0.5078    ] \n\nnp.floor_divide(x,y) = [-1.  0. -1.  0.]\nnp.mod(x,y)          = [0.548 0.41  0.713 2.539]\nnp.power(x,y)        = [2.10830400e+00 6.89210000e-02 1.16734389e+02 1.05514830e+02] \n\nnp.maximum(x,y)      = [2. 3. 4. 5.]\nnp.minimum(x,y)      = [-1.452  0.41  -3.287  2.539]",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "BD/BD-NumPy.html#linear-algebra",
    "href": "BD/BD-NumPy.html#linear-algebra",
    "title": "7  NumPy",
    "section": "7.5 Linear algebra",
    "text": "7.5 Linear algebra\nNumpy provides many functions to support linear algebra operations.\n\nX = np.random.randn(2,3)                       # create a 2 x 3 random matrix\nprint('X =\\n', X, '\\n')\nprint('Transpose of X, X.T =\\n', X.T, '\\n')    # matrix transpose operation X^T\n\ny = np.random.randn(3) # random vector \nprint('y =', y, '\\n')\n\nprint('Matrix-vector multiplication')\nprint('X.dot(y) =\\n', X.dot(y), '\\n')          # matrix-vector multiplication  X * y\n\nprint('Matrix-matrix product')\nprint('X.dot(X.T) =', X.dot(X.T))              # matrix-matrix multiplication  X * X^T\nprint('\\nX.T.dot(X) =\\n', X.T.dot(X))          # matrix-matrix multiplication  X^T * X\n\nX =\n [[ 0.03797097 -0.48738399 -0.4394936 ]\n [-0.1674173   0.01069525 -0.65663002]] \n\nTranspose of X, X.T =\n [[ 0.03797097 -0.1674173 ]\n [-0.48738399  0.01069525]\n [-0.4394936  -0.65663002]] \n\ny = [-0.59878877 -0.05819147 -2.04791673] \n\nMatrix-vector multiplication\nX.dot(y) =\n [0.9056713  1.44434883] \n\nMatrix-matrix product\nX.dot(X.T) = [[0.43213957 0.277015  ]\n [0.277015   0.45930593]]\n\nX.T.dot(X) =\n [[ 0.02947035 -0.02029701  0.09324323]\n [-0.02029701  0.23765754  0.20717932]\n [ 0.09324323  0.20717932  0.62431761]]\n\n\n\nX = np.random.randn(5,3)\nprint('X =\\n', X, '\\n')\n\nC = X.T.dot(X)               # C = X^T * X is a square matrix\nprint('C = X.T.dot(X) =\\n', C, '\\n')\n\ninvC = np.linalg.inv(C)      # inverse of a square matrix\nprint('Inverse of C = np.linalg.inv(C)\\n', invC, '\\n')\n\ndetC = np.linalg.det(C)      # determinant of a square matrix\nprint('Determinant of C = np.linalg.det(C) =', detC)\n\nS, U = np.linalg.eig(C)      # eigenvalue S and eigenvector U of a square matrix\nprint('Eigenvalues of C =\\n', S)\nprint('Eigenvectors of C =\\n', U)\n\nX =\n [[-1.1138295  -0.35104868 -0.25797733]\n [-1.72524254 -0.76359384  0.35377316]\n [-0.82874858  0.43061817 -1.48961301]\n [ 0.5396747   1.12815342 -0.17084753]\n [ 0.09204966  0.119836   -0.99899071]] \n\nC = X.T.dot(X) =\n [[ 5.20362412  1.97138548  0.72735408]\n [ 1.97138548  2.17883355 -1.13348811]\n [ 0.72735408 -1.13348811  3.43782599]] \n\nInverse of C = np.linalg.inv(C)\n [[ 0.42715254 -0.52324808 -0.26289481]\n [-0.52324808  1.19494475  0.50469171]\n [-0.26289481  0.50469171  0.51290544]] \n\nDeterminant of C = np.linalg.det(C) = 14.52796063661525\nEigenvalues of C =\n [0.57911694 6.18546427 4.05570245]\nEigenvectors of C =\n [[-0.41074395  0.90243605  0.12999456]\n [ 0.80692426  0.4261809  -0.40895363]\n [ 0.4244557   0.06307947  0.90324877]]",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "BD/BD-Pandas.html",
    "href": "BD/BD-Pandas.html",
    "title": "8  Pandas",
    "section": "",
    "text": "8.1 Series\nThis section introduces Pandas, a powerful Python package for data manipulation and analysis, providing flexible data structures and tools for handling structured datasets.\nPandas is a Python package that provides powerful and flexible data structures for data analysis and manipulation. Particularly, two main structures, Series and DataFrame, in Pandas are designed to make working with structured data intuitive and efficient.\nA Series object consists of a one-dimensional array (i.e., vector) of values, whose elements can be referenced using an index array.",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "BD/BD-Pandas.html#series",
    "href": "BD/BD-Pandas.html#series",
    "title": "8  Pandas",
    "section": "",
    "text": "8.1.1 Creating Series\nYou can create a Series object from a list, a numpy array, or a Python dictionary.\nFor example, the following shows how to create a Series object with a list.\n\nimport numpy as np   # for later usages\nimport pandas as pd \n\n# creating a series from a list\nlist_data = [3.1, 2.9, -1.7, -0.2, 2.9, 4.5]\nsr = pd.Series(list_data)  \nprint('sr =\\n', sr, '\\n', sep=\"\")\n\nprint('sr.values =', sr.values)                   # display values of the Series\nprint('sr.index  =', sr.index)                     # display indices of the Series\nprint('sr.dtype  =', sr.dtype)                     # display the element type of the Series\n\nsr =\n0    3.1\n1    2.9\n2   -1.7\n3   -0.2\n4    2.9\n5    4.5\ndtype: float64\n\nsr.values = [ 3.1  2.9 -1.7 -0.2  2.9  4.5]\nsr.index  = RangeIndex(start=0, stop=6, step=1)\nsr.dtype  = float64\n\n\nEach element in a Series is automatically labeled with numeric indices in an ascending order, if no index data were provided. When creating a Series, you can manually set the labels with your labels (e.g., in a list) for the argument index:\n\n# assign indexes\nlist_index = ['Record2', 'Record3', 'Record4', 'Record5', 'Record6', 'Record7']\nprint('list_index =\\n', list_index, '\\n', sep=\"\")\n\nsr_labeled = pd.Series(list_data, index = list_index)\nprint('sr_labeled =\\n', sr_labeled, '\\n', sep=\"\")\n\nlist_index =\n['Record2', 'Record3', 'Record4', 'Record5', 'Record6', 'Record7']\n\nsr_labeled =\nRecord2    3.1\nRecord3    2.9\nRecord4   -1.7\nRecord5   -0.2\nRecord6    2.9\nRecord7    4.5\ndtype: float64\n\n\n\nAlternatively, you can assign (overwrite) new index data, accessing the Series’s index attribute:\n\nlist_index_new = ['Rec0', 'Rec1', 'Rec2', 'Rec3', 'Rec4', 'Rec5']\nprint('list_index_new =\\n', list_index_new, '\\n', sep=\"\")\n\nsr_labeled.index = list_index_new                       # assign a new list\nprint('sr_labeled =\\n', sr_labeled, '\\n', sep=\"\")\n\nlist_index_new =\n['Rec0', 'Rec1', 'Rec2', 'Rec3', 'Rec4', 'Rec5']\n\nsr_labeled =\nRec0    3.1\nRec1    2.9\nRec2   -1.7\nRec3   -0.2\nRec4    2.9\nRec5    4.5\ndtype: float64\n\n\n\nA Series object can be created with a numpy object assigning indexes together. For example, when a data array np.arange(3,7) is given with indexes ['a', 'b', 'c', 'd']:\n\n# creating a series from a numpy ndarray\narr_data = np.arange(3,7)\narr_index = ['a', 'b', 'c', 'd']\nsr_arr = pd.Series(arr_data, index=arr_index) \nprint('sr_arr =\\n', sr_arr, '\\n', sep=\"\")\n\nsr_arr =\na    3\nb    4\nc    5\nd    6\ndtype: int64\n\n\n\nAnother way is with a dictionary—the key becomes the index while the the value of the key is taken as the corresponding element’s value. For example, a Series object can be defined from a dictionary {'MI': 'Lansing', 'CA': 'Sacramento', 'TX': 'Austin', 'MN': 'St Paul'}:\n\n# creating a series from a dictionary \ndict_data = {'MI': 'Lansing', 'CA': 'Sacramento', 'TX': 'Austin', 'MN': 'St Paul'}\nsr_dict = pd.Series(dict_data)                \nprint('sr_dict =\\n', sr_dict, '\\n', sep=\"\")\n\nsr_dict =\nMI       Lansing\nCA    Sacramento\nTX        Austin\nMN       St Paul\ndtype: object\n\n\n\n\n\n\n\n\n\nCautionExercise\n\n\n\nCreate a Series object from a numpy object np.arange(3,7) with index ['a', 'b', 'c', 'd']\n\n\nShow the code\narr_data = np.arange(3,7)\narr_index = ['a', 'b', 'c', 'd']\nsr_arr = pd.Series(arr_data, index=arr_index) \nprint('sr_arr =\\n', sr_arr, '\\n', sep=\"\")\n\n\nsr_arr =\na    3\nb    4\nc    5\nd    6\ndtype: int64\n\n\n\nCreate a Series object from a dictionary {'MI': 'Lansing', 'CA': 'Sacramento', 'TX': 'Austin', 'MN': 'St Paul'}.\n\n\nShow the code\ndict_data = {'MI': 'Lansing', 'CA': 'Sacramento', 'TX': 'Austin', 'MN': 'St Paul'}\nsr_dict = pd.Series(dict_data)                # creating a series from dictionary object\nprint('sr_dict =\\n', sr_dict, '\\n', sep=\"\")\n\n\nsr_dict =\nMI       Lansing\nCA    Sacramento\nTX        Austin\nMN       St Paul\ndtype: object\n\n\n\n\n\n\n\n8.1.2 Indexing and Slicing\nTwo typical indexing methods for the value of an element in a Series are based on either the label or the integer index of element(s):\n\nusing .loc[] with a group of rows and columns by labels or boolean array (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)\nusing .iloc[] with a group of rows and columns by integer indexes (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)\n\n\n# Access elements based on labels or a boolean array\nprint(sr_labeled.loc['Rec3'])\nprint(sr_labeled.loc[sr_labeled == -0.2])\n\n-0.2\nRec3   -0.2\ndtype: float64\n\n\n\n# Access elements purely based on integer index (i.e., location)\nprint(\"The 4th element:  \", sr_labeled.iloc[3], \"\\n\")\nprint(\"All the elements from the 4th: \\n\", sr_labeled.iloc[3:], sep=\"\")\n\nThe 4th element:   -0.2 \n\nAll the elements from the 4th: \nRec3   -0.2\nRec4    2.9\nRec5    4.5\ndtype: float64\n\n\n\n\n8.1.3 Numeric Operations\nScalar operations can be performed on elements of a numeric Series.\n\nprint('sr      =\\n', sr, '\\n', sep=\"\")\n\nprint('sr + 1  =\\n', sr + 1, '\\n', sep=\"\")      # addition\nprint('sr - 1  =\\n', sr - 1, '\\n', sep=\"\")      # subtraction\nprint('sr * 2  =\\n', sr * 2, '\\n', sep=\"\")      # multiplication\nprint('1 / sr  =\\n', 1 / sr, '\\n', sep=\"\")      # division\nprint('sr // 2 =\\n', sr // 2, '\\n', sep=\"\")     # integer division\nprint('sr ** 2 =\\n', sr ** 2, '\\n', sep=\"\")     # square\nprint('sr % 2  =\\n', sr % 2, '\\n', sep=\"\")      # modulo  \n\nsr      =\n0    3.1\n1    2.9\n2   -1.7\n3   -0.2\n4    2.9\n5    4.5\ndtype: float64\n\nsr + 1  =\n0    4.1\n1    3.9\n2   -0.7\n3    0.8\n4    3.9\n5    5.5\ndtype: float64\n\nsr - 1  =\n0    2.1\n1    1.9\n2   -2.7\n3   -1.2\n4    1.9\n5    3.5\ndtype: float64\n\nsr * 2  =\n0    6.2\n1    5.8\n2   -3.4\n3   -0.4\n4    5.8\n5    9.0\ndtype: float64\n\n1 / sr  =\n0    0.322581\n1    0.344828\n2   -0.588235\n3   -5.000000\n4    0.344828\n5    0.222222\ndtype: float64\n\nsr // 2 =\n0    1.0\n1    1.0\n2   -1.0\n3   -1.0\n4    1.0\n5    2.0\ndtype: float64\n\nsr ** 2 =\n0     9.61\n1     8.41\n2     2.89\n3     0.04\n4     8.41\n5    20.25\ndtype: float64\n\nsr % 2  =\n0    1.1\n1    0.9\n2    0.3\n3    1.8\n4    0.9\n5    0.5\ndtype: float64\n\n\n\nYou can apply most of operations/functions for NumPy’s ndarray on the Series object, because Series of Pandas is built on top of ndarray and support many similar operations.\n\n# applying numpy functions that returns a single value\nprint(\"np.min(sr)  =\", np.min(sr))   # min \nprint(\"np.max(sr)  =\", np.max(sr))   # max \nprint(\"np.mean(sr) =\", np.mean(sr))  # mean/average\nprint(\"np.std(sr)  =\", np.std(sr))   # standard deviation\nprint(\"np.sum(sr)  =\", np.sum(sr))   # sum \n\nnp.min(sr)  = -1.7\nnp.max(sr)  = 4.5\nnp.mean(sr) = 1.9166666666666667\nnp.std(sr)  = 2.1435303175421203\nnp.sum(sr)  = 11.5\n\n\n\n# applying numpy functions that returns element-wise operation outcomes\nprint('np.sign(sr)      =\\n', np.sign(sr))          # the sign of each element\nprint('np.abs(sr)       =\\n', np.abs(sr))           # the absolute value of each element\nprint('np.sqrt(abs(sr)) =\\n', np.sqrt(abs(sr)))     # the square root of each element\nprint('np.exp(sr)       =\\n', np.exp(sr))           # the exponentiation\nprint('np.log(sr)       =\\n', np.log(abs(sr)))      # the natural logarithm\nprint('np.sort(sr)      =\\n', np.sort(sr))          # the sorting array\n\nnp.sign(sr)      =\n 0    1.0\n1    1.0\n2   -1.0\n3   -1.0\n4    1.0\n5    1.0\ndtype: float64\nnp.abs(sr)       =\n 0    3.1\n1    2.9\n2    1.7\n3    0.2\n4    2.9\n5    4.5\ndtype: float64\nnp.sqrt(abs(sr)) =\n 0    1.760682\n1    1.702939\n2    1.303840\n3    0.447214\n4    1.702939\n5    2.121320\ndtype: float64\nnp.exp(sr)       =\n 0    22.197951\n1    18.174145\n2     0.182684\n3     0.818731\n4    18.174145\n5    90.017131\ndtype: float64\nnp.log(sr)       =\n 0    1.131402\n1    1.064711\n2    0.530628\n3   -1.609438\n4    1.064711\n5    1.504077\ndtype: float64\nnp.sort(sr)      =\n [-1.7 -0.2  2.9  2.9  3.1  4.5]\n\n\n\n# applying numpy functions to multiple numeric Series'\nss = pd.Series([1,3,5,7,7])\n\nprint('np.add(sr,ss)          =\\n', np.add(sr,ss))          # element-wise addition  \nprint('np.subtract(sr,ss)     =\\n', np.subtract(sr,ss))     # element-wise subtraction \nprint('np.multiply(sr,ss)     =\\n', np.multiply(sr,ss))     # element-wise multiplication\nprint('np.divide(sr,ss)       =\\n', np.divide(sr,ss))       # element-wise division\n\nprint('np.floor_divide(sr,ss) =\\n', np.floor_divide(sr,ss)) # element-wise integer division \nprint('np.mod(sr,ss)          =\\n', np.mod(sr,ss))          # element-wise division \nprint('np.power(sr,ss)        =\\n', np.power(sr,ss))        # element-wise exponentiation \n\nprint('np.maximum(sr,ss)      =\\n', np.maximum(sr,ss))      # element-wise maximum \nprint('np.minimum(sr,ss)      =\\n', np.minimum(sr,ss))      # element-wise minimum \n\nnp.add(sr,ss)          =\n 0    4.1\n1    5.9\n2    3.3\n3    6.8\n4    9.9\n5    NaN\ndtype: float64\nnp.subtract(sr,ss)     =\n 0    2.1\n1   -0.1\n2   -6.7\n3   -7.2\n4   -4.1\n5    NaN\ndtype: float64\nnp.multiply(sr,ss)     =\n 0     3.1\n1     8.7\n2    -8.5\n3    -1.4\n4    20.3\n5     NaN\ndtype: float64\nnp.divide(sr,ss)       =\n 0    3.100000\n1    0.966667\n2   -0.340000\n3   -0.028571\n4    0.414286\n5         NaN\ndtype: float64\nnp.floor_divide(sr,ss) =\n 0    3.0\n1    0.0\n2   -1.0\n3   -1.0\n4    0.0\n5    NaN\ndtype: float64\nnp.mod(sr,ss)          =\n 0    0.1\n1    2.9\n2    3.3\n3    6.8\n4    2.9\n5    NaN\ndtype: float64\nnp.power(sr,ss)        =\n 0       3.100000\n1      24.389000\n2     -14.198570\n3      -0.000013\n4    1724.987631\n5            NaN\ndtype: float64\nnp.maximum(sr,ss)      =\n 0    3.1\n1    3.0\n2    5.0\n3    7.0\n4    7.0\n5    NaN\ndtype: float64\nnp.minimum(sr,ss)      =\n 0    1.0\n1    2.9\n2   -1.7\n3   -0.2\n4    2.9\n5    NaN\ndtype: float64",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "BD/BD-Pandas.html#dataframe",
    "href": "BD/BD-Pandas.html#dataframe",
    "title": "8  Pandas",
    "section": "8.2 DataFrame",
    "text": "8.2 DataFrame\nA DataFrame object is a tabular, spreadsheet-like data structure containing a collection of columns, each of which can be of different types (numeric, string, boolean, etc). Unlike Series, a DataFrame has distinct row and column indices.\nThere are many ways to create a DataFrame object (e.g., from a dictionary, list of tuples, or even numpy’s ndarrays).\n\n# creating a DataFrame from a dictionary\ncars = {\n    'make': ['Ford', 'Honda', 'Toyota', 'Tesla'],\n    'model': ['Taurus', 'Accord', 'Camry', 'Model S'],\n    'MSRP': [27595, 23570, 23495, 68000],\n}\ndf_car = pd.DataFrame(cars, index=['A','B','C','D'])\n\nprint('df_car =\\n', df_car, \"\\n\", sep=\"\")\n\nprint('df_car.values =\\n', df_car.values, \"\\n\", sep=\"\")  # the values \nprint('df_car.shape =\\n', df_car.shape, \"\\n\", sep=\"\")    # the shape (# rows, # cols)\nprint('df_car.size  =\\n', df_car.size, \"\\n\", sep=\"\")     # the number of all elements\n\nprint('df_car.index   =\\n', df_car.index, \"\\n\", sep=\"\")  # the row indices\nprint('df_car.columns =\\n', df_car.columns)              # the column labels\n\ndf_car =\n     make    model   MSRP\nA    Ford   Taurus  27595\nB   Honda   Accord  23570\nC  Toyota    Camry  23495\nD   Tesla  Model S  68000\n\ndf_car.values =\n[['Ford' 'Taurus' 27595]\n ['Honda' 'Accord' 23570]\n ['Toyota' 'Camry' 23495]\n ['Tesla' 'Model S' 68000]]\n\ndf_car.shape =\n(4, 3)\n\ndf_car.size  =\n12\n\ndf_car.index   =\nIndex(['A', 'B', 'C', 'D'], dtype='object')\n\ndf_car.columns =\n Index(['make', 'model', 'MSRP'], dtype='object')\n\n\n\n# Creating a DataFrame from a numpy ndarray\nnpdata = np.random.randn(4,3)       # create a 5 by 3 random matrix\ncolumnNames = ['x1','x2','x3']\ndf_rnd = pd.DataFrame(npdata, columns=columnNames)\nprint(df_rnd)\n\n         x1        x2        x3\n0 -0.435293 -0.242869 -0.256680\n1  0.550448  0.558670 -0.544197\n2  1.047401 -0.668058 -0.109651\n3  1.416808 -0.753351 -0.260208\n\n\n\n\n# Creating a DataFrame from a data file\nfile_path_n_name = 'data_header.csv'\nrowNames = [\"Rec0\", \"Rec1\", \"Rec2\", \"Rec3\"]\ndf_csv = pd.read_csv(file_path_n_name)\nprint(df_csv)\n\n   Col0  Col1  Col2\n0     1   2.0   0.3\n1     3   5.0   0.1\n2     5   9.0  -0.1\n3     7   NaN  -0.3\n4     9  17.0  -0.7\n\n\n\n8.2.1 Inserting/Modifying Columns\n\ncarData2 = pd.DataFrame(cars, index = [1,2,3,4])  # change the row index\ncarData2['year'] = 2018    # add column with same value\ncarData2['dealership'] = ['Courtesy Ford','Capital Honda','Spartan Toyota','N/A']\ncarData2                   # display table\n\n\n\n\n\n\n\n\nmake\nmodel\nMSRP\nyear\ndealership\n\n\n\n\n1\nFord\nTaurus\n27595\n2018\nCourtesy Ford\n\n\n2\nHonda\nAccord\n23570\n2018\nCapital Honda\n\n\n3\nToyota\nCamry\n23495\n2018\nSpartan Toyota\n\n\n4\nTesla\nModel S\n68000\n2018\nN/A\n\n\n\n\n\n\n\n\n\n8.2.2 Indexing and Slicing\nThe ways for indexing and slicing data are similar with those for Series to access elements of a DataFrame object.\n\n# accessing an entire column\nprint(df_car['make'], \"\\n\")           # using column's label\nprint(type(df_car['make']), \"\\n\")\n\n# print(df_car.make, \"\\n\")            # column's label as attribute\n# print(df_car.loc[:,'make'], \"\\n\")   # using column's label, selecting all rows\n# print(df_car.iloc[:,0])             # using column's index, selecting all rows\n\nA      Ford\nB     Honda\nC    Toyota\nD     Tesla\nName: make, dtype: object \n\n&lt;class 'pandas.core.series.Series'&gt; \n\n\n\n\n# accessing an entire row\nprint(df_car.loc['B'], \"\\n\")          # using only row's label\n\n# print(df_car.iloc[2], \"\\n\")         # using only row's index\n# print(df_car.loc['B',:], \"\\n\")      # using row's label, selecting all columns\n# print(df_car.iloc[2,:])             # using row's index, selecting all columns\n\nmake      Honda\nmodel    Accord\nMSRP      23570\nName: B, dtype: object \n\n\n\n\n# accessing a specific element of the DataFrame\nprint('df_car.loc[\\'A\\',\\'model\\'] =', df_car.loc['A','model'])    # retrieving from 2nd row, column named 'model'\nprint('df_car.iloc[1,2]      =', df_car.iloc[1,1], '\\n')           # retrieving from 2nd row, 2nd column\n\n# accessing a slice of the DataFrame\nprint('df_car.iloc[1:3,1:3] =\\n', df_car.iloc[1:3,1:3], \"\\n\", sep=\"\")\n\n# selection and filtering\nprint('df_car[df_car.MSRP &gt; 25000] =\\n', df_car[df_car.MSRP &gt; 25000], sep=\"\")  \n\ndf_car.loc['A','model'] = Taurus\ndf_car.iloc[1,2]      = Accord \n\ndf_car.iloc[1:3,1:3] =\n    model   MSRP\nB  Accord  23570\nC   Camry  23495\n\ndf_car[df_car.MSRP &gt; 25000] =\n    make    model   MSRP\nA   Ford   Taurus  27595\nD  Tesla  Model S  68000\n\n\n\n\n8.2.3 Basic Operations\nThere are many useful functions/methods are available in Pandas for DataFrame (and Series), which can help us easily handle data. Here are some basic, essential functions.\n\n# Checking data by viewing a small sample of a Series or DataFrame object\nprint(\"df_car.head() =\\n\", df_car.head(), \"\\n\")   # for the first few\nprint(\"df_car.tail() =\\n\", df_car.tail(), \"\\n\")   # for the last few\n\n# Descrbing data with descriptive statistics\nprint('df_car.describe() =\\n', df_car.describe(), '\\n', sep=\"\")   \n\n# Tabulate the counts of each discrete value\nprint('df_car.value_counts() =\\n', df_car.value_counts(), \"\\n\", sep=\"\")\n\n# Converting the data into other type\nprint(\"df_car.to_numpy() =\\n\", df_car.to_numpy(), \"\\n\")   # ndarray\nprint(\"df_car.to_dict() =\\n\", df_car.to_dict(), \"\\n\")     # dictionary\n\ndf_car.head() =\n      make    model   MSRP\nA    Ford   Taurus  27595\nB   Honda   Accord  23570\nC  Toyota    Camry  23495\nD   Tesla  Model S  68000 \n\ndf_car.tail() =\n      make    model   MSRP\nA    Ford   Taurus  27595\nB   Honda   Accord  23570\nC  Toyota    Camry  23495\nD   Tesla  Model S  68000 \n\ndf_car.describe() =\n               MSRP\ncount      4.000000\nmean   35665.000000\nstd    21641.588435\nmin    23495.000000\n25%    23551.250000\n50%    25582.500000\n75%    37696.250000\nmax    68000.000000\n\ndf_car.value_counts() =\nmake    model    MSRP \nFord    Taurus   27595    1\nHonda   Accord   23570    1\nTesla   Model S  68000    1\nToyota  Camry    23495    1\nName: count, dtype: int64\n\ndf_car.to_numpy() =\n [['Ford' 'Taurus' 27595]\n ['Honda' 'Accord' 23570]\n ['Toyota' 'Camry' 23495]\n ['Tesla' 'Model S' 68000]] \n\ndf_car.to_dict() =\n {'make': {'A': 'Ford', 'B': 'Honda', 'C': 'Toyota', 'D': 'Tesla'}, 'model': {'A': 'Taurus', 'B': 'Accord', 'C': 'Camry', 'D': 'Model S'}, 'MSRP': {'A': 27595, 'B': 23570, 'C': 23495, 'D': 68000}} \n\n\n\nCheck the comprehensive list of attributes and methods for DataFrame and some tutorials from the User Guide.\n\n\n8.2.4 Numeric Operations\n\nprint('Addition: data + 4')\nprint(df_rnd + 4, '\\n')    # addition operation\n\nprint('Multiplication: data * 10')\nprint(df_rnd * 10, '\\n')   # multiplication operation\n\nprint('Absolute values:')\nprint(df_rnd.abs(), '\\n')           # get the absolute value for each element\n\nprint('Minimum per column:')\nprint(df_rnd.min(), '\\n')    # get minimum value for each row\n\nprint('Maximum per row:')\nprint(df_rnd.max(axis=1), '\\n')           # get maximum value for each column\n\nprint('Sum per column:')\nprint(df_rnd.sum(), '\\n')          # get sum of values for each column\n\nprint('Average per row:')\nprint(df_rnd.mean(axis=1), '\\n')   # get average value for each row\n\nprint('Standard deviations per row:')\nprint(df_rnd.std(), '\\n')          # get average value for each row\n\nAddition: data + 4\n         x1        x2        x3\n0  3.564707  3.757131  3.743320\n1  4.550448  4.558670  3.455803\n2  5.047401  3.331942  3.890349\n3  5.416808  3.246649  3.739792 \n\nMultiplication: data * 10\n          x1        x2        x3\n0  -4.352930 -2.428691 -2.566797\n1   5.504481  5.586697 -5.441968\n2  10.474011 -6.680577 -1.096514\n3  14.168078 -7.533510 -2.602083 \n\nAbsolute values:\n         x1        x2        x3\n0  0.435293  0.242869  0.256680\n1  0.550448  0.558670  0.544197\n2  1.047401  0.668058  0.109651\n3  1.416808  0.753351  0.260208 \n\nMinimum per column:\nx1   -0.435293\nx2   -0.753351\nx3   -0.544197\ndtype: float64 \n\nMaximum per row:\n0   -0.242869\n1    0.558670\n2    1.047401\n3    1.416808\ndtype: float64 \n\nSum per column:\nx1    2.579364\nx2   -1.105608\nx3   -1.170736\ndtype: float64 \n\nAverage per row:\n0   -0.311614\n1    0.188307\n2    0.089897\n3    0.134416\ndtype: float64 \n\nStandard deviations per row:\nx1    0.802826\nx2    0.599818\nx3    0.181760\ndtype: float64",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "BD/BD-Pandas.html#reference",
    "href": "BD/BD-Pandas.html#reference",
    "title": "8  Pandas",
    "section": "8.3 Reference",
    "text": "8.3 Reference\n\nhttps://pandas.pydata.org/docs/reference/index.html\nhttps://www.w3schools.com/python/pandas/default.asp\nhttp://www.cse.msu.edu/~ptan/dmbook/tutorials/tutorial2/tutorial2.ipynb",
    "crumbs": [
      "Data Science with Python",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "DV/DV-Front.html",
    "href": "DV/DV-Front.html",
    "title": "Data Visualization",
    "section": "",
    "text": "This chapter explores data visualization.\n\nIntroduction to Data Visualization\nMatplotlib\nCommon Plots",
    "crumbs": [
      "Data Visualization"
    ]
  },
  {
    "objectID": "DV/DV-IntroVisual.html",
    "href": "DV/DV-IntroVisual.html",
    "title": "9  Visualizing Data",
    "section": "",
    "text": "9.1 What is Data Visualization?\nThis section provides basic ideas on data visualization.\nData visualization (or data viz) is a non-text-based representation of data that enhances our understanding of it. The goal is to take numbers, which by themselves can be overwhelming, and turn them into something visual so the human brain can quickly identify patterns, trends, and outliers. Thus, data visualization is a core component of data analysis, and there are many packages and approaches available when working in Python.\nData visualization is not just numbers, and it’s not just pictures — it’s the fusion of the two. A spreadsheet of values isn’t a visualization. A pretty poster with no data isn’t a visualization. But a well-designed chart, map, or graph that makes the numbers clearer? That’s data visualization. Another way to think about data visualization is as a visual language. The sender encodes information into a chart, and the receiver decodes it to find meaning. If the visualization works, it speeds up comprehension and reveals insights that would otherwise stay hidden in the numbers.\nA classic example of why visualization matters is Anscombe’s Quartet. This is a set of four datasets that, on paper, look nearly identical — they all have the same mean, the same standard deviation, and the same correlation. If you just looked at the numbers, you might assume the datasets are essentially the same. But when you plot them out, you see they’re completely different — one is a linear relationship, another is curved, one has an outlier, and another forms almost a perfect line with a single point skewing the data.\nShow the code\n# packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n# Define the four datasets\nx = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\ny1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68]\ny2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74]\ny3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73]\nx4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8]\ny4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\n\ndatasets = {\"I\": (x, y1), \"II\": (x, y2), \"III\": (x, y3), \"IV\": (x4, y4)}\n\n# Create subplots\nfig, axs = plt.subplots(\n    1, 4, sharex=True, sharey=True, figsize=(12, 3),\n    gridspec_kw={\"wspace\": 0.08, \"hspace\": 0.08},\n)\n\naxs[0].set(xlim=(0, 20), ylim=(2, 14))\naxs[0].set(xticks=(0, 10, 20), yticks=(4, 8, 12))\n\n# Plot each dataset with regression line and summary stats\nfor ax, (label, (x, y)) in zip(axs.flat, datasets.items()):\n    ax.text(0.1, 0.9, label, fontsize=20, transform=ax.transAxes, va=\"top\")\n    ax.tick_params(direction=\"in\", top=True, right=True)\n    ax.plot(x, y, \"o\")\n\n    # Linear regression\n    slope, intercept = np.polyfit(x, y, deg=1)\n    ax.axline(xy1=(0, intercept), slope=slope, color=\"r\", lw=2)\n\n    # Statistics box\n    stats = (\n        f\"$\\\\mu$ = {np.mean(y):.2f}\\n\"\n        f\"$\\\\sigma$ = {np.std(y):.2f}\\n\"\n        f\"$r$ = {np.corrcoef(x, y)[0][1]:.2f}\"\n    )\n    bbox = dict(boxstyle=\"round\", fc=\"blanchedalmond\", ec=\"orange\", alpha=0.5)\n    ax.text(\n        0.95, 0.07, stats, fontsize=9, bbox=bbox,\n        transform=ax.transAxes, horizontalalignment=\"right\",\n    )\n\nplt.suptitle(\"Anscombe's Quartet\")\nplt.show()\nThis example shows why visualization is so important. Without it, we might make the mistake of treating very different datasets as though they were identical. With visualization, we see the real story immediately. So, to sum it up: data visualization is about making numbers visual so we can learn something from them that would otherwise be invisible.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "DV/DV-IntroVisual.html#what-is-data-visualization",
    "href": "DV/DV-IntroVisual.html#what-is-data-visualization",
    "title": "9  Visualizing Data",
    "section": "",
    "text": "9.1.1 Data Visualization vs. Infographic\nA data visualization requires actual data, and it represents that data visually in a way that makes it easier to understand. It’s usually more about graphs, charts, and geometric elements that highlight relationships among numbers.\nAn infographic, on the other hand, is more like a designed collection of facts. It often uses icons, images, and a lot of text. It may include a little data, but it’s not always data-driven. Typically, an infographic is divided into sections, and each section is with text and pictures. Some section may or may not include a data visualization. Many of sections may just list out facts where the visuals are to catch your eye, not necessarily to represent data.\n\nNicely designed posters with a few numbers on them aren’t really data viz. — Amanda Cox, an editor at The New York Times\n\n\nInfographics are great for storytelling and communication. But if you’re trying to reveal insights hidden in numbers, then data visualization is what you need.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "DV/DV-IntroVisual.html#why-use-data-visualizations",
    "href": "DV/DV-IntroVisual.html#why-use-data-visualizations",
    "title": "9  Visualizing Data",
    "section": "9.2 Why Use Data Visualizations?",
    "text": "9.2 Why Use Data Visualizations?\nThere are four key reasons to use data visualization, instead of just sticking with numbers in tables, or long paragraphs of text:\n\nSpeed: Data visualizations allow us to grasp meaning within just a few seconds. Think about our attention spans today — they’re shorter than ever where we need to deal with lots of data every day in the fast-moving world. A well-designed chart communicates in a glance what would take several sentences or even paragraphs to explain in words.\nComprehension: Complex information becomes easier to understand when it’s visual. Visuals help us uncover trends, patterns, and outliers that would be hard to notice in a spreadsheet. For example, if I show you a time-series line chart, you’ll immediately see the rise and fall of values over time — something that’s much harder to perceive in raw numbers.\nAppeal: Visuals are attention-grabbing. Text and tables can feel dry, but a good chart or map is more engaging. It can make your message more compelling and memorable.\nRetention: Our brains are wired to remember images. If you present data visually, people are far more likely to recall it later compared to when they just read the numbers.\n\nVisuals speed up understanding, clarify complexity, capture attention, and help us remember the message. That’s why visualization is such a powerful communication tool.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "DV/DV-IntroVisual.html#what-makes-a-good-data-visualization",
    "href": "DV/DV-IntroVisual.html#what-makes-a-good-data-visualization",
    "title": "9  Visualizing Data",
    "section": "9.3 What Makes a Good Data Visualization?",
    "text": "9.3 What Makes a Good Data Visualization?\nThere are five main qualities that can lead to good data visualizations:\n\nAccuracy: A good visualization must be truthful. It should not misrepresent data or exaggerate differences. For example, manipulating the scale of an axis can easily mislead — that’s something we must avoid.\nClarity: A visualization should be easy to understand. If it takes several minutes for someone to figure out what your chart is saying, then it’s not doing its job.\nRelevance to the audience: Always consider the people who will see your visualization. Ask yourself: ‘So what?’ Why should they care? A good visualization answers that question clearly.\nSimplicity: Show only what’s necessary. Remove clutter. Every line, label, or shape should serve a purpose. If something doesn’t help people understand the data, it doesn’t belong.\nStorytelling: A strong visualization tells a story. It’s not just about presenting numbers — it’s about guiding the audience to a conclusion, an insight, or a key message.\n\n\n“Beauty is desirable, but I’m not excited by pretty charts that are also pretty useless.” — Graham Wills, a data science expert at IBM\n\nThe goal isn’t just to make something pretty — it’s to make something meaningful.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "DV/DV-IntroVisual.html#planning-your-data-visualization",
    "href": "DV/DV-IntroVisual.html#planning-your-data-visualization",
    "title": "9  Visualizing Data",
    "section": "9.4 Planning Your Data Visualization",
    "text": "9.4 Planning Your Data Visualization\n\n9.4.1 The Story\nWhen planning a data visualization, the very first step is to identify the story in your data.\nLet’s consider an example. Here, we see data from Demographic and Health Surveys showing the percentage of demand for family planning satisfied with modern methods across several years. Notice what happens: in 1993, the rate was just about 40 percent. For nearly a decade, it barely moved — stagnating below 50 percent. But in recent years, something changed. The rate climbed sharply, surpassing 50 percent and eventually reaching over 70 percent.\nNow, if I had simply shown you this as a table of numbers, that story might not have been obvious. But as a visual, the trend jumps out. That’s the power of visualization — it not only communicates information, it actually helps us discover the story hidden in the numbers.\nSo, when you plan your visualization, ask yourself: what is the key message or story here? Once you know that, the design decisions become much easier.\n\n\n\n\n\n\nNoteClarify the Message\n\n\n\nA graphic may tell a thousand words, but you must decide which words.\n\nAsk yourself: “What does this plot tell the viewer?”\nIdentify the key takeaways that need to be immediately apparent in the graphic\nEnsure the viewer is left with no ambiguity about your intended message\n\n\n\n\n\n9.4.2 The Audience\nThe second step in planning is to think carefully about your audience. Who are you creating this visualization for?\nYou can start by considering a few factors:\n\nWhere are they from? What do they already know about the subject?\nAre they experts, policymakers, or members of the general public?\nDo they have access to high-speed internet, or will they only see a printed version?\nAre they likely to be skeptical, or are they already invested in the topic?\n\nBy finding some answers to these questions, you can define the expected audience.\nAfter that, most importantly, you should ask yourself:\n\nWhy should they care about this visualization?\n\nIf the answer isn’t clear, then the visualization isn’t doing its job.\nHere’s an example: imagine you’re presenting data on health insurance coverage in US. If your audience is local policymakers for early career development, you may want to highlight patterns or distribution in specific age groups, and keep the design straightforward. But if your audience is a federal agency, you might emphasize comparisons across various characteristics.\nIn short: the story may stay the same, but how you frame it — what you emphasize, what you simplify — depends entirely on who’s in your audience.\n\n\n9.4.3 Accuracy\nThe third key planning step is accuracy. Accuracy in data visualization is non-negotiable. Misrepresenting data — even unintentionally — can destroy trust.\nHere are some common mistakes to watch out for:\n\nPercent change vs. point change. These are not the same, and mixing them up can dramatically distort the story.\nBubble charts sized by diameter, not area. If you scale bubbles incorrectly, the differences look much larger than they actually are.\nInconsistent units. Mixing currencies, time periods, or measurement systems without clarification confuses the reader and undermines credibility.\nOversimplification. Stripping out too much context can make data misleading or meaningless.\nTruncated axes. If you cut off the y-axis and start at a higher number, small differences can appear exaggerated. For example, showing a bar chart that starts at 30 makes a subtle difference look enormous.\n\nThe bottom line is this: your audience should take the message based on the truth of the data, not a distorted impression. Accuracy is what gives your visualization integrity.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "DV/DV-IntroVisual.html#design-principles",
    "href": "DV/DV-IntroVisual.html#design-principles",
    "title": "9  Visualizing Data",
    "section": "9.5 Design Principles",
    "text": "9.5 Design Principles\nIt’s good to know some tips and principles in designing data visualization.\n\n9.5.1 Ink\nOne of the most important design principles in visualization is what Edward Tufte called the data-ink ratio. Think of it this way: every bit of ink, or every pixel, on your chart should be doing work to help communicate the data. If it’s not helping, it’s distracting.\nSo how do we improve the data-ink ratio? Start by stripping away unnecessary elements. For example, the bar chart is well decorated with lots of colors and backgrounds. But, the same information can be delivered more compactly with higher data-ink ratio.\nAnd, even further, we can make this chart slimer by removing one more from this chart. The gridlines don’t actually help us estimate values precisely, and they may not add value to this visualization. Instead, we can label the bars directly and drop the y-axis altogether. That alone makes the graphic cleaner.\nHowever, this kind of removal may not work well for other visualizations in such cases that a larger number of items are included in the chart so that it becomes harder to compare each other by taking the numbers from labels for the bars.\nWe can also lighten labels, simplify color schemes, and reduce decorative elements — things like shading, 3D effects, or drop shadows. These don’t clarify the message; they clutter it. The goal isn’t to make the chart boring — it’s to make sure every line, every word, and every shape contributes to understanding the data. And if it doesn’t, delete it. That’s how you use your ink strategically.\n\n\n9.5.2 Texts\nEven though we want visuals to do most of the work, good text is still essential in data visualization.\nHere are some tips:\n\nUse text and labels to clarify, not clutter.\n\nInclude labels if they help people read the chart quickly.\n\nAxis labels – Always include them, and if there are units, state them clearly (e.g., “Salary (2015 USD)”).\n\nTick labels – Tailor them to the scale (linear vs. logarithmic).\n\nTitles – Use them if axes and the plot alone do not fully convey the message.\n\n\nUse text annotations to point out key features.\n\nMake your titles work harder.\n\nTitles should communicate the key takeaway. So that, the audience can immediately know the message you want them to walk away with.\n\nChoose fonts for readability. Sans serif fonts — like Helvetica, Arial, or Gill Sans — are clean, modern, and easier to read on screens.\n\nUse emphasis sparingly. All caps, bold, italics, or larger sizes can draw attention, but don’t overuse them. If everything is emphasized, nothing stands out.\nStay consistent. Switching fonts or styles across slides or graphics makes the design look messy.\n\n\n\n\n9.5.3 Colors\nColor is another powerful tool in your design toolbox — but only if you use it thoughtfully.\nOur brains process color much faster than shapes or text, so color can guide attention instantly.\nTo make it work, the following principles would help us.\n\nFirst, use darker or brighter colors to mean ‘more.’\n\nStronger colors should correspond to higher numbers or greater importance.\nUse gray for neutral or background data.\n\nBy doing so, it will help audience keep the focus where you want to emphasize.\nFading less important elements with transparency is a similar option.\n\n\nSecond, every color should have a purpose. Don’t add colors just because they look nice. Each one should signal a category, a comparison, or a level of emphasis.\n\nAlso, keep palettes consistent. If blue means ‘Region A’ on one chart, it should mean ‘Region A’ everywhere else.\nBesides, contrast matters. Higher contrast makes objects stand out more. If two bars are meant to be compared directly, don’t use two nearly identical shades.\n\nFinally, be mindful of symbolism. Colors may carry meaning beyond the chart. Red often signals danger, urgency, or loss. Blue conveys calm, trust, or stability. Yellow can mean optimism — or caution. Think about what your colors might communicate emotionally as well as numerically.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "DV/DV-IntroVisual.html#suggested-workflow-resources",
    "href": "DV/DV-IntroVisual.html#suggested-workflow-resources",
    "title": "9  Visualizing Data",
    "section": "9.6 Suggested Workflow & Resources",
    "text": "9.6 Suggested Workflow & Resources\nWhen it comes to actually building a data visualization, it’s helpful to have a process to guide you.\nHere’s a simple workflow you can follow:\n\nExperiment.\n\nStart by trying different types of visuals.\nDon’t lock yourself into one chart too early.\nSometimes, the story in your data only becomes clear after you’ve tried out a few formats.\n\nDecide.\n\nOnce you’ve explored, decide which type of visual best fits your data and the story you want to tell.\n\nIs it a line chart to show trends over time?\nA bar chart for comparisons?\nA map for geographic differences?\n\n\nRefine.\n\nNext, experiment with design options.\nThis is where trial and error comes in — adjust colors, labels, scales, and layouts until the message is clear and uncluttered.\n\nBuild the final version.\n\nAfter testing and refining, put everything together into a polished visualization that communicates your message effectively.\n\n\n\nKey takeaway: building a strong visualization is not a one-shot effort — it’s an iterative process of experimenting, refining, and polishing.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "DV/DV-IntroVisual.html#resources-for-data-visualizations",
    "href": "DV/DV-IntroVisual.html#resources-for-data-visualizations",
    "title": "9  Visualizing Data",
    "section": "9.7 Resources for Data Visualizations",
    "text": "9.7 Resources for Data Visualizations\n\n9.7.1 General Data Visualization\n\nTexts\n\nFundamentals of Data Visualization\n12 Great Books About Data Visualization\n\nGlossaries\n\nVisual Vocabulary\nData Visualization Cheat Sheet\n\nVisualization Gallery\n\nData Viz Project\nData Visualization Reference Guides\nData Visualization Gallery\n\nOthers\n\nThe 10 Best Data Visualization Blogs To Follow\n\n\n\n\n9.7.2 Python Data Visualization Packages\nPython has a rich ecosystem of visualization packages, which can be categorized in two broad approaches to creating visualizations with code:\n\nImperative – You specify step by step what to draw.\n\nPros: Maximum flexibility and control.\n\nCons: Often verbose; more effort for common plots.\n\nDeclarative – You declare what you want, and the library handles the details.\n\nPros: Quick and concise for standard chart types.\n\nCons: Requires data in the correct format; customization can be limited.\n\n\nDepending on your goals and data, you can choose between them and accordingly a python package. The following sections introduce some popular python packages. For a comprehensive list, see the PyViz Tools Overview.\n\n9.7.2.1 Core Visualization Packages\nHere are the core libraries you are most likely to use either directly or indirectly (as many other high-level libraries are built on these core libraries):\nMatplotlib is the most important and widely used visualization library in Python.\n\nKey Features:\n\nImperative approach – build plots piece by piece for complete control.\n\nHighly flexible but can be verbose for complex plots.\n\nSupports static plots, diagrams, animations, and 3D visualizations (3D should be used sparingly for clarity).\n\nWhen to Use:\n\nYou need fine-grained control over every visual element.\n\nYou are making bespoke or unusual charts.\nYou require careful graphical design or incremental plot building.\n\n\nPlotly is a declarative-oriented library designed for interactive visualizations.\n\nKey Features:\n\nGenerates interactive charts with tooltips and zooming.\nIdeal for dashboards and web applications.\nCan export static images but shines in browser-based interactivity.\n\nWhen to Use:\n\nYou are building a data dashboard or web-based visualization.\n\nYou need interactive plots to explore data beyond static figures.\n\n\nBokeh is another interactive visualization library for Python.\n\nKey Features:\n\nEnables browser-based, interactive plotting.\nCan handle streaming and real-time data.\nIntegrates with Jupyter notebooks, dashboards, and web apps.\n\nWhen to Use:\n\nYou need interactive visualizations with real-time or large data handling.\nYou want standalone HTML outputs for sharing results without extra dependencies.\n\n\n\n\n9.7.2.2 Other Libraries\nPython has many specialized visualization packages that complement the core ones. These are useful for statistical plotting, interactive dashboards, machine learning visualization, or domain-specific applications.\n\nPandas Built-in plotting provides quick, convenient plots:\n\nSyntax: df.plot.* (e.g., df.plot.scatter).\n\nInternally uses Matplotlib.\nExcellent for fast exploratory data analysis (EDA), but not suitable for polished publication figures.\n\nSeaborn is a high-level statistical visualization library built on Matplotlib:\n\nWorks best with tidy data (one row per observation, one column per variable).\nProvides high-level functions for common statistical plots (e.g., box plots, violin plots, heatmaps).\n\nIdeal for exploratory analysis and quick statistical graphics.\n\nAltair is a declarative, web-oriented library:\n\nProduces beautiful, minimalist charts with minimal code.\n\nBest for interactive, browser-friendly visualizations.\nBuilt on Vega-Lite widely used in newsroom data visualization.\n\n\nBeyond the core and high-level packages, Python offers many specialized tools for niche visualization needs:\n\nproplot: Lightweight Matplotlib wrapper for publication-quality plots.\n\nseaborn-image: Brings Seaborn-like workflows to image data.\nLit: Visualization and interpretability for NLP models.\n\nWordcloud: Generates word clouds (use sparingly!).\nVisPy: GPU-accelerated visualization for very large datasets.\nHoloViews: Simplifies data-to-visualization workflows; builds on Bokeh and Matplotlib.\n\nchartify: Quick, high-level plotting library from Spotify.\npalettable: Additional color palettes for Matplotlib and Seaborn.\n\ncolorcet: Perceptually uniform color maps** for accurate data perception.\n\nmissingno: Visualizes patterns of missing data in your dataset.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "DV/DV-IntroVisual.html#reference",
    "href": "DV/DV-IntroVisual.html#reference",
    "title": "9  Visualizing Data",
    "section": "9.8 Reference",
    "text": "9.8 Reference\n\nhttps://aeturrell.github.io/coding-for-economists/intro.html\nhttps://www.prb.org/pace-policy-communication-toolkit/",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Visualizing Data</span>"
    ]
  },
  {
    "objectID": "DV/DV-Matplotlib.html",
    "href": "DV/DV-Matplotlib.html",
    "title": "10  Matplotlib",
    "section": "",
    "text": "10.1 Two Interfaces of Matplotlib\nThis section introduces Matplotlib, a core Python Package for data visualization.\nMatplotlib is a comprehensive Python library for creating static, animated, and interactive visualizations.\nMatplotlib an incredibly powerful and customisable visualisation package, and so plays a role of the foundation for many other data visualisation packages (see a comprehensive list of Python visualization libraries from All Tools in PyViz.\nTo create a plot, you can use one of two main interfaces:",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "DV/DV-Matplotlib.html#two-interfaces-of-matplotlib",
    "href": "DV/DV-Matplotlib.html#two-interfaces-of-matplotlib",
    "title": "10  Matplotlib",
    "section": "",
    "text": "State-based (pyplot) – quick and MATLAB-like.\nObject-oriented (OO) – more explicit and powerful for complex layouts.\n\n\n10.1.1 Pyplot State-Based Interface\nMatplotlib is inspired by MATLAB’s plotting style, which is why the pyplot interface looks very similar to MATLAB commands.\nThis pyplot style treats matplotlib.pyplot (as plt) like a command-based system. You use commands to call methods (plt.plot, plt.title, etc.) sequentially, and they apply to the current figure and axes that Matplotlib manages internally.\nThis pyplot style is - Good for quick and simple plots. - But, less flexible when you need multiple subplots or fine-grained customization.\n\nimport matplotlib.pyplot as plt\n\n# Data\nx = [2, 4, 5, 9]\ny = [10, 20, 25, 30]\n\n# Example of State-based plotting\nplt.plot(x, y, label=\"Line plot\")   # Add line\nplt.xlabel(\"X-axis\")                # Add x-label\nplt.ylabel(\"Y-axis\")                # Add y-label\nplt.title(\"Pyplot Example\")         # Add title\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nmatplotlib support raw data in list (numpy.ndarray and pandas.Series & pandas.DataFrame too) unlike some other visualization packages (e.g., seaborn).\nMatplotlib returns an object (e.g., &lt;matplotlib.legend.Legend at 0x1e17adb25d0&gt;). To suppress this,\n\nend the command with a semi-colon, ;, or\ncall plt.show() as the last command.\n\n\n\n\n\n\n10.1.2 Object-Oriented (OO) Interface\nIn the OO style, you explicitly create a Figure and one or more Axes objects, and then call methods on them. This style is closer to how Matplotlib actually works behind the scene, so it can provide more control.\nThis style is\n\nGood for complex, multi-panel figures, reusable code, fine control.\nSlightly more typing (manual coding) required, compared to pyplot.\n\n\n# Example of object-oriented plotting\nfig, ax = plt.subplots()                 # Create figure and axes explicitly\n\nax.plot(x, y, label=\"Line plot\")         # Add line\nax.set_xlabel(\"X-axis\")                  # Add x-label\nax.set_ylabel(\"Y-axis\")                  # Add y-label\nax.set_title(\"Object-Oriented Example\")  # Add title\nax.legend()\n\nplt.show()",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "DV/DV-Matplotlib.html#pandas-and-matplotlib",
    "href": "DV/DV-Matplotlib.html#pandas-and-matplotlib",
    "title": "10  Matplotlib",
    "section": "10.2 Pandas and Matplotlib",
    "text": "10.2 Pandas and Matplotlib\nPandas handles the data and Matplotlib handles the plotting.\n\nMatplotlib support any array-like data, including Series and DataFrame of pandas.\nPandas has built-in plotting methods that make use of Matplotlib.\n\nLet’s walk through how to use Pandas for Matplotlib step by step, with the following df:\n\nimport pandas as pd\ndf = pd.DataFrame({'x': x, 'y': y})\ndf.index = [\"a\",\"b\",\"c\",\"d\"]\nprint(df.head())\n\n   x   y\na  2  10\nb  4  20\nc  5  25\nd  9  30\n\n\n\n10.2.1 Pandas as Input for Matplotlib\nThe Series objects can be used for Matplotlib, as one-dim array data. From a DataFrame, you can select/extract two Series data objects and use them for x- and y-axis data, respectively.\n\n# Create a plot using Matplotlib's function\nplt.plot(df['x'], df['y'])   # Add a line\nplt.show()\n\n\n\n\n\n\n\n\nIf a whole DataFrame is used, Matplotlib will return a plot of multiple lines. In the plot, each line is from a column of the DataFrame, while the x-axis is based on the index labels.\n\nplt.plot(df)   # Add lines\nplt.show()\n\n\n\n\n\n\n\n\n\n\n10.2.2 Matplotlib Methods of Pandas.DataFrame\nYou can create a plot with DataFrame by using its plot() method:\n\n# Create a plot using DataFrame's method\ndf.plot(x=\"x\", y=\"y\")\nplt.show()\n\n\n\n\n\n\n\n\nIf x and y are not specified, then the method plot() will take all columns as y-axis values for separate lines, using the indices as x-axis values:\n\ndf.plot()\nplt.show()\n\n\n\n\n\n\n\n\nMore details are available in the Pandas documentations.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "DV/DV-Matplotlib.html#customising-charts",
    "href": "DV/DV-Matplotlib.html#customising-charts",
    "title": "10  Matplotlib",
    "section": "10.3 Customising Charts",
    "text": "10.3 Customising Charts\nLet’s explore some standard customisations that can enable you to create your own unique plot, while the Matplotlib interface is too extensive to cover every detail in this class.\n\n10.3.1 Components of a Matplotlib Chart\nThe figure of Matplotlib consists of many components, and you can customize each of those components for a plot. The figure below shows an overview of some components frequently customized.\n\n\n\nAnatomy of a matplotlib figure\n\n\n\n\n10.3.2 Artists\n\nEverything you see in a Matplotlib figure is an Artist.\nTwo types:\n\nPrimitives: graphical elements, such as Line2D, Rectangle, Text, AxesImage.\nContainers: objects that hold other artists, such as Figure, Axes, and Axis.\n\n\n\n\n10.3.3 Figure (fig)\n\nThe entire canvas that holds all parts of the visualization.\nContains one or more Axes plus special artists (e.g., figure title, figure-level legend).\n\n\n# create a figure class object\nfig = plt.figure()\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n# or more commonly:\nfig, ax = plt.subplots()\n\n\n\n\n\n\n\n\n\n\n10.3.4 Axes (ax)\n\nThe actual plot area where the data is drawn.\nA Figure can contain multiple Axes (subplots).\nEach Axes includes:\n\nTwo Axis objects (or three in the case of 3D graph) for an x-axis and a y-axis.\nA title (ax.set_title()).\nlabels (set_xlabel(), set_ylabel()).\n\n\n\n# Adding a plot to ax\nfig, ax = plt.subplots()\n\nax.plot(df[\"x\"], df[\"y\"])      # add a plot to the 1st subplot of `ax` \n\nplt.show()\n\n\n\n\n\n\n\n\n\n# With additional arguments\nfig, ax = plt.subplots()\n\nax.plot(df[\"x\"], df[\"y\"], 'r--')  # red dashed line\n# ax.plot(df[\"x\"], df[\"y\"], 'r--')  # green points  dashed line\n\nplt.show()\n\n\n\n\n\n\n\n\nIf graphics are overlaying, which plot comes first? Check Zorder documentation for the details.\n\n# multiple graphs on a plot\nfig, ax = plt.subplots()\n\nax.plot(df[\"x\"], df[\"y\"], 'r')     # add a plot to `ax` \n\nax.scatter(df[\"x\"], df[\"y\"])       # add another plot to `ax` \n\nplt.show()\n\n\n\n\n\n\n\n\nFacet plots (i.e., a figure that consists of multiple small plots) can be easily created by defining the frame:\n\n# multiple subplots\nfig, axs = plt.subplots(1,2)       # frame with a grid of 1 row and 2 column \n\naxs[0].plot(df[\"x\"], df[\"y\"])      # add a plot to the 1st subplot of `axs` \n\naxs[1].scatter(df[\"x\"], df[\"y\"])   # add a plot to the 2nd subplot of `axs` \n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n10.3.5 Titles\n\nA description that provides the key takeaway of the graph\n\nAt the ax-level level, ax.set_title()\nAt the figure level, plt.suptitle()\n\n\n\n# Titles at different levels\nfig, ax = plt.subplots()\n\nax.plot(df[\"x\"], df[\"y\"])                     # Make a plot on \"ax\"\nax.set_title(\"This is a title\", loc=\"right\")  # Add a title to `ax`, aligning right\n\nplt.suptitle(\"This is a SUPER title :D\",      # Add a SUPER title to `plt`,\n             x=0.35, y=1.02)                  #    at a specific-coordinate location\nplt.show()\n\n\n\n\n\n\n\n\n\n# Axis labels\nfig, ax = plt.subplots()\n\nax.plot(df[\"x\"], df[\"y\"])   # Make a plot on \"ax\"\n\nax.set_xlabel(\"X\")          # Set the x label\nax.set_ylabel(\"Y\")          # Set the y label\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n10.3.6 Axis\n\nThe number line (horizontal or vertical) inside each Axes.\nControls:\n\nLimits (set_xlim(), set_ylim())\nTicks (marks on the axis).\nTick labels (the text for each tick).\n\n\n\n# axis limits and ticks\nfig, ax = plt.subplots()\n\nax.plot(df[\"x\"], df[\"y\"])   # Make a plot on \"ax\"\n\nax.set_xlim(0, 10)  # Set the limits on the x-axis\nax.set_ylim(5, 40)  # Set the limits on the y-axis\n\nax.set_xticks([1,3,5,7,9], [\"one\", \"three\", \"five\", \"seven\", \"nine\"])\nax.set_yticks([11, 21, 31, 41])  # note that tick labels are optional\n\nplt.show()\n\n\n\n\n\n\n\n\n\n10.3.6.1 Scales\n\nThe ticks can be tranformed on a different scale\n\nThe linear scale\nNonlinear scales (e.g., a log-scale\n\n\nFind details and other examples from scales.\n\nfig, ax = plt.subplots()\n\nax.plot(df[\"x\"], df[\"y\"]**2)      # Make a plot on \"ax\"\n\nax.set_xlim(0, 10)  # Set the limits on the x-axis\n#ax.set_ylim(5, 40)  # Set the limits on the y-axis\n\nax.set_yscale(\"log\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n10.3.7 Text Annotations\n\nExtra descriptions to make (elements of) the plot understandable, informative, or noticeable\n\nNow we use ax.annotate() to add this information.\n\nfig, ax = plt.subplots()\n\nax.plot(df[\"x\"], df[\"y\"]) \nax.annotate(text=\"TEXT :)\", xy=(5,28))\n\nplt.show()\n\n\n\n\n\n\n\n\nYou can learn more about text annotations here.\n\n\n10.3.8 Legend\n\nA space designated to explain the meaning of colors, markers, or line styles.\nBased on either\n\neach plot label in the plotting function\nor, a list directly entered in ax.legend()\n\n\n\nfig, ax = plt.subplots()\n\nax.plot(df[\"x\"], df[\"y\"] * 2, label=\"Sales\")\nax.plot(df[\"x\"], df[\"y\"] + 5, label=\"Expenses\")\n\nax.legend()\n#ax.legend([\"SALES\", \"COST\"])\n\nplt.show()",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "DV/DV-Matplotlib.html#exporting-the-result",
    "href": "DV/DV-Matplotlib.html#exporting-the-result",
    "title": "10  Matplotlib",
    "section": "10.4 Exporting the result",
    "text": "10.4 Exporting the result\n\n### In pyplot interface\nplt.plot(df[\"x\"], df[\"y\"], marker=\"o\", label=\"Line\")\nplt.title(\"Export Example\")\nplt.legend()\n\n# Save the figure BEFORE `plt.show()`\nplt.savefig(\"my_plot_pyplot.png\")   # Saves in PNG format\nplt.show()\n\n\n\n\n\n\n\n\n\n# In OO interface\nfig, ax = plt.subplots()\nax.plot(df[\"x\"], df[\"y\"], \"r:\", label=\"Line\")\nax.set_title(\"Export Example\")\nax.legend()\n\n# Save using the figure object\nfig.savefig(\"my_plot_oo.pdf\")   # Saves as PDF\nplt.show()",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "DV/DV-Matplotlib.html#resources",
    "href": "DV/DV-Matplotlib.html#resources",
    "title": "10  Matplotlib",
    "section": "10.5 Resources",
    "text": "10.5 Resources\nFor more in-depth introduction, you can check:\n\nMatplotlib has well-organized documentations for Tutorials\nMatplotlib tutorial of Nicolas P. Rougier\n\nAlso, cheatsheets and handouts for functions/parameters in Matplotlib are available in the official website.",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "DV/DV-Matplotlib.html#reference",
    "href": "DV/DV-Matplotlib.html#reference",
    "title": "10  Matplotlib",
    "section": "10.6 Reference",
    "text": "10.6 Reference\n\nhttps://matplotlib.org/stable/tutorials/index\nhttps://aeturrell.github.io/coding-for-economists/vis-matplotlib.html\nhttps://github.com/rougier/scientific-visualization-book",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Matplotlib</span>"
    ]
  },
  {
    "objectID": "DV/DV-ComPlots.html",
    "href": "DV/DV-ComPlots.html",
    "title": "11  Common Plots",
    "section": "",
    "text": "11.1 Preliminaries\nThis section introduces to various types of plots using popular visualization packages:",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Common Plots</span>"
    ]
  },
  {
    "objectID": "DV/DV-ComPlots.html#preliminaries",
    "href": "DV/DV-ComPlots.html#preliminaries",
    "title": "11  Common Plots",
    "section": "",
    "text": "11.1.1 Packages\nYou need to install the package if an error arises.\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport altair as alt\nimport plotly.graph_objects as go\n\n# For ease of data handling\n#import datetime\n\n#from pathlib import Path\n#from itertools import cycle\n\n\n\n11.1.2 Data\nThe following simple data set will be used in some examples.\n\n# plot with a dataframe\nrow_names = [\"A\", \"B\", \"C\", \"D\"]\ncol_names = ['X1', 'X2', 'X3', 'X4', 'X5']\ndf = pd.DataFrame(\n    [\n        [10, 20, 10, 26, 2], \n        [20, 25, 15, 21, 9], \n        [12, 15, 19, 6,  4],\n        [10, 18, 11, 19, 7]\n    ],\n    index=row_names,\n    columns=col_names\n)\nprint(df)\n\n   X1  X2  X3  X4  X5\nA  10  20  10  26   2\nB  20  25  15  21   9\nC  12  15  19   6   4\nD  10  18  11  19   7",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Common Plots</span>"
    ]
  },
  {
    "objectID": "DV/DV-ComPlots.html#bar-charts",
    "href": "DV/DV-ComPlots.html#bar-charts",
    "title": "11  Common Plots",
    "section": "11.2 Bar Charts",
    "text": "11.2 Bar Charts\nBar chart.\n\n11.2.1 Simple Bar Chart\n\n# data\nx = row_names\ny = df.iloc[:,0]\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot\nfig, ax = plt.subplots()\nax.bar(x, y)\nplt.show()\n\n\n\n\n\n\n\n\n\n# horizontal bars\nfig, ax = plt.subplots()\nax.barh(x, y)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nsns.set_theme()\nax = sns.barplot(x=x, y=y)\nax.set(xlabel=\"Row\", ylabel=\"X1\", title=\"X1 by Row\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nalt.data_transformers.disable_max_rows()\n\nchart = (\n    alt.Chart(pd.DataFrame({\"Row\": x, \"X1\": y}))\n    .mark_bar()\n    .encode(x=\"Row:N\", y=\"X1:Q\")\n    .properties(title=\"X1 by Row\", width=400, height=300)\n)\nchart\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure()\n\nfig.add_bar(\n    x=row_names, \n    y=df.iloc[:, 0], \n    name=\"X1\"\n)\nfig.update_layout(\n    title=\"X1 by Row\",\n    xaxis_title=\"Row\",\n    yaxis_title=\"X1\"\n)\nfig.show()\n\n                            \n                                            \n\n\n\n\n\n\n\n\n11.2.2 Stacked Bar Chart\n\n# multiple data\nx = df.index\ny1, y2, y3, y4, y5 = df[\"X1\"], df[\"X2\"], df[\"X3\"], df[\"X4\"], df[\"X5\"]\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot\nfig, ax = plt.subplots()\n\nax.bar(x, y1, color='r')\nax.bar(x, y2, bottom=y1, color='b')\nax.bar(x, y3, bottom=y1+y2, color='y')\nax.bar(x, y4, bottom=y1+y2+y3, color='g')\nax.bar(x, y5, bottom=y1+y2+y3+y4, color='k')\n\n# labels\nax.legend([\"X1\", \"X2\", \"X3\", \"X4\", \"X5\"])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\n\ndf.plot(\n    kind=\"bar\", stacked=True, ax=ax,\n    color=[\"r\", \"b\", \"y\", \"g\", \"k\"]\n)\n\nax.set(xlabel=\"Row\", ylabel=\"Value\", title=\"Stacked Bar (X1–X5)\")\nax.legend(title=\"Columns\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndata = df.reset_index().melt(id_vars=\"index\", var_name=\"Variable\", value_name=\"Value\")\n\nchart = (\n    alt.Chart(data)\n    .mark_bar()\n    .encode(\n        x=alt.X(\"index:N\", title=\"Row\"),\n        y=alt.Y(\"Value:Q\", stack=\"zero\"),\n        color=\"Variable:N\"\n    )\n    .properties(title=\"Stacked Bar (X1–X5)\", width=400, height=300)\n)\nchart\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure()\n\nfig.add_bar(x=df.index, y=df[\"X1\"], name=\"X1\", marker_color=\"red\")\nfig.add_bar(x=df.index, y=df[\"X2\"], name=\"X2\", marker_color=\"blue\")\nfig.add_bar(x=df.index, y=df[\"X3\"], name=\"X3\", marker_color=\"yellow\")\nfig.add_bar(x=df.index, y=df[\"X4\"], name=\"X4\", marker_color=\"green\")\nfig.add_bar(x=df.index, y=df[\"X5\"], name=\"X5\", marker_color=\"black\")\n\nfig.update_layout(\n    barmode=\"stack\",\n    title=\"Stacked Bar (X1–X5)\",\n    xaxis_title=\"Row\",\n    yaxis_title=\"Value\"\n)\n\nfig.show()\n\n                            \n                                            \n\n\n\n\n\n\n\n\n11.2.3 Grouped Bar Chart\n\n# data\nx = np.arange(df.shape[0])   # just with the same number of rows \ny1 = df.iloc[:,0]\ny2 = df.iloc[:,1]\ny3 = df.iloc[:,2]\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot data in grouped manner of bar type\nfig, ax = plt.subplots()\n\nwidth = 0.2\nax.bar(x-0.2, y1, width, color='cyan')\nax.bar(x, y2, width, color='orange')\nax.bar(x+0.2, y3, width, color='green')\n\n# labels\nax.legend([\"X1\", \"X2\", \"X3\", \"X4\", \"X5\"])\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndata = df[[\"X1\", \"X2\", \"X3\"]].reset_index().melt(id_vars=\"index\",\n                                                 var_name=\"Variable\",\n                                                 value_name=\"Value\")\n\nfig, ax = plt.subplots()\nsns.barplot(data=data, x=\"index\", y=\"Value\", hue=\"Variable\", ax=ax)\nax.set(xlabel=\"Row\", ylabel=\"Value\", title=\"Grouped Bar (X1–X3)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndata = df[[\"X1\", \"X2\", \"X3\"]].reset_index().melt(id_vars=\"index\",\n                                                 var_name=\"Variable\",\n                                                 value_name=\"Value\")\n\nchart = (\n    alt.Chart(data)\n    .mark_bar()\n    .encode(\n        x=alt.X(\"index:N\", title=\"Row\"),\n        y=alt.Y(\"Value:Q\"),\n        color=\"Variable:N\"\n    )\n    .properties(title=\"Grouped Bar (X1–X3)\", width=400, height=300)\n)\nchart\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure()\nfig.add_bar(x=df.index, y=df[\"X1\"], name=\"X1\", marker_color=\"cyan\")\nfig.add_bar(x=df.index, y=df[\"X2\"], name=\"X2\", marker_color=\"orange\")\nfig.add_bar(x=df.index, y=df[\"X3\"], name=\"X3\", marker_color=\"green\")\n\nfig.update_layout(\n    barmode=\"group\",\n    title=\"Grouped Bar (X1–X3)\",\n    xaxis_title=\"Row\",\n    yaxis_title=\"Value\"\n)\nfig.show()",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Common Plots</span>"
    ]
  },
  {
    "objectID": "DV/DV-ComPlots.html#line-area-charts",
    "href": "DV/DV-ComPlots.html#line-area-charts",
    "title": "11  Common Plots",
    "section": "11.3 Line & Area Charts",
    "text": "11.3 Line & Area Charts\n\n11.3.1 Line plot\n\n# data\nx = [1, 2, 3, 4, 5]\ny = [2, 3, 7, 13, 16]\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(x, y, marker='o', linestyle='-')\n\n# Add annotations\nfor xi, yi in zip(x, y):\n    ax.annotate(f'({xi}, {yi})', (xi, yi),\n                textcoords=\"offset points\", xytext=(0, 10), ha='center')\n\n# labels\nax.set_title('Line Chart with Annotations')\nax.set_xlabel('X-axis Label')\nax.set_ylabel('Y-axis Label')\n\n# grid\nax.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(8, 6))\nsns.lineplot(x=x, y=y, marker=\"o\", ax=ax)\n\nfor xi, yi in zip(x, y):\n    ax.annotate(f\"({xi}, {yi})\", (xi, yi),\n                textcoords=\"offset points\", xytext=(0, 10), ha=\"center\")\n\nax.set_title(\"Line Chart with Annotations\")\nax.set_xlabel(\"X-axis Label\")\nax.set_ylabel(\"Y-axis Label\")\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndata = pd.DataFrame({\"x\": x, \"y\": y, \"label\": [f\"({xi}, {yi})\" for xi, yi in zip(x, y)]})\n\nline = alt.Chart(data).mark_line(point=True).encode(\n    x=\"x:Q\", y=\"y:Q\"\n)\n\ntext = alt.Chart(data).mark_text(dy=-10).encode(\n    x=\"x:Q\", y=\"y:Q\", text=\"label:N\"\n)\n\nchart = (line + text).properties(\n    title=\"Line Chart with Annotations\", width=500, height=350\n)\nchart\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x, y=y, mode=\"lines+markers\", name=\"Series\"))\n\nfor xi, yi in zip(x, y):\n    fig.add_annotation(x=xi, y=yi, text=f\"({xi}, {yi})\",\n                       showarrow=False, yshift=10)\n\nfig.update_layout(\n    title=\"Line Chart with Annotations\",\n    xaxis_title=\"X-axis Label\",\n    yaxis_title=\"Y-axis Label\"\n)\nfig.show()\n\n                            \n                                            \n\n\n\n\n\n\n\n\n11.3.2 Multiple Line Plot and Filled Area\n\n# data\nx = np.array([1, 2, 3, 4])\ny1 = x**2\ny2 = [3, 4, 5, 6]\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot\nfig, ax = plt.subplots(figsize=(8, 6))\n\nax.plot(x, y1, label=\"y1\")\nax.plot(x, y2, label=\"y2\")\n\n# labels\nax.set_title('Multiple-graphs plot')\nax.set_xlabel('X-axis Label')\nax.set_ylabel('Y-axis Label')\n\n# grid\nax.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# Reshape into long format\ndata = pd.DataFrame({\"x\": x, \"y1\": y1, \"y2\": y2})\ndata_long = data.melt(id_vars=\"x\", var_name=\"Series\", value_name=\"y\")\n\nfig, ax = plt.subplots(figsize=(8, 6))\nsns.lineplot(data=data_long, x=\"x\", y=\"y\", hue=\"Series\", ax=ax)\n\nax.set_title(\"Multiple-graphs plot\")\nax.set_xlabel(\"X-axis Label\")\nax.set_ylabel(\"Y-axis Label\")\nax.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndata = pd.DataFrame({\"x\": x, \"y1\": y1, \"y2\": y2})\ndata_long = data.melt(id_vars=\"x\", var_name=\"Series\", value_name=\"y\")\n\nchart = (\n    alt.Chart(data_long)\n    .mark_line(point=True)\n    .encode(\n        x=\"x:Q\", y=\"y:Q\", color=\"Series:N\"\n    )\n    .properties(title=\"Multiple-graphs plot\", width=500, height=350)\n)\nchart\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=x, y=y1, mode=\"lines+markers\", name=\"y1\"))\nfig.add_trace(go.Scatter(x=x, y=y2, mode=\"lines+markers\", name=\"y2\"))\n\nfig.update_layout(\n    title=\"Multiple-graphs plot\",\n    xaxis_title=\"X-axis Label\",\n    yaxis_title=\"Y-axis Label\"\n)\n\nfig.show()",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Common Plots</span>"
    ]
  },
  {
    "objectID": "DV/DV-ComPlots.html#circular-charts",
    "href": "DV/DV-ComPlots.html#circular-charts",
    "title": "11  Common Plots",
    "section": "11.4 Circular Charts",
    "text": "11.4 Circular Charts\n\n11.4.1 Polar\n\n# spiral data\nrads = np.arange(0, 2 * np.pi, 0.1)\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\nax.plot(rads, rads, 'g.')   # angle = rads, radius = rads\n\nax.set_title(\"Spiral in Polar Coordinates\")\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\nsns.scatterplot(x=rads, y=rads, color=\"green\", ax=ax)  # polar interprets x as theta, y as r\n\nax.set_title(\"Spiral in Polar Coordinates (Seaborn on Matplotlib)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndata = pd.DataFrame({\n    \"theta\": rads,\n    \"r\": rads,\n    \"x\": rads * np.cos(rads),\n    \"y\": rads * np.sin(rads)\n})\n\nchart = (\n    alt.Chart(data)\n    .mark_point(color=\"green\")\n    .encode(x=\"x:Q\", y=\"y:Q\")\n    .properties(title=\"Spiral (Polar converted to Cartesian)\", width=400, height=400)\n)\nchart\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatterpolar(\n    r=rads,\n    theta=np.degrees(rads),  # Plotly uses degrees\n    mode='markers',\n    marker=dict(color='green')\n))\n\nfig.update_layout(\n    title=\"Spiral in Polar Coordinates\",\n    polar=dict(radialaxis=dict(visible=True))\n)\n\nfig.show()\n\n                            \n                                            \n\n\n\n\n\n\n\n\n11.4.2 Radar (or spider) chart\n\n# data\nprint(df.head())\n\n   X1  X2  X3  X4  X5\nA  10  20  10  26   2\nB  20  25  15  21   9\nC  12  15  19   6   4\nD  10  18  11  19   7\n\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# custom function...\ndef radar_plot(dataframe, figsize=(12,8)):\n    rows, cols = dataframe.index, dataframe.columns\n    n_cols = len(cols)\n\n    # Angles for each column (variable)\n    angles = [n / float(n_cols) * 2 * np.pi for n in range(n_cols)]\n    angles += [angles[0]]\n\n    # Initialise spider plot\n    fig = plt.figure(figsize=figsize)\n    ax = fig.add_subplot(111, polar=True)\n\n    # Plot each row (observation) of the DataFrame\n    for idx, row in dataframe.iterrows():\n        values = row.tolist()\n        values += [values[0]]  # close loop\n\n        ax.plot(angles, values, linewidth=1, linestyle=\"solid\", label=idx)\n        ax.fill(angles, values, alpha=0.1)  # optional fill\n\n    # Add category labels\n    ax.set_xticks(angles[:-1])\n    ax.set_xticklabels(cols)\n\n    ax.legend(loc=\"upper right\", bbox_to_anchor=(1.1, 1.1))\n    plt.show()\n\n# Example usage\nradar_plot(df)\n\n\n\n\n\n\n\n\n\n\n\ndef radar_plot_seaborn(df, figsize=(12, 8), fill=True):\n    cols = df.columns.tolist()\n    n_cols = len(cols)\n    angles = [n / float(n_cols) * 2 * np.pi for n in range(n_cols)]\n    angles += [angles[0]]\n\n    sns.set_theme(style=\"whitegrid\")\n    fig, ax = plt.subplots(subplot_kw={\"projection\": \"polar\"}, figsize=figsize)\n\n    for idx, row in df.iterrows():\n        values = row.tolist() + [row.tolist()[0]]\n        ax.plot(angles, values, linewidth=2, label=idx)\n        if fill:\n            ax.fill(angles, values, alpha=0.15)\n\n    ax.set_xticks(angles[:-1])\n    ax.set_xticklabels(cols)\n    ax.set_title(\"Radar Chart (Seaborn + Matplotlib)\", pad=20)\n    ax.legend(loc=\"upper right\", bbox_to_anchor=(1.15, 1.15))\n    plt.show()\n\nradar_plot_seaborn(df)\n\n\n\n\n\n\n\n\n\n\n\ndef radar_plot_altair(df, title=\"Radar Chart (Altair via Cartesian)\"):\n    cols = df.columns.tolist()\n    n_cols = len(cols)\n    angles = np.linspace(0, 2*np.pi, n_cols, endpoint=False)\n\n    # Build long-form with Cartesian coords per row/variable and close the loop\n    records = []\n    for row_name, row in df.iterrows():\n        vals = row.values\n        xs = (vals * np.cos(angles)).tolist()\n        ys = (vals * np.sin(angles)).tolist()\n        # close loop\n        xs.append(xs[0]); ys.append(ys[0])\n        vars_seq = cols + [cols[0]]\n        for order, (x, y, var, val) in enumerate(zip(xs, ys, vars_seq, list(vals)+[vals[0]])):\n            records.append({\n                \"Row\": row_name, \"Variable\": var, \"Value\": float(val),\n                \"x\": float(x), \"y\": float(y), \"order\": order\n            })\n    data = pd.DataFrame(records)\n\n    line = alt.Chart(data).mark_line().encode(\n        x=\"x:Q\", y=\"y:Q\", color=\"Row:N\", detail=\"Row:N\", order=\"order:O\"\n    )\n    pts = alt.Chart(data).mark_point().encode(\n        x=\"x:Q\", y=\"y:Q\", color=\"Row:N\"\n    )\n    chart = (line + pts).properties(\n        width=450, height=450, title=title\n    )\n    chart\n       \nradar_plot_altair(df)\n\n\n\n\ndef radar_plot_plotly(df, title=\"Radar Chart (Plotly)\"):\n    categories = df.columns.tolist()\n    fig = go.Figure()\n    for idx, row in df.iterrows():\n        values = row.tolist() + [row.tolist()[0]]              # close loop\n        fig.add_trace(go.Scatterpolar(\n            r=values,\n            theta=categories + [categories[0]],\n            mode=\"lines+markers\",\n            name=idx\n        ))\n    fig.update_layout(\n        title=title,\n        polar=dict(radialaxis=dict(visible=True)),\n        showlegend=True\n    )\n    fig.show()\n\nradar_plot_plotly(df)\n\n                            \n                                            \n\n\n\n\n\n\n\n\n11.4.3 Contour Plot\n\n# data\nx = np.linspace(0, 5, 100)    # the 1st dim\ny = np.linspace(0, 5, 100)    # the 2nd dim\nX, Y = np.meshgrid(x, y)    # all possible pairs between x and y\n\nZ = np.sin(X) ** 10 + np.cos(10 + Y * X) * np.cos(X)  # the 3rd dim\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot only with contour lines\nfig, ax = plt.subplots(1, 1)\n\nax.contour(X, Y, Z)\n# ax.contourf(X, Y, Z, cmap=\"viridis\")  # filled contours\n\nax.set_title('Filled Contour Plot')\nax.set_xlabel('X')\nax.set_ylabel('Y')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nsns.set_theme(style=\"whitegrid\")\n\nfig, ax = plt.subplots(figsize=(6,5))\ncs = ax.contour(X, Y, Z, cmap=\"viridis\")\nax.set_title(\"Contour Plot (Seaborn style)\")\nax.set_xlabel(\"X\")\nax.set_ylabel(\"Y\")\nplt.colorbar(cs, ax=ax)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndata = pd.DataFrame({\n    \"X\": X.ravel(),\n    \"Y\": Y.ravel(),\n    \"Z\": Z.ravel()\n})\n\nchart = (\n    alt.Chart(data)\n    .mark_rect()\n    .encode(\n        x=\"X:Q\",\n        y=\"Y:Q\",\n        color=\"Z:Q\"\n    )\n    .properties(title=\"Heatmap (Contour alternative in Altair)\",\n                width=400, height=350)\n)\nchart\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure(data=\n    go.Contour(\n        z=Z,\n        x=x,\n        y=y,\n        colorscale=\"Viridis\"\n    )\n)\n\nfig.update_layout(\n    title=\"Contour Plot (Plotly)\",\n    xaxis_title=\"X\",\n    yaxis_title=\"Y\"\n)\nfig.show()",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Common Plots</span>"
    ]
  },
  {
    "objectID": "DV/DV-ComPlots.html#scatter-plot",
    "href": "DV/DV-ComPlots.html#scatter-plot",
    "title": "11  Common Plots",
    "section": "11.5 Scatter Plot",
    "text": "11.5 Scatter Plot\n\n11.5.1 Scatter plot\n\n# data\nx1 = df[\"X1\"]\nx2 = df[\"X2\"]\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot\nfig, ax = plt.subplots()\nax.scatter(x1, x2)\n\nax.set_xlabel(\"X1\", fontsize=15)\nax.set_ylabel(\"X2\", fontsize=7)\nax.set_title('Between X1 and X2')\nax.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nsns.scatterplot(data=df, x=\"X1\", y=\"X2\", ax=ax)\n\nax.set_xlabel(\"X1\", fontsize=15)\nax.set_ylabel(\"X2\", fontsize=7)\nax.set_title(\"Between X1 and X2\")\nax.grid(True)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nchart = (\n    alt.Chart(df)\n    .mark_point()\n    .encode(x=\"X1:Q\", y=\"X2:Q\")\n    .properties(title=\"Between X1 and X2\", width=400, height=300)\n)\nchart\n\n\n\n\n\n\n\n\n\nPlotly is another declarative plotting library, at least sometimes (!), but one that is interactive by default.\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=df[\"X1\"], y=df[\"X2\"],\n    mode=\"markers\",\n    marker=dict(size=8, color=\"blue\"),\n    name=\"Points\"\n))\n\nfig.update_layout(\n    title=\"Between X1 and X2\",\n    xaxis_title=\"X1\",\n    yaxis_title=\"X2\"\n)\nfig.show()\n\n                            \n                                            \n\n\n\n\n\n\n\n\n11.5.2 Bubble plot\n\n# data\nx = df[\"X1\"]\ny = df[\"X2\"]\nz = df[\"X3\"]\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot\nfig, ax = plt.subplots()\nax.scatter(df[\"X1\"], df[\"X2\"], s=df[\"X3\"]*100, alpha=0.6)\n\nax.set_xlabel(\"X1\")\nax.set_ylabel(\"X2\")\nax.set_title(\"Bubble Chart (X1 vs X2, size=X3)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nsns.scatterplot(\n    data=df, x=\"X1\", y=\"X2\", size=\"X3\",\n    sizes=(20, 500), alpha=0.6, ax=ax\n)\n\nax.set_title(\"Bubble Chart (X1 vs X2, size=X3)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nchart = (\n    alt.Chart(df)\n    .mark_circle(opacity=0.6)\n    .encode(\n        x=\"X1:Q\",\n        y=\"X2:Q\",\n        size=\"X3:Q\"\n    )\n    .properties(title=\"Bubble Chart (X1 vs X2, size=X3)\", width=400, height=300)\n)\nchart\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x=df[\"X1\"], y=df[\"X2\"],\n    mode=\"markers\",\n    marker=dict(size=df[\"X3\"]*10, sizemode=\"area\", opacity=0.6),\n    text=[f\"Size={val}\" for val in df[\"X3\"]]  # hover info\n))\n\nfig.update_layout(\n    title=\"Bubble Chart (X1 vs X2, size=X3)\",\n    xaxis_title=\"X1\",\n    yaxis_title=\"X2\"\n)\nfig.show()\n\n                            \n                                            \n\n\n\n\n\n\n\n\n11.5.3 Lollipop\n\n# data \ndf_planets = sns.load_dataset(\"planets\").groupby(\"year\")[\"number\"].count()\nprint(df_planets.head())\n\nyear\n1989    1\n1992    2\n1994    1\n1995    1\n1996    6\nName: number, dtype: int64\n\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot\nfig, ax = plt.subplots()\nax.stem(df_planets.index, df_planets, basefmt=\"\")\nax.yaxis.tick_right()\nax.spines[\"left\"].set_visible(False)\nax.set_ylim(0, 200)\nax.set_title(\"Number of exoplanets discovered per year\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# vertical lines\nax.vlines(df_planets.index, 0, df_planets, color=\"steelblue\", alpha=0.7)\n\n# markers\nax.plot(df_planets.index, df_planets, \"o\", color=\"steelblue\")\n\nax.yaxis.tick_right()\nax.spines[\"left\"].set_visible(False)\nax.set_ylim(0, 200)\nax.set_title(\"Number of exoplanets discovered per year\")\nplt.show()\n\n\n\n\ndata = pd.DataFrame({\"year\": df_planets.index, \"count\": df_planets.values})\n\nchart = (\n    alt.Chart(data)\n    .mark_rule()\n    .encode(x=\"year:O\", y=\"count:Q\", y2=alt.value(0))\n    +\n    alt.Chart(data)\n    .mark_point(color=\"steelblue\")\n    .encode(x=\"year:O\", y=\"count:Q\")\n).properties(\n    title=\"Number of exoplanets discovered per year\",\n    width=600, height=300\n)\nchart\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure()\n\n# vertical stems\nfor xi, yi in zip(df_planets.index, df_planets.values):\n    fig.add_trace(go.Scatter(\n        x=[xi, xi], y=[0, yi],\n        mode=\"lines\",\n        line=dict(color=\"steelblue\"),\n        showlegend=False\n    ))\n\n# markers\nfig.add_trace(go.Scatter(\n    x=df_planets.index, y=df_planets.values,\n    mode=\"markers\",\n    marker=dict(color=\"steelblue\", size=6),\n    name=\"Exoplanets\"\n))\n\nfig.update_layout(\n    title=\"Number of exoplanets discovered per year\",\n    xaxis_title=\"Year\",\n    yaxis_title=\"Count\",\n    yaxis=dict(range=[0, 200], side=\"right\")\n)\nfig.show()",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Common Plots</span>"
    ]
  },
  {
    "objectID": "DV/DV-ComPlots.html#tables",
    "href": "DV/DV-ComPlots.html#tables",
    "title": "11  Common Plots",
    "section": "11.6 Tables",
    "text": "11.6 Tables\n\n11.6.1 Heatmap\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot \nfig, ax = plt.subplots()\nim = ax.imshow(df.to_numpy('f'))\n\n# colorbar\ncbar = ax.figure.colorbar(im, ax=ax)\n\n# ticks and labels\nax.set_xticks(np.arange(len(df.columns)))\nax.set_yticks(np.arange(len(df.index)))\nax.set_xticklabels(df.columns, rotation=90)\nax.set_yticklabels(df.index)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots()\nsns.heatmap(df, cmap=\"viridis\", cbar=True, ax=ax,\n            xticklabels=True, yticklabels=True)\n\nax.set_title(\"Heatmap (Seaborn)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndata = df.reset_index().melt(id_vars=\"index\", var_name=\"Column\", value_name=\"Value\")\n\nchart = (\n    alt.Chart(data)\n    .mark_rect()\n    .encode(\n        x=alt.X(\"Column:N\", title=\"\"),\n        y=alt.Y(\"index:N\", title=\"\"),\n        color=\"Value:Q\"\n    )\n    .properties(title=\"Heatmap (Altair)\", width=400, height=300)\n)\nchart\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure(data=go.Heatmap(\n    z=df.to_numpy(),\n    x=df.columns,\n    y=df.index,\n    colorscale=\"Viridis\"\n))\n\nfig.update_layout(title=\"Heatmap (Plotly)\")\nfig.show()\n\n                            \n                                            \n\n\n\n\n\n\n\n\n11.6.2 Calendar heatmap\n\nimport dayplot as dp\ndf_date = dp.load_dataset()\nprint(df_date.head())\n\n       dates  values\n0 2024-06-17       3\n1 2024-08-22       4\n2 2024-04-03       1\n3 2024-09-20       5\n4 2024-05-22       5\n\n\n\nMatplotlib\n\n\n\n# plot\nfig, ax = plt.subplots(figsize=(15, 6))\ndp.calendar(\n    dates=df_date[\"dates\"],\n    values=df_date[\"values\"],\n    start_date=\"2024-01-01\",\n    end_date=\"2024-12-31\",\n    ax=ax,\n)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11.6.3 Violin plot\n\n# data\nx1 = df[\"X1\"] \nx2 = df[\"X2\"]\n\n\n\nMatplotlibSeabornAltairPlotly\n\n\n\n# plot\nfig, (ax1, ax2) = plt.subplots(nrows = 1, \n                               ncols = 2,\n                               figsize =(9, 4),\n                               sharey = True)\n\n# plot for x1\nax1.set_title('X1 Distribution')\nax1.set_ylabel('Observed values')\nax1.violinplot(x1)\n\n# plot for x2\nax2.set_title('X2 Distribution')\nax2.violinplot(x2)\n\n# Function to show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndata = df.melt(value_vars=[\"X1\", \"X2\"], var_name=\"Variable\", value_name=\"Value\")\n\nfig, ax = plt.subplots(figsize=(7, 4))\nsns.violinplot(data=data, x=\"Variable\", y=\"Value\", ax=ax)\nax.set_title(\"X1 & X2 Distributions\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndata = df.melt(value_vars=[\"X1\", \"X2\"], var_name=\"Variable\", value_name=\"Value\")\n\nviolin = alt.Chart(data).transform_density(\n    \"Value\",\n    groupby=[\"Variable\"],\n    as_=[\"Value\", \"Density\"]\n).mark_area(orient=\"horizontal\").encode(\n    y=\"Value:Q\",\n    x=alt.X(\"Density:Q\", stack=\"center\", impute=None, title=None),\n    color=\"Variable:N\",\n    column=\"Variable:N\"\n).properties(title=\"X1 & X2 Distributions\")\nviolin\n\n\n\n\n\n\n\n\n\n\nfig = go.Figure()\n\nfig.add_trace(go.Violin(y=df[\"X1\"], name=\"X1\", box_visible=True, meanline_visible=True))\nfig.add_trace(go.Violin(y=df[\"X2\"], name=\"X2\", box_visible=True, meanline_visible=True))\n\nfig.update_layout(\n    title=\"X1 & X2 Distributions\",\n    yaxis_title=\"Observed values\"\n)\nfig.show()",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Common Plots</span>"
    ]
  },
  {
    "objectID": "DV/DV-ComPlots.html#reference",
    "href": "DV/DV-ComPlots.html#reference",
    "title": "11  Common Plots",
    "section": "11.7 Reference",
    "text": "11.7 Reference\n\nhttps://aeturrell.github.io/coding-for-economists/vis-common-plots-one.html\nhttps://aeturrell.github.io/coding-for-economists/vis-common-plots-two.html",
    "crumbs": [
      "Data Visualization",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Common Plots</span>"
    ]
  },
  {
    "objectID": "App/App-Proximity.html",
    "href": "App/App-Proximity.html",
    "title": "Appendix B — Proximity",
    "section": "",
    "text": "B.1 What is Proximity?\nThis section introduces the concept of proximity—how similar or dissimilar data objects are—and explains how to measure it in practice.\nProximity measures, including similarity and dissimilarity, play a central role in data analysis and form the foundation of many data mining and machine learning algorithms.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Proximity</span>"
    ]
  },
  {
    "objectID": "App/App-Proximity.html#key-concepts",
    "href": "App/App-Proximity.html#key-concepts",
    "title": "Appendix B — Proximity",
    "section": "",
    "text": "Proximity, a general term referring to either similarity or dissimilarity between two data objects.\nSimilarity indicates how alike two data objects are.\n\nExpressed as a numerical value, typically between 0 and 1.\n\nHigher values indicate greater similarity.\n\nDissimilarity indicates how different two data objects are.\n\nExpressed as a numerical value, often ranging from 0 to ∞.\n\nLower values indicate greater similarity.\n\n\n\nB.1.1 Choosing a Measure\nThe choice of proximity measure depends on the type of attributes:\n\nFor nominal attributes, measures such as the Simple Matching Coefficient (SMC) and the Jaccard Index are commonly used.\nFor numerical attributes, distance-based measures are most common, such as Euclidean distance, Manhattan distance, and Minkowski distance\n\n\n\nB.1.2 Packages\nImport general packages.\n\n# packages for this section\nimport numpy as np\nimport pandas as pd\n\nInstall new packages scipy and scikit-learn, using the following command in the terminal.\n\nconda install scipy scikit-learn",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Proximity</span>"
    ]
  },
  {
    "objectID": "App/App-Proximity.html#measures-for-single-attribute-data",
    "href": "App/App-Proximity.html#measures-for-single-attribute-data",
    "title": "Appendix B — Proximity",
    "section": "B.2 Measures for Single-Attribute Data",
    "text": "B.2 Measures for Single-Attribute Data\nWhen two data objects have only a single attribute, their proximity can be assessed by directly comparing their attribute values. The approach depends on the type of attribute: nominal, ordinal, or numerical.\n\nB.2.1 Nominal Attributes\nFor nominal (categorical) attributes, we can compare values directly using comparison operators1.\n\nThe equality operator == checks if two values are the same.\nThe result is a Boolean (True or False).\nBy converting the Boolean to an integer, we obtain a numerical similarity (1 if equal, 0 otherwise).\n\n\n# Define nominal attribute values\nx = 'WV'\ny = 'PA'\nz = 'WV'\n\n# Similarity (1 if equal, 0 otherwise)\nsim_xy = int(x == y)\nsim_xz = int(x == z)\n\nprint(\"Similarity between x and y:\", sim_xy)\nprint(\"Similarity between x and z:\", sim_xz)\n\nSimilarity between x and y: 0\nSimilarity between x and z: 1\n\n\nDissimilarity can be obtained using the negated equal operator !=, again converted to integers:\n\n# Dissimilarity (1 if different, 0 otherwise)\ndissim_xy = int(x != y)\ndissim_xz = int(x != z)\n\nprint(\"Dissimilarity between x and y:\", dissim_xy)\nprint(\"Dissimilarity between x and z:\", dissim_xz)\n\nDissimilarity between x and y: 1\nDissimilarity between x and z: 0\n\n\n\n\nB.2.2 Ordinal Attributes\nFor ordinal attributes, proximity is based on the rank order of values rather than the raw categories themselves.\nTo compute proximity:\n\nMap ordinal values to numeric ranks (e.g., integer labels based on order).\n\nCompare ranks using distance or difference-based measures.\n\nAs an example, consider grades for five students. Suppose we rank the grades alphabetically2. We can obtain these ranks in Python with the rankdata() function from scipy.stats:\n\nfrom scipy.stats import rankdata\n\n# Sample ordinal data\ndat_grade = [\"A\", \"B\", \"C\", \"D\", \"C\"]\n\n# Rank alphabetically\ndat_grade_rank = rankdata(\n    dat_grade, \n    method='min'     # method='min' assigns ties the lowest rank\n)\nprint(\"Ranked grades:\", dat_grade_rank)\n\nRanked grades: [1 2 3 5 3]\n\n\nOnce the ranks are assigned, we can measure proximity between two objects. For instance, the dissimilarity between the first and third elements is the normalized rank difference:\n\n# Extract ranks of the first and third items\nx = dat_grade_rank[0]\ny = dat_grade_rank[2]\nn = len(dat_grade)\n\n# Dissimilarity: normalized absolute difference\ndis_xy = abs(x - y) / (n - 1)\nprint(\"Dissimilarity between x and y:\", dis_xy)\n\nDissimilarity between x and y: 0.5\n\n\nHere, abs(x - y) gives the absolute rank difference. Dividing by (n - 1) normalizes the dissimilarity to fall between 0 and 1.\nThen, similarity can be derived from dissimilarity by applying a mathematical transformation, as the complement.\n\n# Similarity: 1 - dissimilarity\nsim_xy = 1 - dis_xy\nprint(\"Similarity between x and y:\", sim_xy)\n\nSimilarity between x and y: 0.5\n\n\n\n\nB.2.3 Numerical Attributes\nFor numerical attributes, proximity can be computed directly using numeric operations.\nA common dissimilarity measure is the absolute difference between two values:\n\n# Sample numerical values\nx, y = 65, 45\n\n# Dissimilarity: absolute difference\ndis_xy = abs(x - y)\nprint(\"Dissimilarity:\", dis_xy)\n\nDissimilarity: 20\n\n\n\n\n\n\n\n\nNote\n\n\n\nSimilarity is often derived from dissimilarity by applying a mathematical transformation. Different transformations reflect different assumptions about how similarity should decrease as difference grows.\n\nNegated difference as a simple but unbounded transformation with \\(f(x)= -x\\)::\n\n\n# Similarity as negative dissimilarity\nsim_xy = -dis_xy\nprint(\"Similarity (negated difference):\", sim_xy)\n\nSimilarity (negated difference): -20\n\n\n\nInverse transformation that maps dissimilarity into a bounded similarity score in the range \\((0, 1]\\):\n\n\n# Similarity using inverse transformation\nsim_xy = 1 / (1 + dis_xy)\nprint(\"Similarity (inverse):\", sim_xy)\n\nSimilarity (inverse): 0.047619047619047616\n\n\n\nExponential decay that strongly penalizes larger differences, with \\(f(x)=e^{-x}\\):\n\n\nimport math\n# Similarity using exponential decay\nsim_xy = math.exp(-dis_xy)\nprint(\"Similarity (exponential decay):\", sim_xy)\n\nSimilarity (exponential decay): 2.061153622438558e-09",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Proximity</span>"
    ]
  },
  {
    "objectID": "App/App-Proximity.html#measures-for-multiple-attribute-data",
    "href": "App/App-Proximity.html#measures-for-multiple-attribute-data",
    "title": "Appendix B — Proximity",
    "section": "B.3 Measures for Multiple-Attribute Data",
    "text": "B.3 Measures for Multiple-Attribute Data\nIn most real-world applications, each data object is described by multiple attributes (features).\nMeasuring proximity—whether similarity or dissimilarity—between these multi-attribute objects is essential for tasks such as clustering, classification, and nearest-neighbor search.\nWhen multiple attributes are involved, we consider the entire feature vector of each object and apply a mathematical function that aggregates the differences across all attributes.\n\nB.3.1 Simple Matching Coefficient (SMC)\nThe Simple Matching Coefficient (SMC) is commonly used for binary or nominal attributes. It calculates the proportion of attributes where two objects match.\n\nB.3.1.1 SMC for a Pair of Objects\nSuppose we have two data records xi and xj, each with five binary attributes:\n\n# Define two categorical vectors\nxi = ['Yes', 'No', 'No', 'Yes', 'No']\nxj = ['Yes', 'Yes', 'No', 'Yes', 'No']\n\nWe compare the attributes element-wise with the equality operator == that returns a Boolean value (True if equal, False otherwise):\n\n# Element-wise comparison (Boolean)\nmatches = [a == b for a, b in zip(xi, xj)]\nprint(\"Matching positions:\", matches)\n\nMatching positions: [True, False, True, True, True]\n\n\nSince Python treats True and False as numeric 1 and 0, respectively, we can count matches by summing the Boolean values in the list. Then, dividing by the total number of attributes gives the SMC:\n\n# Compute simple matching coefficient\nnumer = sum(matches)       # Number of matching attributes\ndenom = len(xi)            # Total number of attributes\nsmc = numer / denom        # Simple Matching Coefficient\n\nprint(\"Simple Matching Coefficient:\", smc)\n\nSimple Matching Coefficient: 0.8\n\n\nFor convenience, the computation can be written as a one-liner:\n\n# One-liner SMC computation\nsmc = sum([a == b for a, b in zip(xi, xj)]) / len(xi)\nprint(\"SMC (one-liner):\", smc)\n\nSMC (one-liner): 0.8\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe Simple Matching Coefficient is appropriate when:\n\nAll attributes are equally important, and\nPresence and absence are treated symmetrically (no special emphasis on one category).\n\n\n\n\n\nB.3.1.2 SMC for Multiple Objects\nNow, let’s extend the idea of SMC to a dataset with more than two objects.\nSuppose we have three records xi, xj, and xk, each described by five binary attributes:\n\nimport pandas as pd\n\n# Define three categorical records\nxi = ['Yes', 'No', 'No', 'Yes', 'No']\nxj = ['Yes', 'Yes', 'No', 'Yes', 'No']\nxk = ['No', 'Yes', 'Yes', 'Yes', 'No']\n\n# Combine into a DataFrame\ndat1 = pd.DataFrame(\n    [xi, xj, xk], \n    index=['xi', 'xj', 'xk'],\n    columns=['X1', 'X2', 'X3', 'X4', 'X5']\n)\ndat1\n\n\n\n\n\n\n\n\nX1\nX2\nX3\nX4\nX5\n\n\n\n\nxi\nYes\nNo\nNo\nYes\nNo\n\n\nxj\nYes\nYes\nNo\nYes\nNo\n\n\nxk\nNo\nYes\nYes\nYes\nNo\n\n\n\n\n\n\n\n\nConvert to Binary\nTo compute similarity measures efficiently, it helps to convert categorical attributes into binary form.\nFor example, we can encode whether each attribute equals Yes (presence) or No (absence):\n\n# Convert to binary (logical) format based on 'Yes' responses\ndat1_bin = dat1 == \"Yes\"\ndat1_bin\n\n\n\n\n\n\n\n\nX1\nX2\nX3\nX4\nX5\n\n\n\n\nxi\nTrue\nFalse\nFalse\nTrue\nFalse\n\n\nxj\nTrue\nTrue\nFalse\nTrue\nFalse\n\n\nxk\nFalse\nTrue\nTrue\nTrue\nFalse\n\n\n\n\n\n\n\n\n\nCompute Pairwise SMCs\nPython does not provide a built-in \"simple matching\" metric in typical data science packages.\nHowever, we can leverage the Hamming distance as an equivalent measure for binary attributes, since SMC = 1 – Hamming distance:\n\nHamming distance: proportion of attributes where two objects differ.\n\nSimple Matching Coefficient (SMC): proportion of attributes where two objects match.\n\nThe function pdist() in the module scipy.spatial.distance in scipy package computes pairwise distances between data objects, and then convert them to similarities.\n\nfrom scipy.spatial.distance import pdist, squareform\n\n# Pairwise dissimilarity (Hamming distance)\nhamm_condensed = pdist(dat1_bin, metric='hamming')\nhamm_matrix = squareform(hamm_condensed)\nprint(hamm_matrix)\n\n[[0.  0.2 0.6]\n [0.2 0.  0.4]\n [0.6 0.4 0. ]]\n\n\nThe matrix hamm_matrix above shows the dissimilarities (fraction of mismatches) between each pair of objects. To obtain the Simple Matching Coefficient, subtract from 1:\n\n# Pairwise similarity (SMC = 1 - Hamming)\nsmc_matrix = 1 - hamm_matrix\nprint(smc_matrix)\n\n[[1.  0.8 0.4]\n [0.8 1.  0.6]\n [0.4 0.6 1. ]]\n\n\n\n\nAccessing Specific Similarities\nYou can extract a particular similarity value directly from the matrix. For example, the similarity between xi (row 0) and xk (row 2):\n\ni, j = 0, 2\nsmc_matrix[i, j]\n\nnp.float64(0.4)\n\n\n\n\nCustom Function\nSometimes, the similarity or distance measure you need may not be directly available in existing Python libraries. In such cases, writing a custom function is often the most flexible solution.\nBelow, you can create a custom function simple_matching() that calculates the SMC between two binary records x and y:\n\n# Define a custom function for SMC\ndef simple_matching(x, y):\n    return sum(x == y) / len(x)\n\nUsing the function, the SMC matrix can be obtained:\n\n# Compute pairwise similarity matrix manually\nsmc_matrix_custom = pd.DataFrame(index=dat1_bin.index, columns=dat1_bin.index, dtype=float)\nfor i in dat1_bin.index:\n    for j in dat1_bin.index:\n        smc_matrix_custom.loc[i, j] = simple_matching(dat1_bin.loc[i], dat1_bin.loc[j])\n\nsmc_matrix_custom\n\n\n\n\n\n\n\n\nxi\nxj\nxk\n\n\n\n\nxi\n1.0\n0.8\n0.4\n\n\nxj\n0.8\n1.0\n0.6\n\n\nxk\n0.4\n0.6\n1.0\n\n\n\n\n\n\n\nThis approach directly computes a full similarity matrix across all objects, without relying on built-in metrics.\n\n\n\n\n\n\nTipFlexibility of Approaches\n\n\n\nA given Python task can often be accomplished in several ways. Choosing the right approach depends on factors such as:\n\nPerformance (computational speed for large datasets)\nEase of coding (simplicity and readability)\nCompactness (shorter vs. more explicit code)\nCompatibility (with other tools, packages, or programming languages)\n\nIn such situations,\n\nYou may use existing package functions, following the format required (so that you may need to do some preprocessing).\nYou may define a custom function, giving you full control of the calculation (and possibly incorporating data preprocessing).\nOr, you may combine both strategies, as shown below.\n\n\n# A custom function\ndef simple_nonmatching(x, y):\n    return sum(x != y) / len(x)\n\n# Compute pairwise similarity matrix with pdist in scipy\nsmc_condensed = pdist(dat1_bin, metric=simple_nonmatching)\nsmc_matrix_mix = 1 - squareform(smc_condensed)\nprint(smc_matrix)\n\n[[1.  0.8 0.4]\n [0.8 1.  0.6]\n [0.4 0.6 1. ]]\n\n\nTo make such a decision, always consider:\n\nDo I need to preprocess the data to fit the requirements of a library function?\nWould a custom function be simpler for my dataset and teaching purpose?\nCan I combine both approaches to balance flexibility and efficiency?\n\n\n\n\n\n\n\nB.3.2 Jaccard Coefficient\nThe Jaccard coefficient (also called the Jaccard index) measures the similarity between two records by focusing only on shared positive values.\nUnlike the SMC, the Jaccard coefficient ignores negative–negative matches (False–False) since the absence of attributes is not considered evidence of similarity in many applications (e.g., market basket analysis).\nLet’s compare the two binary records xj and xk from our earlier dat1_bin dataset:\n\n# Extract binary rows for xj and xk\nxj_bin = dat1_bin.loc['xj']\nxk_bin = dat1_bin.loc['xk']\n\n# Display both for comparison\nprint(\n    pd.DataFrame([xj_bin, xk_bin], index=['xj', 'xk'])\n)\n\n       X1    X2     X3    X4     X5\nxj   True  True  False  True  False\nxk  False  True   True  True  False\n\n\n\nB.3.2.1 Counting Possible Combinations\nFor each attribute, the pair (xj, xk) can take one of four combinations:\n\nTrue–True → positive-positive (count_pp)\nTrue–False → positive-negative (count_pn)\nFalse–True → negative-positive (count_np)\nFalse–False → negative-negative (count_nn)\n\nWe can count these cases as follows:\n\n# Count different value combinations\ncount_pp = ((xj_bin == True) & (xk_bin == True)).sum()\ncount_pn = ((xj_bin == True) & (xk_bin == False)).sum()\ncount_np = ((xj_bin == False) & (xk_bin == True)).sum()\ncount_nn = ((xj_bin == False) & (xk_bin == False)).sum()\n\n# Show as a 2x2 matrix in a DataFrame\nprint(\n    pd.DataFrame(\n        np.array([[count_pp, count_pn], [count_np, count_nn]]),\n        index=[\"True\", \"False\"],\n        columns=[\"True\", \"False\"]\n    )\n)\n\n       True  False\nTrue      2      1\nFalse     1      1\n\n\nAlternatively, you can get this same result using crosstab() in pandas:\n\n# Cross-tabulation using pandas\nprint(\n    pd.crosstab(xj_bin.astype(bool), xk_bin.astype(bool), rownames=['xj'], colnames=['xk'])\n)\n\nxk     False  True \nxj                 \nFalse      1      1\nTrue       1      2\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe use .astype(bool) to ensure the values are treated as Boolean categories (True/False), which makes the crosstab() result clearer.\n\n\n\n\nB.3.2.2 Compute Jaccard Similarity\nThe Jaccard coefficient measures similarity by focusing only on attributes where at least one record is positive (True).\nFormally:\n\\[\nJ(x_j, x_k) = \\frac{\\#( \\text{Positive–Positive} )}{\\#( \\text{Positive–Positive, Positive–Negative, Negative–Positive} )}\n\\]\nThat is, the similarity is the ratio of shared positives to all attributes with at least one positive.\n\nnumer = count_pp\ndenom = count_pp + count_pn + count_np\njaccard_coeff = numer / denom\njaccard_coeff\n\nnp.float64(0.5)\n\n\nOr, you can also calculate the Jaccard coefficient matrix using jaccard_score() in sklearn.metrics:\n\nfrom sklearn.metrics import jaccard_score\n\n# Apply Jaccard similarity on binary rows (must convert to numpy or pandas arrays internally)\njaccard_score(dat1_bin.loc['xj'], dat1_bin.loc['xk'], average='binary')\n\nnp.float64(0.5)\n\n\nAlternatively, you can compute the whole Jaccard distance matrix using scipy’s pdist():\n\n# Compute Jaccard distance (1 - similarity)\njaccard_dist = pdist(dat1_bin, metric='jaccard')\njaccard_sim_matrix = 1 - squareform(jaccard_dist)\n\n# Format as a DataFrame\nprint(pd.DataFrame(jaccard_sim_matrix, index=dat1_bin.index, columns=dat1_bin.index))\n\n          xi        xj    xk\nxi  1.000000  0.666667  0.25\nxj  0.666667  1.000000  0.50\nxk  0.250000  0.500000  1.00\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIn scipy, pdist(..., metric='jaccard') returns the distance (i.e., 1 - similarity).\n\n\n\n\n\nB.3.3 Numerical Attributes\nConsider a dataset with three objects—xi, xj, and xk—each described by two numerical attributes:\n\nX1: Average time spent online (hours)\n\nX2: Number of orders during the last month\n\n\nimport pandas as pd\n\n# Create a DataFrame with numerical attributes\ndat2 = pd.DataFrame({\n    'X1': [2, 3, 3],  # Average time spent online\n    'X2': [3, 0, 4]   # Number of orders during the last month\n}, index=['xi', 'xj', 'xk'])\nprint(dat2)\n\n    X1  X2\nxi   2   3\nxj   3   0\nxk   3   4\n\n\nFor demonstration, let’s extract two records (xi and xj) as vectors:\n\n# Extract specific data points as Series\nxi = dat2.loc['xi']\nxj = dat2.loc['xj']\n\nprint(\"xi:\", xi.to_list())\nprint(\"xj:\", xj.to_list())\n\nxi: [2, 3]\nxj: [3, 0]\n\n\nWith numerical attributes, we can compute a variety of distance and similarity measures such as\n\nEuclidean distance → straight-line (L2) distance between vectors\nManhattan distance → sum of absolute differences (L1 distance)\nCosine similarity → similarity based on the angle between vectors\nCorrelation coefficient → similarity based on linear relationship\n\n\nB.3.3.1 Distance\nDistances are commonly used as dissimilarity measures between numerical data objects.\n\nEuclidean Distance\nThe Euclidean distance between two objects \\(\\mathbf{x}_i\\) and \\(\\mathbf{x}_j\\) is defined as:\n\\[\nd(\\mathbf{x}_i, \\mathbf{x}_j) = \\sqrt{ \\sum_{k=1}^{N}(x_{ik} - x_{jk})^2 },\n\\]\nInstead of manual computation, we can use built-in functions from scipy.spatial.distance or sklearn.metrics\nYou can use functions from scipy.spatial.distance or sklearn.metrics3 to compute the distance between rows:\n\nfrom scipy.spatial.distance import euclidean\n\n# Compute Euclidean distance between xi and xj\neuclidean(dat2.loc['xi'], dat2.loc['xj'])\n\nnp.float64(3.1622776601683795)\n\n\n\n# Combine xi and xj into a matrix\ndat2_ij = dat2.loc[['xi', 'xj']]\n\n# Compute Euclidean distance\neuclidean(dat2_ij.loc['xi'], dat2_ij.loc['xj'])\n\nnp.float64(3.1622776601683795)\n\n\nTo compute pairwise Euclidean distances across all rows, use scipy.spatial.distance.pdist() with metric='euclidean':\n\nfrom scipy.spatial.distance import pdist, squareform\n\n# Pairwise Euclidean distances\ndist_matrix_euclidean = pd.DataFrame(\n    squareform(pdist(dat2, metric='euclidean')),\n    index=dat2.index, columns=dat2.index\n)\nprint(dist_matrix_euclidean)\n\n          xi        xj        xk\nxi  0.000000  3.162278  1.414214\nxj  3.162278  0.000000  4.000000\nxk  1.414214  4.000000  0.000000\n\n\n\n\n\n\n\n\nNoteSteps for manual computation and the codes\n\n\n\n\nCompute element-wise differences\n\nSquare the differences\n\nSum the squared differences\n\nTake the square root of the sum\n\n\ndiff = xi - xj                              # 1) xik - xjk for each attribute k\ndiff_sqr = diff ** 2                        # 2) (xik - xjk)^2\ndiff_sqr_sum = diff_sqr.sum()               # 3) sum((xi - xj)^2)\neuclidean_manual = np.sqrt(diff_sqr_sum)    # 4) sqrt(sum((xi - xj)^2))\neuclidean_manual\n\nnp.float64(3.1622776601683795)\n\n\n\n\n\n\n\nB.3.3.2 Other Distance Metrics\nBesides Euclidean, several other distance metrics are useful in practice:\nManhattan Distance (City Block), \\(d(\\mathbf{x}_i, \\mathbf{x}_j) = \\sum_{k=1}^{N} |x_{ik} - x_{jk}|\\):\n\n# Manhattan (L1) distance matrix\ndist_matrix_manhattan = pd.DataFrame(\n    squareform(pdist(dat2, metric='cityblock')),\n    index=dat2.index, columns=dat2.index\n)\nprint(dist_matrix_manhattan)\n\n     xi   xj   xk\nxi  0.0  4.0  2.0\nxj  4.0  0.0  4.0\nxk  2.0  4.0  0.0\n\n\nMinkowski Distance (Generalized form with parameter p), \\(d(\\mathbf{x}_i, \\mathbf{x}_j) = \\Bigg( \\sum_{k=1}^{N} |x_{ik} - x_{jk}|^p \\Bigg)^{\\tfrac{1}{p}}\\):\n\n# Minkowski distance with p = 1.5\ndist_matrix_minkowski = pd.DataFrame(\n    squareform(pdist(dat2, metric='minkowski', p=1.5)),\n    index=dat2.index, columns=dat2.index\n)\nprint(dist_matrix_minkowski)\n\n          xi        xj        xk\nxi  0.000000  3.373505  1.587401\nxj  3.373505  0.000000  4.000000\nxk  1.587401  4.000000  0.000000\n\n\nChebyshev Distance (Minkowski with \\(p\\rightarrow\\infty\\), \\(d(\\mathbf{x}_i, \\mathbf{x}_j) = \\max_{k} \\, |x_{ik} - x_{jk}|\\):\n\n# Chebyshev (maximum coordinate difference)\ndist_matrix_chebyshev = pd.DataFrame(\n    squareform(pdist(dat2, metric='chebyshev')),\n    index=dat2.index, columns=dat2.index\n)\nprint(dist_matrix_chebyshev)\n\n     xi   xj   xk\nxi  0.0  3.0  1.0\nxj  3.0  0.0  4.0\nxk  1.0  4.0  0.0\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll of these distance metrics are available through scipy.spatial.distance.pdist(), which provides an efficient way to compute pairwise distances for entire datasets.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Proximity</span>"
    ]
  },
  {
    "objectID": "App/App-Proximity.html#related-readingreference",
    "href": "App/App-Proximity.html#related-readingreference",
    "title": "Appendix B — Proximity",
    "section": "B.4 Related Reading/Reference",
    "text": "B.4 Related Reading/Reference\n\nChapter 11.2 in Business Analytics: communicating with Numbers, 2nd ed. (Jaggia et al., 2023)\nChapter 2.4 in Introduction to Data Mining, 2nd ed. (Tan et al., 2019)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Proximity</span>"
    ]
  },
  {
    "objectID": "App/App-Proximity.html#footnotes",
    "href": "App/App-Proximity.html#footnotes",
    "title": "Appendix B — Proximity",
    "section": "",
    "text": "Check the comparison operator in 4. Data Type↩︎\nAlphabetical ranking is used here for illustration. In practice, rankings should reflect the true ordinal meaning of the categories.↩︎\nAs the distance calculation is widely used in data science, there are many packages available for the same computation.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Proximity</span>"
    ]
  },
  {
    "objectID": "S/S-Front.html",
    "href": "S/S-Front.html",
    "title": "Supervised Methods",
    "section": "",
    "text": "This chapter explores supervised data mining methods\n\nClassification\n\nk-nearest neighbors",
    "crumbs": [
      "Supervised Methods"
    ]
  },
  {
    "objectID": "S/S-Front.html#overview",
    "href": "S/S-Front.html#overview",
    "title": "Supervised Data Mining",
    "section": "",
    "text": "Classification\n\nPartial Clustering\nHierarchical Clustering\nDensity-based Clustering\n\nRegression\n\nLinear Models\nNonlinear Models\nModels with Regularization\nGeneralized Linear Models\nSupport Vector Regression\n\nPattern Mining\n\nAssociation Rules\nRecommendation Systems\n\nFeature Engineering\n\nFeature Extraction\nFeature Selection (Filter Methods)",
    "crumbs": [
      "Supervised Methods"
    ]
  },
  {
    "objectID": "S/S-Front.html#related-reading",
    "href": "S/S-Front.html#related-reading",
    "title": "Supervised Data Mining",
    "section": "Related Reading",
    "text": "Related Reading\n\nChapters in the course textbook\n\nchapter 2 of Business Analytics - Communicating with numbers\n\nWebsites for R textbook\n\nSection 3.3, 3.4, 3.5 of An Introduction to R\nSections 7 of Beginning Computer Science with R",
    "crumbs": [
      "Supervised Methods"
    ]
  },
  {
    "objectID": "S/SC-KNN.html",
    "href": "S/SC-KNN.html",
    "title": "12  k-Nearest Neighbors",
    "section": "",
    "text": "12.1 What is kNN?\nThis section introduces k-nearest neighbors (kNN), a distance-based algorithm used in data mining tasks such as classification and regression.\nkNN is a simple but powerful algorithm:\nFor classification of new samples, kNN is based on the class labels of the k nearest neighbors. - A sample is assigned to the majority class among its k nearest neighbors.\n- If k=1, the sample takes the class of its single nearest neighbor.\nAlso, for regression (known as kNN regression or nearest neighbor smoothing), kNN is based on the target values of the k nearest neighbors. - The prediction is the average of the values of the k nearest neighbors.",
    "crumbs": [
      "Supervised Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "S/SC-KNN.html#what-is-knn",
    "href": "S/SC-KNN.html#what-is-knn",
    "title": "12  k-Nearest Neighbors",
    "section": "",
    "text": "As a non-parametric method that makes no assumptions about the data distribution.\nAs a lazy learning algorithm because it does not build a model during training.\n\nInstead, prediction happens (the algorithm finds its k nearest neighbors from the training data) when a test sample is given.\n\n\n\n\n\n12.1.1 The Core kNN Algorithm\nPrediction in kNN involves:\n\nCalculating the distance from the query point to all training examples.\n\nSorting distances.\n\nSelecting the k nearest neighbors.\n\nMaking a prediction1, using majority vote (classification) or averaging (regression).\n\n\n\n12.1.2 Distance Metrics\nTo identify nearest neighbors, defining “closeness” of a sample to another requires a distance measure such as Euclidean distance , Manhattan distance (L1 norm), Minkowski distance, Hamming distance and Correlation-based measures ( sometimes used for specialized data, such as gene expression or time-series).\nThe choice of distance metric can significantly affect the accuracy of the kNN algorithm.\n\n\n\n\n\n\nNoteThe Importance of Feature Scaling\n\n\n\nSince kNN is based on distance calculations, its performance can be distorted if features are measured on different scales or in different units.\n\nStandardization (Z-score normalization): rescales features so they have mean 0 and standard deviation 1.\n\nMin–max scaling: rescales features to a fixed range, typically [0, 1].\n\nScaling ensures that all features contribute equally to distance calculations, preventing variables with larger numeric ranges from dominating the results.",
    "crumbs": [
      "Supervised Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "S/SC-KNN.html#knn-classifier",
    "href": "S/SC-KNN.html#knn-classifier",
    "title": "12  k-Nearest Neighbors",
    "section": "12.2 kNN classifier",
    "text": "12.2 kNN classifier\n\n12.2.1 Packages\nLet’s import general packages first.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n12.2.2 Data\nLet’s create a simple data set of the input features X_tr and the class labels Y_tr, which will be used for the training:\n\n# Example using make_blobs [23]\nfrom sklearn.datasets import make_blobs\ncenters = [[ 1, 2 ], [ 7, 10 ]]\nn_classes = len(centers)\nX_tr, y_tr = make_blobs(\n    n_samples=10, \n    centers=np.array(centers), \n    random_state=1\n)\ndf_tr = pd.DataFrame(X_tr, columns=['X1','X2'])\ndf_tr['Y'] = y_tr\ndf_tr\n\n\n\n\n\n\n\n\nX1\nX2\nY\n\n\n\n\n0\n8.462108\n7.939859\n1\n\n\n1\n8.133769\n8.900109\n1\n\n\n2\n6.677583\n9.615946\n1\n\n\n3\n2.624345\n1.388244\n0\n\n\n4\n1.865408\n-0.301539\n0\n\n\n5\n7.042214\n10.582815\n1\n\n\n6\n2.744812\n1.238793\n0\n\n\n7\n0.471828\n0.927031\n0\n\n\n8\n6.827572\n9.122142\n1\n\n\n9\n1.319039\n1.750630\n0\n\n\n\n\n\n\n\nAnd, let’s create another data set of the input features X_new and the class labels Y_new, using the same method:\n\n# new data generation\nX_new, y_new = make_blobs(\n    n_samples=5, \n    centers=np.array(centers), \n    random_state=2\n)\ndf_new = pd.DataFrame(X_new, columns=['X1','X2'])\ndf_new['Y'] = y_new\ndf_new\n\n\n\n\n\n\n\n\nX1\nX2\nY\n\n\n\n\n0\n7.502881\n8.754712\n1\n\n\n1\n-0.793436\n1.158253\n0\n\n\n2\n-1.136196\n3.640271\n0\n\n\n3\n0.583242\n1.943733\n0\n\n\n4\n5.942048\n9.090992\n1\n\n\n\n\n\n\n\n\n12.2.2.1 Visualizing the Training and New Data\nBefore applying kNN, it is helpful to visualize the datasets to see how the training and new points are distributed in feature space.\n\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(5, 4))\n\n# Training points (circles), color by class label\nscatter_tr = ax.scatter(\n    df_tr['X1'], df_tr['X2'],\n    s=70, marker='o', label='Training'\n)\n\n# New points (X markers), color by class label\nscatter_new = ax.scatter(\n    df_new['X1'], df_new['X2'],\n    s=120, marker='x', label='New'\n)\n\n# Labels and title\nax.set_title(\"Training points (circles) and new points (X)\")\nax.set_xlabel(\"X1\")\nax.set_ylabel(\"X2\")\nax.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n12.2.3 Implementation with Scikit-learn (sklearn)\nInstead of manually coding kNN, you can use the KNeighborsClassifier available in scikit-learn.\nThe neighbors module in sklearn provides efficient implementations of nearest-neighbor algorithms and supports both NumPy arrays and SciPy sparse matrices as input.\n\n12.2.3.1 Step 1: Instantiate the KNeighborsClassifier\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Instantiate with chosen parameters\nknn = KNeighborsClassifier(\n    n_neighbors=5,       # number of neighbors\n    metric='minkowski',  # distance metric\n    p=2                  # power parameter (p=2 → Euclidean, p=1 → Manhattan)\n)\n\nThis example consider some key parameters:\n\nn_neighbors (int, default=5): The number of neighbors to consider for the classification vote.\nmetric (str or callable, default=‘minkowski’): The distance metric used. Default ‘minkowski’ with p=2 is Euclidean.\np (float, default=2): The power parameter for the Minkowski metric (1 for Manhattan, 2 for Euclidean).\n\nIf parameters are not explicitly set, the defaults are used (e.g., knn = KNeighborsClassifier()).\n\n\n12.2.3.2 Step 2: Fit the Classifier to Training Data\n\n# Train kNN classifier\nknn.fit(X_tr, y_tr)\n\nKNeighborsClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifier?Documentation for KNeighborsClassifieriFittedKNeighborsClassifier() \n\n\n\n\n12.2.3.3 Step 3: Make Predictions on New Data\n\n# Predict labels for new data points\npredicted_labels = knn.predict(X_new)\n\nprint(\"Predictions from the classifier:\", predicted_labels)\nprint(\"True labels:                    \", y_new)\n\nPredictions from the classifier: [1 0 0 0 1]\nTrue labels:                     [1 0 0 0 1]\n\n\n\n\n\n12.2.4 Manual Procedure for Classification with kNN\nTo better understand how kNN works, let’s go through manual implementation of the classification steps with kNN.\n\n12.2.4.1 Step 1: Calculate Distances\nFirst, compute the distances between each training point in X_tr and each new point in X_new.\n\nfrom sklearn.metrics import pairwise_distances\n\n# Compute Euclidean distance between all training points and the new point\ndistances = pairwise_distances(X_tr, X_new)\n\nprint( 'Matrix shape', distances.shape, '\\n')\nprint( distances.round(3) )\n\nMatrix shape (10, 5) \n\n[[ 1.259 11.474 10.517  9.901  2.771]\n [ 0.647 11.817 10.658 10.267  2.2  ]\n [ 1.193 11.285  9.837  9.798  0.904]\n [ 8.835  3.426  4.383  2.115  8.387]\n [10.668  3.033  4.955  2.586 10.239]\n [ 1.885 12.256 10.728 10.787  1.854]\n [ 8.895  3.539  4.564  2.274  8.478]\n [10.522  1.286  3.154  1.023  9.827]\n [ 0.769 11.023  9.668  9.514  0.886]\n [ 9.343  2.194  3.098  0.761  8.675]]\n\n\nHere, the result is a matrix of shape (len(X_tr), len(X_new)), and its element at row i, column j is the distance between training sample i and new sample j.\n\n\n12.2.4.2 Step 2: Identify Nearest Neighbors\nFor simplicity, let’s focus on the classification of the 4th new point in X_new (i.e., j = 3). We extract the column of distances corresponding to that new point:\n\nj = 3  # index of the 4th new point\ndistances_j = distances[:, j]\ndistances_j\n\narray([ 9.9010128 , 10.26652927,  9.79815453,  2.11534182,  2.58557423,\n       10.78666086,  2.27361468,  1.02278815,  9.51426297,  0.76071422])\n\n\nThen, rank (sort) them based on the resulted distances, by using np.argsort() that returns the indexes:\n\n# Sort indices by distance (ascending order)\nindices_sorted_by_distance = np.argsort(distances_j)\nindices_sorted_by_distance\n\narray([9, 7, 3, 6, 4, 8, 2, 0, 1, 5])\n\n\nGiven a predetermined neighbor size k (as a user parameter), define a set for the neighbors of the jth point in X_new by taking the top (i.e., closest to the jth example) k points in X_tr:\n\n# Get indices of the k closest points\nk = 3\nneighbor_indices = indices_sorted_by_distance[:k]\nneighbor_indices\n\narray([9, 7, 3])\n\n\n\n\n12.2.4.3 Step 3: Retrieve Neighbor Labels\nRetrieve the class labels for the nearest neighbors.\n\nneighbor_labels = y_tr[neighbor_indices]\nneighbor_labels\n\narray([0, 0, 0])\n\n\n\n\n12.2.4.4 Step 4: Plurality vote\nFinally, assign the class label of the new point by majority vote (mode) of its neighbors’ labels:\n\nfrom collections import Counter\n\n# Get the most frequent label (mode)\nmost_common = Counter(neighbor_labels).most_common(1)[0][0]\nmost_common\n\nnp.int64(0)\n\n\n\n\n\n\n\n\nNoteVoronoi Diagram\n\n\n\nWhen (k = 1), the decision boundary of the kNN classifier corresponds to the borders of a Voronoi diagram. Each region in the diagram contains all points that are closest to a particular training point.\nThe visualization below shows how the training data divides the input space into such regions.\n\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\n\n# Create Voronoi diagram from training data\nvor = Voronoi(X_tr)\n\n# Plot the Voronoi diagram\nfig = plt.figure(figsize=(6, 6))\nvoronoi_plot_2d(\n    vor, \n    show_vertices=False, \n    line_colors='gray', \n    line_width=1, \n    line_alpha=0.6, \n    point_size=10\n)\n\n# Overlay training points with class-based colors\ncolors = ['blue', 'green', 'purple']\nfor i, point in enumerate(X_tr):\n    plt.scatter(\n        point[0], point[1], \n        color=colors[y_tr[i]], \n        s=70, \n        label=f'Class {y_tr[i]}' if f'Class {y_tr[i]}' not in plt.gca().get_legend_handles_labels()[1] else \"\"\n    )\n\n# Plot new data points\nplt.scatter(\n    X_new[:, 0], X_new[:, 1], \n    c='red', marker='*', s=200, \n    label='New point'\n)\n\n# Labels and formatting\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.title('Voronoi Diagram (k=1 Decision Boundaries)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n&lt;Figure size 576x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nThis plot visually demonstrates how kNN with k=1 partitions the input space:\n\nEach cell (region) is assigned to the class of the nearest training point.\nNew data points fall into one of these cells and are classified accordingly.",
    "crumbs": [
      "Supervised Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "S/SC-KNN.html#reference",
    "href": "S/SC-KNN.html#reference",
    "title": "12  k-Nearest Neighbors",
    "section": "12.4 Reference",
    "text": "12.4 Reference\n\nChapter 12.1, 12.2 in Business Analytics: communicating with Numbers, 2nd ed. (Jaggia et al., 2023)\nChapter 4.3 in Introduction to Data Mining, 2nd ed. (Tan et al., 2019)",
    "crumbs": [
      "Supervised Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "S/SC-KNN.html#footnotes",
    "href": "S/SC-KNN.html#footnotes",
    "title": "12  k-Nearest Neighbors",
    "section": "",
    "text": "Weights can be assigned to neighbors so that closer neighbors contribute more strongly, often using inverse distance weighting.↩︎",
    "crumbs": [
      "Supervised Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "App/App-Proximity.html#what-is-proximity",
    "href": "App/App-Proximity.html#what-is-proximity",
    "title": "Appendix B — Proximity",
    "section": "",
    "text": "Proximity, a general term referring to either similarity or dissimilarity between two data objects.\nSimilarity indicates how alike two data objects are.\n\nExpressed as a numerical value, typically between 0 and 1.\n\nHigher values indicate greater similarity.\n\nDissimilarity indicates how different two data objects are.\n\nExpressed as a numerical value, often ranging from 0 to ∞.\n\nLower values indicate greater similarity.\n\n\n\nB.1.1 Choosing a Measure\nThe choice of proximity measure depends on the type of attributes:\n\nFor nominal attributes, measures such as the Simple Matching Coefficient (SMC) and the Jaccard Index are commonly used.\nFor numerical attributes, distance-based measures are most common, such as Euclidean distance, Manhattan distance, and Minkowski distance\n\n\n\nB.1.2 Packages\nImport general packages.\n\n# packages for this section\nimport numpy as np\nimport pandas as pd\n\nInstall new packages scipy and scikit-learn, using the following command in the terminal.\n\nconda install scipy scikit-learn",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Proximity</span>"
    ]
  },
  {
    "objectID": "S/SC-KNN.html#knn-for-classification",
    "href": "S/SC-KNN.html#knn-for-classification",
    "title": "12  k-Nearest Neighbors",
    "section": "12.2 kNN for classification",
    "text": "12.2 kNN for classification\n\n12.2.1 Packages\nLet’s import general packages first.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n12.2.2 Data\nWe can use sklearn.datasets.make_blobs() to generate a synthetic dataset with well-separated clusters. This is useful for demonstrating how k-NN works on simple 2D data.\nLet’s first create a simple data set of the input features X_tr and the class labels Y_tr, which will be used for the training:\n\nfrom sklearn.datasets import make_blobs\n\n# Define the centers of the clusters (each corresponds to a class)\ncenters = [[ 1, 2 ], [ 7, 10 ]]            # the center coordinates of each data class\n\n# Generate training data\nX_tr, y_tr = make_blobs(\n    n_samples=10,               # number of data samples to generate\n    centers=np.array(centers),  # cluster centers\n    random_state=123            # fixed seed to control the \"random\" creation for reproducibility\n)\n\n# Convert to a DataFrame for easier handling\ndf_tr = pd.DataFrame(X_tr, columns=['X1','X2'])\ndf_tr['Y'] = y_tr\ndf_tr\n\n\n\n\n\n\n\n\nX1\nX2\nY\n\n\n\n\n0\n9.205930\n12.186786\n1\n\n\n1\n-0.085631\n2.997345\n0\n\n\n2\n0.421400\n3.651437\n0\n\n\n3\n6.321114\n9.905291\n1\n\n\n4\n1.282978\n0.493705\n0\n\n\n5\n8.491390\n9.361098\n1\n\n\n6\n6.556018\n9.565649\n1\n\n\n7\n2.265936\n1.133260\n0\n\n\n8\n-1.426679\n1.571087\n0\n\n\n9\n8.004054\n10.386186\n1\n\n\n\n\n\n\n\nWe can also generate a separate set of samples to use as new (test) data with the input features X_new and the class labels Y_new. These samples will be classified later using the kNN algorithm trained on the earlier dataset.\n\n# Generate new data (same cluster centers as training set)\nX_new, y_new = make_blobs(\n    n_samples=5,                # number of new data samples\n    centers=np.array(centers),  # same cluster centers as training\n    random_state=456            # different seed for reproducibility\n)\n\n# Convert to DataFrame\ndf_new = pd.DataFrame(X_new, columns=['X1', 'X2'])\ndf_new['Y'] = y_new\ndf_new\n\n\n\n\n\n\n\n\nX1\nX2\nY\n\n\n\n\n0\n2.350509\n3.629589\n0\n\n\n1\n0.331871\n1.501790\n0\n\n\n2\n6.654189\n9.684769\n1\n\n\n3\n1.618576\n2.568692\n0\n\n\n4\n7.301966\n10.449483\n1\n\n\n\n\n\n\n\n\n12.2.2.1 Visualizing the Training and New Data\nBefore applying kNN, it is helpful to visualize the datasets to see how the training and new samples are distributed in feature space.\n\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(5, 4))\n\n# Training samples (circles), color by class label\nscatter_tr = ax.scatter(\n    df_tr[df_tr['Y']==0]['X1'], df_tr[df_tr['Y']==0]['X2'],\n    s=70, marker='^', label='Training, Y=0'\n)\nscatter_tr = ax.scatter(\n    df_tr[df_tr['Y']==1]['X1'], df_tr[df_tr['Y']==1]['X2'],\n    s=70, marker='v', label='Training, Y=1'\n)\n\n# New samples (X markers), color by class label\nscatter_new = ax.scatter(\n    df_new['X1'], df_new['X2'],\n    s=120, marker='o', label='New'\n)\n\n# Labels and title\nax.set_title(\"Training samples and new samples (X)\")\nax.set_xlabel(\"X1\")\nax.set_ylabel(\"X2\")\nax.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n12.2.3 Implementation with Scikit-learn (sklearn)\nInstead of manually coding kNN, you can use the KNeighborsClassifier available in scikit-learn.\nThe neighbors module in sklearn provides efficient implementations of nearest-neighbor algorithms and supports both NumPy arrays and SciPy sparse matrices as input.\n\n12.2.3.1 Step 1: Instantiate the KNeighborsClassifier\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Instantiate with chosen parameters\nknn = KNeighborsClassifier(\n    n_neighbors=5,       # number of neighbors\n    metric='minkowski',  # distance metric\n    p=2                  # power parameter (p=2 → Euclidean, p=1 → Manhattan)\n)\n\nThis example consider some key parameters:\n\nn_neighbors (int, default=5): The number of neighbors to consider for the classification vote.\nmetric (str or callable, default=‘minkowski’): The distance metric used. Default ‘minkowski’ with p=2 is Euclidean.\np (float, default=2): The power parameter for the Minkowski metric (1 for Manhattan, 2 for Euclidean).\n\nIf parameters are not explicitly set, the defaults are used (e.g., knn = KNeighborsClassifier()).\n\n\n12.2.3.2 Step 2: Fit the Classifier to Training Data\n\n# Train kNN classifier\nknn.fit(X_tr, y_tr)\n\nKNeighborsClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifier?Documentation for KNeighborsClassifieriFittedKNeighborsClassifier() \n\n\n\n\n12.2.3.3 Step 3: Make Predictions on New Data\n\n# Predict labels for new data samples\npredicted_labels = knn.predict(X_new)\n\nprint(\"Predictions from the classifier:\", predicted_labels)\nprint(\"True labels:                    \", y_new)\n\nPredictions from the classifier: [0 0 1 0 1]\nTrue labels:                     [0 0 1 0 1]\n\n\n\n\n\n12.2.4 Manual Procedure for Classification with kNN\nTo better understand how kNN works, let’s go through manual implementation of the classification steps with kNN.\n\n12.2.4.1 Step 1: Calculate Distances\nFirst, compute the distances between each training point in X_tr and each new point in X_new.\n\nfrom sklearn.metrics import pairwise_distances\n\n# Compute Euclidean distance between all training samples and the new point\ndistances = pairwise_distances(X_tr, X_new)\n\nprint( 'Matrix shape', distances.shape, '\\n')\nprint( distances.round(3) )\n\nMatrix shape (10, 5) \n\n[[10.965 13.889  3.574 12.251  2.577]\n [ 2.517  1.553  9.495  1.757 10.493]\n [ 1.929  2.152  8.675  1.614  9.672]\n [ 7.426 10.319  0.399  8.714  1.122]\n [ 3.313  1.386 10.645  2.102 11.634]\n [ 8.4   11.329  1.865  9.663  1.612]\n [ 7.275 10.187  0.154  8.564  1.157]\n [ 2.498  1.969  9.612  1.575 10.59 ]\n [ 4.302  1.76  11.451  3.204 12.451]\n [ 8.81  11.739  1.521 10.094  0.705]]\n\n\nHere, the result is a matrix of shape (len(X_tr), len(X_new)), and its element at row i, column j is the distance between training sample i and new sample j.\n\n\n12.2.4.2 Step 2: Identify Nearest Neighbors\nFor simplicity, let’s focus on the classification of the 4th new point in X_new (i.e., j = 3). We extract the column of distances corresponding to that new point:\n\nj = 3  # index of the 4th new point\ndistances_j = distances[:, j]\ndistances_j\n\narray([12.2505377 ,  1.75728856,  1.61417649,  8.7143299 ,  2.10195063,\n        9.66293669,  8.56362865,  1.57465629,  3.20449589, 10.09393606])\n\n\nThen, rank (sort) them based on the resulted distances, by using np.argsort() that returns the indexes:\n\n# Sort indices by distance (ascending order)\nindices_sorted_by_distance = np.argsort(distances_j)\nindices_sorted_by_distance\n\narray([7, 2, 1, 4, 8, 6, 3, 5, 9, 0])\n\n\nGiven a predetermined neighbor size k (as a user parameter), define a set for the neighbors of the jth point in X_new by taking the top (i.e., closest to the jth example) k samples in X_tr:\n\n# Get indices of the k closest samples\nk = 3\nneighbor_indices = indices_sorted_by_distance[:k]\nneighbor_indices\n\narray([7, 2, 1])\n\n\n\n\n12.2.4.3 Step 3: Retrieve Neighbor Labels\nRetrieve the class labels for the nearest neighbors.\n\nneighbor_labels = y_tr[neighbor_indices]\nneighbor_labels\n\narray([0, 0, 0])\n\n\n\n\n12.2.4.4 Step 4: Plurality vote\nFinally, assign the class label of the new point by majority vote (mode) of its neighbors’ labels:\n\nfrom collections import Counter\n\n# Get the most frequent label (mode)\nmost_common = Counter(neighbor_labels).most_common(1)[0][0]\nmost_common\n\nnp.int64(0)\n\n\n\n\n\n\n\n\nNoteVoronoi Diagram\n\n\n\nWhen (k = 1), the decision boundary of the kNN classifier corresponds to the borders of a Voronoi diagram. Each region in the diagram contains all samples that are closest to a particular training sample.\nThe visualization below shows how the training data divides the input space into such regions.\n\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\n\n# Create Voronoi diagram from training data\nvor = Voronoi(X_tr)\n\n# Plot the Voronoi diagram\nfig = plt.figure(figsize=(6, 6))\nvoronoi_plot_2d(\n    vor, \n    show_vertices=False, \n    line_colors='gray', \n    line_width=1, \n    line_alpha=0.6, \n    point_size=10\n)\n\n# Overlay training samples with class-based colors\ncolors = ['blue', 'green', 'purple']\nfor i, point in enumerate(X_tr):\n    plt.scatter(\n        point[0], point[1], \n        color=colors[y_tr[i]], \n        s=70, \n        label=f'Class {y_tr[i]}' if f'Class {y_tr[i]}' not in plt.gca().get_legend_handles_labels()[1] else \"\"\n    )\n\n# Plot new data samples\nplt.scatter(\n    X_new[:, 0], X_new[:, 1], \n    c='red', marker='*', s=200, \n    label='New point'\n)\n\n# Labels and formatting\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.title('Voronoi Diagram (k=1 Decision Boundaries)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n&lt;Figure size 576x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nThis plot visually demonstrates how kNN with k=1 partitions the input space:\n\nEach cell (region) is assigned to the class of the nearest training point.\nNew data samples fall into one of these cells and are classified accordingly.",
    "crumbs": [
      "Supervised Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "S/SC-KNN.html#knn-for-regression",
    "href": "S/SC-KNN.html#knn-for-regression",
    "title": "12  k-Nearest Neighbors",
    "section": "12.3 kNN for Regression",
    "text": "12.3 kNN for Regression\nWhile kNN is often introduced as a classification algorithm, it can also be applied to regression tasks. In this case, instead of predicting a class label, the algorithm predicts a numerical value for a new data point.\n\nStep 1-4. Select neighbors: Identify the k closest training samples to the query point, using a distance metric (e.g., Euclidean).\n\nStep 5. Aggregate values: Take the average (or sometimes weighted average) of the target values of these neighbors.\n\nStep 6. Prediction Assign this aggregated value as the prediction for the new point.\n\nFor a new point \\(\\mathbf{x}_{new}\\), the prediction is:\n\n\\[\n  \\hat{y}(\\mathbf{x}_{new}) = \\frac{1}{k} \\sum_{i \\in \\mathcal{N}_k(\\mathbf{x}_{new})} y_i\n  \\]\nwhere:\n\n\\(\\mathcal{N}_k(\\mathbf{x})\\) is the set of the k nearest neighbors of \\(\\mathbf{x}\\).\n\n\\(y_i\\) is the target value of neighbor \\(i\\).\n\n\n\n12.3.1 Example with Scikit-learn\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.neighbors import KNeighborsRegressor\n\n# Generate a simple regression dataset for training\nX_train, y_train = make_regression(n_samples=40, n_features=1, noise=2, random_state=1)\nX_test, y_test = make_regression(n_samples=20, n_features=1, noise=2, random_state=1)\n\n# Fit k-NN regression model\nknn_reg = KNeighborsRegressor(n_neighbors=3, weights='distance')\nknn_reg.fit(X_train, y_train)\n\n# Predict on a grid of values\nX_test = np.linspace(X_train.min()-1, X_train.max()+1, 100).reshape(-1, 1)\ny_pred = knn_reg.predict(X_test)\n\n# Plot\nfig, ax = plt.subplots()\nax.scatter(X_train, y_train, c='blue', label='Training data')\nax.plot(X_test, y_pred, c='red', label='k-NN regression (k=3)')\nax.set_title(\"k-NN Regression\")\nax.set_xlabel(\"X\")\nax.set_ylabel(\"y\")\nax.legend()\nplt.show()",
    "crumbs": [
      "Supervised Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "S/SC-KNN.html#example-with-scikit-learn",
    "href": "S/SC-KNN.html#example-with-scikit-learn",
    "title": "12  k-Nearest Neighbors",
    "section": "12.4 Example with Scikit-learn",
    "text": "12.4 Example with Scikit-learn\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.neighbors import KNeighborsRegressor\n\n# Generate a simple regression dataset for training\nX_train, y_train = make_regression(n_samples=40, n_features=1, noise=2, random_state=1)\nX_test, y_test = make_regression(n_samples=20, n_features=1, noise=2, random_state=1)\n\n# Fit k-NN regression model\nknn_reg = KNeighborsRegressor(n_neighbors=3, weights='distance')\nknn_reg.fit(X_train, y_train)\n\n# Predict on a grid of values\nX_test = np.linspace(X_train.min()-1, X_train.max()+1, 100).reshape(-1, 1)\ny_pred = knn_reg.predict(X_test)\n\n# Plot\nfig, ax = plt.subplots()\nax.scatter(X_train, y_train, c='blue', label='Training data')\nax.plot(X_test, y_pred, c='red', label='k-NN regression (k=3)')\nax.set_title(\"k-NN Regression\")\nax.set_xlabel(\"X\")\nax.set_ylabel(\"y\")\nax.legend()\nplt.show()",
    "crumbs": [
      "Supervised Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "S/SC-KNN.html#readingreference",
    "href": "S/SC-KNN.html#readingreference",
    "title": "12  k-Nearest Neighbors",
    "section": "12.4 Reading/Reference",
    "text": "12.4 Reading/Reference\n\nChapter 12.1, 12.2 in Business Analytics: communicating with Numbers, 2nd ed. (Jaggia et al., 2023)\nChapter 4.3 in Introduction to Data Mining, 2nd ed. (Tan et al., 2019)",
    "crumbs": [
      "Supervised Methods",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "PD/PD-Front.html",
    "href": "PD/PD-Front.html",
    "title": "Predictive Modeling",
    "section": "",
    "text": "This chapter explores predictive modeling methods\n\nk-nearest neighbors",
    "crumbs": [
      "Predictive Modeling"
    ]
  },
  {
    "objectID": "PY/PY-Front.html",
    "href": "PY/PY-Front.html",
    "title": "Python Basics",
    "section": "",
    "text": "This chapter introduces Python basics:\n\nGetting Started\n\nPython\nSetting Python Development Environment\n\nConcepts and Syntax\n\nExpression and Operators\nStatements and Variables\nIndentation\nComments\n\nData Types\n\nBuilt-in Data Types\nNumbers\nStrings\nBoolean Values\nLists\nDictionaries\n\nFunctions and Packages\n\nFunctions\nModules and Packages\n\n(Optional) Classes and Methods\n\nClasses\nMethods",
    "crumbs": [
      "Python Basics"
    ]
  },
  {
    "objectID": "PY/PY-GetStarted.html",
    "href": "PY/PY-GetStarted.html",
    "title": "2  Getting Started",
    "section": "",
    "text": "2.1 Overview\nThis section provides you with a basic idea about this course’s main tool, Python, and a brief instruction of setting up the computational environment (e.g., Python version, libraries, etc.).",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PY/PY-GetStarted.html#python",
    "href": "PY/PY-GetStarted.html#python",
    "title": "2  Getting Started",
    "section": "2.2 Python",
    "text": "2.2 Python\nIn business analytics, learning a programming language is valuable (often essential) since many tasks are more efficiently done with computer and code. Once you become familiar with a programming language and its core concepts (like variables, loops, data structures), learning other languages often becomes easier, though each has its own syntax and paradigm-specific features. Once you become familiar with a language, learning other languages (including ones, like R or C++, specialized to specific tasks) becomes much easier, where most of the programming concepts similarly apply across most languages.\n\n2.2.1 What is Python?\nPython is a high-level, interpreted programming language created in 1991 by Guido van Rossum.\n\nBeing high-level means it abstracts away many of the low-level details of computer operation, such as memory management, so that programmers can focus on problem-solving rather than machine instructions.\nIt is also an interpreted language, which means Python code does not need to be compiled before execution. Instead, the Python interpreter reads and executes the code line by line, making it highly flexible for testing and development.\nA key feature of Python is its emphasis on simplicity and readability. Its syntax is designed to resemble plain English, which makes programs easier to write, understand, and maintain. This characteristic has made Python a very accessible language for beginners, while still powerful enough for advanced applications.\nPython is also cross-platform. It runs consistently on Windows, macOS, and Linux, and it integrates well with other languages such as C, C++, and Java. This versatility has contributed significantly to its widespread adoption.\nFinally, Python is open-source and supported by a global community. Anyone can contribute to its development, expand its libraries, and share tools. As a result, Python has evolved into one of the most widely used and versatile programming languages today.\n\n\n\n2.2.2 Why Python?\nPython has become one of the most popular programming languages in the world, especially for data science, machine learning, and business analytics.\n\n\n\nZDNet’s programming language popularity index as of 2024 (Image source link).\n\n\nThe reasons include:\n\nPython has an extensive ecosystem of libraries and frameworks. These libraries are ready-made toolkits that extend Python’s core capabilities. For example, pandas allows efficient handling of tabular data, numpy provides fast numerical computations, matplotlib and seaborn enable data visualization, and scikit-learn supports machine learning. This broad set of tools makes Python highly adaptable to tasks in business analytics, data mining, and visualization.\nPython offers high productivity. Its simple and readable syntax allows users to express ideas in fewer lines of code compared to many other programming languages. This reduces development time and makes it easier to test and debug. The interpreted nature of Python also enables interactive development, where code can be tested incrementally without needing to compile full programs.\nPython benefits from a strong and active global community. Because it is open-source, the language is constantly improved and expanded. Documentation, tutorials, and Q&A forums are widely available, meaning that support is easily accessible. This strong community ensures that Python stays relevant and up to date with evolving technologies.\n\nIn summary, Python is popular because it combines power and flexibility with accessibility. These qualities make it an excellent language for exploring data, performing analysis, and creating clear, visual insights.\n\n\n2.2.3 Where to Use Python?\nPython is a general-purpose programming language, which means it can be applied across a wide variety of domains. Some common uses1 include:\n\nWeb development: Creating websites and web applications using frameworks such as Django and Flask.\nData analysis and visualization: Working with structured and unstructured data, cleaning it, analyzing patterns, and presenting results visually with libraries like pandas, matplotlib, and seaborn.\nMachine learning and artificial intelligence: Building predictive models, natural language processing systems, and intelligent applications with libraries such as scikit-learn, TensorFlow, or PyTorch.\nScientific computing: Performing simulations, optimization, and large-scale computations in research and engineering.\nAutomation and scripting: Writing scripts to automate repetitive tasks, system processes, or business workflows.\nDesktop and GUI applications: Developing standalone tools or user-friendly applications with interfaces.\n\n\n\n2.2.4 Online Materials for Python\nThere are many resources available online for learning and troubleshooting Python. - The Python Documentation is one of the great sources for the information, which includes explanations, examples, and reference material for every part of the language. - The Python Wiki provides curated information including Beginner’s Guide separately for non-programmers and those with prior programming experience. - Beyond that, platforms such as Stack Overflow, Real Python, Geeks for Geeks, and various tutorials offer practical examples and solutions.\n\n\n\n\n\n\nNoteTutorials and beginner guides\n\n\n\nFrom the Python Software Foundation and Python Wiki.\n\nFor nonprogrammer\nFor programmer (know other programming languages)\n\n\n\n\n\n2.2.5 Python Versions\nPython exists in two major versions2 — Python 2 and Python 3.\n\nPython 2 was widely used for many years but reached its official end-of-life in January 2020. This means it no longer receives updates, bug fixes, or security patches. Some legacy codebases may still use Python 2, but it is no longer recommended for new development.\nPython 3 is the current and actively maintained version of the language. All modern libraries and tools are built for Python 3, and this is the version we will use throughout this course. Specifically, we will rely on Python 3.11, which is stable, well-supported, and compatible with the libraries we need for data mining and visualization.\n\n\n\n\n\n\n\nTip\n\n\n\nWhen you encounter tutorials or examples online, you may still see some written for Python 2. The syntax and behavior can differ in subtle but important ways, so always confirm that the code is written for the version you are using.\n\n\n\n\n2.2.6 Python Environment\nBefore diving into coding, it’s important to understand a Python (development) environment3 as the setup that allows you to write and run Python code. Often, you cannot even use Python without a proper development environment.\nThere are a number of ways to build development environments for python with various programs. At this time, let’s learn one way for building a properly configured environment to ensure that your code runs consistently, both on your machine and on others’.\nA Python environment typically includes core components that together define where and how your code will run:\n\nOperating system (OS) you’re working on (e.g., macOS) with a computer\nProgramming language (e.g., Python 3.11) that enables the computer to interpret and execute the code\nPackages that extend Python’s capabilities for various tasks\n\nTo set up a efficient Python environment, you can additionally consider:\n\nAn Integrated Development Environment (IDE) that is a tool to write and execute code (in a convenient way)\nVirtual environments that enables the development separately by project in isolated setups",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PY/PY-GetStarted.html#setting-python-development-environment-local",
    "href": "PY/PY-GetStarted.html#setting-python-development-environment-local",
    "title": "2  Getting Started",
    "section": "2.3 Setting Python Development Environment (Local)",
    "text": "2.3 Setting Python Development Environment (Local)\nThe following instruction is for a python environment on your own computer. The overall installation is as follow:\n\nInstall Anaconda/Conda as a platform for virtual environments\nInstall Python in a virtual environment\nInstall Jupyter Notebook as an IDE in the virtual environment\n\n\n2.3.1 Installing Anaconda (and Conda)\nDifferent projects often require different environment setups. That’s when a virtual environment comes in handy, which helps to work on isolated Python environments where you can freely create/delete them (with no risk of messing up your entire computer).\n\n2.3.1.1 Virtual Environment\nA virtual environment allows you to create a self-contained workspace where Python and all required libraries are stored separately from the system-wide installation.\nAnaconda/Conda is a popular software to manage virtual environments. To manage Python environments, we will use Anaconda/Conda.\n\nConda\n\nA package as the environment manager that creates isolated environments and installs packages (Python, R, C/Fortran libs, CUDA toolkits, etc.).\nWorks with any “distribution” (Anaconda, Miniconda, Miniforge).\n\nAnaconda\n\nA bundled distribution that includes conda, Python, Anaconda Navigator (GUI), and hundreds of prebuilt packages and Jupyter—all in one installer.\nBig install (~GBs), great for offline or “everything ready” setups.\n\n\n\n\n\n\n\n\nNoteWhy Use Conda to Install Python?\n\n\n\nInstalling Python through Conda (via Anaconda or Miniconda—minimal version of Anaconda) is highly recommended for this course, especially for users working with data science and analytics tools.\nHere’s why:\n\nIsolated Environments: Conda allows you to create separate environments for different projects. Each environment can have its own version of Python and packages—preventing version conflicts.\nBetter Package Management: Unlike pip (Python’s default package manager), Conda can install not just Python packages but also system-level dependencies like C or Fortran libraries. This is especially helpful for scientific packages like numpy, scipy, and pytorch.\nCross-Platform Compatibility: Conda works consistently across Windows, macOS, and Linux. It is also used by most cloud data science environments, helping ensure reproducibility.\nFast Setup with Anaconda: The Anaconda distribution includes over 250 pre-installed data science packages (e.g., pandas, matplotlib, scikit-learn, jupyterlab), making it ideal for beginners and fast onboarding.\nScientific Computing Support: Many data science and machine learning tools depend on optimized compiled libraries. Conda handles these dependencies more reliably than pip.\nReproducible, portable environments that “just work,” especially in data science: Conda is the most robust choice.\n\n\n\n\n\n\n2.3.2 Installing Python in Virtual Environment through Conda\nTo install Python, we’re going to use the command-line interface (CLI), because it’s simple to lightly handle environments, packages, and version control via the terminal.\n\n\n\n\n\n\nNoteThe Terminal in Brief\n\n\n\nThe command-line interface (also known as the command-line  and sometimes the command prompt) is a text-based interface that allows users to interact with the system (software) via command, each of which is formatted as a line of text, to your computer. In there, a command interpreter (also known as a command-line interpreter, command processor, or shell) is a program that implements a user’s commands via a CLI, acting like a bridge between the user and the operating system’s internal functions.\nMost OS’s (Linux, Mac, and Windows) have a built-in command-line program:\n\nthe PowerShell on Windows.\n\nSearch PowerShell and open it (without activating a conda environment which will be discussed below).\nOr, install PowerShell Prompt in Anaconda and run it in the virtual environment (activating it).\n\nthe Terminal on macOS\n\nSearch “Terminal” and open it\nTerminal User Guide\n\nthe Terminal on Linux\n\nSearch “Terminal” (the default Bash and open it\nThe Linux command line for beginners\nUsingTheTerminal - Ubuntu documantation\n\n\n\n\n\n\n2.3.2.1 Installing Anaconda\nInstalling Anaconda Distribution is the official website for the installation, in which the step-by-step procedure is documented well.\n\n\n2.3.2.2 Creating a Virtual Environment\nOnce you open the installed Anaconda on your computer, you start the Anaconda GUI on the base environment where your OS directly interact and that it is recommended not to use for projects. Instead of working on the base, let’s create a new one.\nTo do that, let’s open a terminal\n\nIn Windows, any prompt on the Anaconda GUI (e.g., Powershell Prompt, CMD.exe Prompt, or anaconda_prompt) — Not directly from Windows\nIn macOS/Linux, the OS’s terminal\n\nIn the terminal’s prompt, you should have (base) that indicates the current environment.\nA new environment with a name buda450_py311 can be created with the following command:\nconda create --name buda450_py311\nIn the command, you can replace buda450_py311 with the name you want for the environment. After completing the creation, the environment can be activated with the following command:\nconda activate buda450_py311\nCheck more details from Managing environments and about other Commands .\n\n\n2.3.2.3 Installing Python and Programs/Packages\nThen, Python can be installed through the following command.\nconda install python=3.11\nHere, Python’s version is specified (i.e., python 3.11). Without the version specification like conda install python, Python will be installed based on the conda’s default version.\n\n\n\n\n\n\nTipCreating an environment with python installation\n\n\n\nBy including programs/packages (and its versions) in the command, you can install them together when the environment is created.\nconda create --name buda450_py311 python=3.11\n\n\nSimilarly, some programs useful for Python can be installed in Conda environments.\nThe following command installs Jupyter’s Notebook and JupyterLab together.\nconda install notebook jupyterlab\n\n\n\n\n\n\nNote\n\n\n\nIn this course, we will use conda to install packages because it’s relatively more generic and convenient for tasks dealing with environments and complex dependencies, compared with pip. See the explanation in link for more details.\n\n\nSimilarly, you can install packages by executing a commend. For example, let’s install three pacakges\n\nnumpy for comprehensive numerical, mathematical operations as a basis of many advanced data science packages, by entering the following commend into the command line in your terminal.\npandas for data analysis and manipulation\nmatplotlib for creating static, animated, and interactive visualizations.\n\nconda install numpy pandas matplotlib\n\n\n\n\n\n\nWarning\n\n\n\nSometimes, the name of a package for installation may differ from its full name or for import.\nFor example, scikit-learn is a package for data mining and machine learning tasks. To install it, we use the name scikit-learn:\nconda install scikit-learn\nHowever, the package is called sklearn.\n\nimport sklearn\nprint(sklearn.__version__)\n\n1.6.1\n\n\nSo, it’s recommended to always check the exact commands from the original website (e.g., pandas) and repositories (e.g., anaconda’s Python Package Index (PyPi)).",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PY/PY-GetStarted.html#footnotes",
    "href": "PY/PY-GetStarted.html#footnotes",
    "title": "2  Getting Started",
    "section": "",
    "text": "https://www.python.org/about/apps/↩︎\nMany versions documented in Python Documentation by Version.↩︎\nA Python environment consists of all the tools and configurations that allow you to write, run, and manage Python programs efficiently.↩︎",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "PY/PY-Basics.html",
    "href": "PY/PY-Basics.html",
    "title": "3  Concepts and Syntax",
    "section": "",
    "text": "3.1 Expressions and Operators\nThis section introduces fundamental concepts and syntax in python, including basic programming concepts and syntax, operators, and data types.\nAn expression is a piece of syntax which can be evaluated to some value. The detailed definitions are available in 6. Expressions (ver. 3.11).\nThe following expression is a simple expression for mathematical operation with the “addition” operator +:\n1 + 1\n\n2\nBy using a combination of multiple operators, an expression for complex computation can be computed.\n8**2 - 5%7\n\n59\nAs shown in this example, many different operators can be used in Python. Here are operators for arthmatic operations:\nSee more operators from https://www.w3schools.com/python/python_operators.asp\nWhen you run (i.e., evaluate) an expression, the operations in the expression are evaluated in the “PEMDAS” order:\nIn the previous example, if some elements and operations were in parentheses, the result becomes different:\n(8**2 - 5) % 7\n\n3",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PY/PY-Basics.html#expressions-and-operators",
    "href": "PY/PY-Basics.html#expressions-and-operators",
    "title": "3  Concepts and Syntax",
    "section": "",
    "text": "Operator\nOperation\nExample\nEvaluation\n\n\n\n\n+\nAddition\n4 + 3\n7\n\n\n-\nSubtraction\n18 - 4\n14\n\n\n*\nMultiplication\n7 * 8\n56\n\n\n/\nDivision\n30 / 6\n5\n\n\n%\nModulus/Remainder\n34 % 6\n4\n\n\n**\nExponent/Power\n3 ** 3\n27\n\n\n\n\n\n\nParentheses\nExponents\nMultiplication and Division (from left to right)\nAddition and Subtraction (from left to right)",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PY/PY-Basics.html#statements-and-variables",
    "href": "PY/PY-Basics.html#statements-and-variables",
    "title": "3  Concepts and Syntax",
    "section": "3.2 Statements and Variables",
    "text": "3.2 Statements and Variables\nA statement is part of a suite (a “block” of code) as a syntactic unit the interpreter executes.\nLet’s start with a simple statement for assignment. In Python terms, an assignment (re)binds a name to a value. In other words, we assign a value to a variable to bind a name to an object, where variables are containers for storing objects (e.g., data values).\nFor example, the following statement is about the assignment of a value (computed from an expression) to a variable result:\n\nresult = (8**2 - 5) % 7\n\nBy doing so, we can refer to the stored value later, reuse it, update program state, pass information between parts of a program, and make code clearer to humans.\nFor example, the stored value can be called by using print() function, which display the output, and can be reused:\n\nprint( result )\nprint( result + 4 )\n\n3\n7\n\n\nTo be specific, Python divides statements into - simple statements (single logical line, e.g., expression statements and assignment) - compound statements (control flow or definition blocks that contain other statements, e.g., if, for, while, try, with, and def) that contain (groups of) other statements.\nLater, we will revisit some of those that are helpful for our tasks. The detailed definitions are available in 7. Simple statements and 8. Compound statements (ver. 3.11).\n\n3.2.1 Output versus printing\nIn the examples above, the output was displayed below the cell either from the excution or through print(). When you run a code line by line in the interactive environment (e.g., the interactive interpreter and Jupyter notebook), the output will be displayed. But, it will not work when you have more lines.\nIn the example below we run two lines after two assignments. When not using the print(), only the output of the last operation in the cell is printed.\n\nfirst_value = 111\nsecond_value = 222\nfirst_value\nsecond_value\n\n222\n\n\nFurther, if the last operation is for some other (e.g., the assignment of a variable) rather than referring to a value, nothing will be printed.\n\nfirst_value\nsecond_value\nsomething_else = \"abc\"\n\nIn such situation, print() is used to print output to the screen.\n\nprint( first_value )\nprint( second_value )\nsomething_else = \"abc\"\n\n111\n222\n\n\nRule of thumb: - use the normal output for quick checking the output of an operation while developing in an interactive environment. - use print() for controling what is printed when, while developing more complicated codes (often in long codes or scripts).",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PY/PY-Basics.html#indentation",
    "href": "PY/PY-Basics.html#indentation",
    "title": "3  Concepts and Syntax",
    "section": "3.3 Indentation",
    "text": "3.3 Indentation\nIndentation refers to the spaces at the beginning of a code line. The indentation in Python is very important, while the indentation in code in other programming languages is for readability only.\nPython uses indentation to indicate a block of code. For example, the following is if statement (a compound statement) that contains a condition and a suite of two simple statements (excution of print() on two lines). This statement will return the result of the print() only if the condition is met.\n\nif 5 &gt; 2:\n    print(\"Is five greater than two?\")\n    print(\"Yes!\")\n\nIs five greater than two?\nYes!\n\n\nBased on the identation, your code may lead to a different result, as the suite for the statement is differently defined and interpreted by Python.\n\nif -7 &gt; 3:\n    print(\"Is five greater than two?\")\nprint(\"Yes!\")\n\nOn the other hand, Python will give you an error if the indentation is either omitted in a statemet that expects an indented suite:\n\nif 5 &gt; 2:\nprint(\"Is five greater than two?\")\nprint(\"Yes!\")\n\nAlso, you have to use the same level (number of spaces) in the same block of code, otherwise Python will give you an error:\n\nif 5 &gt; 2:\n    print(\"Is five greater than two?\")\n  print(\"Yes!\")",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PY/PY-Basics.html#comments",
    "href": "PY/PY-Basics.html#comments",
    "title": "3  Concepts and Syntax",
    "section": "3.4 Comments",
    "text": "3.4 Comments\nPython has commenting capability for the purpose of in-code documentation. Comments start with a sharp #, and Python will render the rest of the line, ignoring the rest of the line.\nComments can be added to your code in two typical ways. - a single-line comment can be placed for a one-liner note to explain the following lines:\n\n# This is a single-line comment. 1 + 1 will be NOT calculated by Python.\nprint(\"Hello, World!\")\n\nHello, World!\n\n\n\na inline comment can be placed right next to an expression to explain it:\n\n\nprint( 3 + 2 ) # addition\nprint( 3 - 2 ) # substraction\nprint( 3 * 2 ) # multiplication\nprint( 3 / 2 ) # division\n\n5\n1\n6\n1.5\n\n\nMany developers use comments for various purpose. You can check some best practices discussed in many online posts including How to Use Python Comments Effectively?.",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PY/PY-Basics.html#reference",
    "href": "PY/PY-Basics.html#reference",
    "title": "3  Concepts and Syntax",
    "section": "3.5 Reference",
    "text": "3.5 Reference\n\nhttps://uofsclibraries-drs.github.io\nhttps://www.w3schools.com/python-",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Concepts and Syntax</span>"
    ]
  },
  {
    "objectID": "PY/PY-Data.html",
    "href": "PY/PY-Data.html",
    "title": "4  Data Types",
    "section": "",
    "text": "4.1 Built-in Data Types in Python\nThis section introduces built-in data types in Python.\nPython has various built-in data types, categorized as follows:\nAll expression evaluate to a single value. In the above examples, the expression evaluated to single numerical value. Numerical values come in two basic forms:",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PY/PY-Data.html#built-in-data-types-in-python",
    "href": "PY/PY-Data.html#built-in-data-types-in-python",
    "title": "4  Data Types",
    "section": "",
    "text": "Category\nData Type\nExample\n\n\n\n\nNumeric\nint\n20\n\n\nNumeric\nfloat\n20.5\n\n\nNumeric\ncomplex\n1j\n\n\nText\nstr\n\"Hello World\"\n\n\nSequence\nlist\n[\"apple\", \"banana\", \"cherry\"]\n\n\nSequence\ntuple\n(\"apple\", \"banana\", \"cherry\")\n\n\nSequence\nrange\nrange(6)\n\n\nMapping\ndict\n{\"name\": \"John\", \"age\": 36}\n\n\nSet\nset\n{\"apple\", \"banana\", \"cherry\"}\n\n\nSet\nfrozenset\nfrozenset({\"apple\", \"banana\", \"cherry\"})\n\n\nBoolean\nbool\nTrue\n\n\nBinary\nbytes\nb\"Hello\"\n\n\nBinary\nbytearray\nbytearray(5)\n\n\nBinary\nmemoryview\nmemoryview(bytes(5))\n\n\nNone\nNoneType\nNone",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PY/PY-Data.html#numbers",
    "href": "PY/PY-Data.html#numbers",
    "title": "4  Data Types",
    "section": "4.2 Numbers",
    "text": "4.2 Numbers\nThere are three numeric types in Python. Let’s enter each type in Python and check it by using the type() that returns the type of the specified object.\n\nint: Int, or integer, is a whole number, positive or negative, without decimals, of unlimited length.\n\n\n# int\nprint( 123 ) \nprint( type( 123 ) )\n\n123\n&lt;class 'int'&gt;\n\n\n\nfloat: Float, or “floating point number” is a number, positive or negative, containing one or more decimals.\n\n\nprint( 3.14 )\nprint( type( 3.14 ) )\n\n3.14\n&lt;class 'float'&gt;\n\n\n- Float can also be scientific numbers with an \"e\" to indicate the power of 10.\n\nprint( 987e5 )\nprint( 1.23e-3 )\n\n98700000.0\n0.00123\n\n\n\ncomplex: Complex numbers are written with a real number + a j as the imaginary part:\n\n\nprint( 1.5+4j )\nprint( type( 1.5+4j ) )\n\n(1.5+4j)\n&lt;class 'complex'&gt;\n\n\n\nint( 3.14 )\n\n3",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PY/PY-Data.html#strings",
    "href": "PY/PY-Data.html#strings",
    "title": "4  Data Types",
    "section": "4.3 Strings",
    "text": "4.3 Strings\nA snippet of text in Python is called a string. Strings in python are surrounded by either single quotation marks ', or double quotation marks \".\nFor example, 'hello' is the same as \"hello\". To evaluate whether two values are equal, we can use two equals signs == between them. The expression will evaluate to either True or False (see below for Boolean value).\n\n'hello' == \"hello\"\n\nTrue\n\n\nA string can contain letters, spaces, line breaks, and numbers. When a non-text value is embraced by quotation marks, it becomes a string, and Python treats it differently. For example, an integer 5 is converted to a string with quotation marks.\n\nprint( type(\"5\") )\n\n&lt;class 'str'&gt;\n\n\n\n# Compare an integer with the same meaning in other types\nprint( 5 == 5.0 )    # integer vs float\nprint( 5 == '5' )    # integer vs string \n\nTrue\nFalse\n\n\nThe distinction between each of these data types may seem unimportant, but it is. This is because an operator performs different operations, depending on the data type.\nFor example, the addition + for strings conbine two strings, called concatenation, exactly as they are in the order of the strings in the expression:\n\n# Combine the strings 'Hello' and 'World'\n'hello' + ' world'\n\n'hello world'\n\n\nHowever, using such operators may cause an error when the operators are applied to different types (e.g., numeric and non-numeric).\n\n# Try adding a string to an integer\n'5' + 7",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PY/PY-Data.html#boolean-values",
    "href": "PY/PY-Data.html#boolean-values",
    "title": "4  Data Types",
    "section": "4.4 Boolean Values",
    "text": "4.4 Boolean Values\nIn programming, you often need to know whether an expression is true or not. Booleans is a way to represent one of two possible values, True or False.\nIn Python, Boolean values can be handled by entering exactly True or False (case-sensitive).\n\nprint( False )\nprint( type(False) )\n\nFalse\n&lt;class 'bool'&gt;\n\n\nIn Python, the Boolean values True and False can be converted into numeric values 1 and 0, respectively.\n\nprint( int(True) )\nprint( float(False) )\n\n1\n0.0\n\n\n\n4.4.1 Comparison Operators\nComparison operators in Python are used to compare two values.\n\n\n\nOperator\nName\nExample\n\n\n\n\n==\nEqual\nx == y\n\n\n!=\nNot equal\nx != y\n\n\n&gt;\nGreater than\nx &gt; y\n\n\n&lt;\nLess than\nx &lt; y\n\n\n&gt;=\nGreater than or equal to\nx &gt;= y\n\n\n&lt;=\nLess than or equal to\nx &lt;= y\n\n\n\nAs shown in the example about strings, the == operator returns True if two values are equal to each other.\n\nprint( 5 == 5.0 )             # If the values are the same, an integer and a float are the same\nprint( 5 == \"five\" )          # A string cannot be equal to a float or an integer.\nprint( \"Five\" == \"five\" )     # Strings with different cases are not the same.\n\nTrue\nFalse\nFalse\n\n\n\n\n4.4.2 Logical Operators\nLogical operators are used to combine Boolean values (e.g., from conditional statements).\n\n\n\n\n\n\n\n\nOperator\nDescription\nExample\n\n\n\n\nand\nTrue if both statements are true\nx &lt; 5 and x &lt; 10\n\n\nor\nTrue if at least one statement is true\nx &lt; 5 or x &lt; 4\n\n\nnot\nReverses the result (Boolean negation)\nnot (x &lt; 5 and x &lt; 10)\n\n\n\nThe operation with a logical operator for two Boolean values returns a single Boolean value.\nFor example, when both statements are True, the and operator returns True\n\n# When (condition one is True) AND (condition two is True):\ncond1 = 1 &lt; 6\ncond2 = 4 &lt; 6\nprint( cond1 and cond2 )\nprint( True and True )\n\nTrue\nTrue\n\n\n\n# When (condition one is True) AND (condition two is False):\nprint( True and False )\n\nFalse\n\n\nConsidering two possible values of the statements, all possible combinations and their and results can be organized in a Truth table:\n\n\n\nCondition 1\nLogical operator\nCondition 2\nEvaluation\n\n\n\n\nTrue\nand\nTrue\nTrue\n\n\nTrue\nand\nFalse\nFalse\n\n\nFalse\nand\nTrue\nFalse\n\n\nFalse\nand\nFalse\nFalse\n\n\n\nSimilarly, create a Truth table that shows all possible results from or operator with two statements.\n\n\n\nCondition 1\nLogical operator\nCondition 2\nEvaluation\n\n\n\n\nTrue\nand\nTrue\nTrue\n\n\nTrue\nand\nFalse\nTrue\n\n\nFalse\nand\nTrue\nTrue\n\n\nFalse\nand\nFalse\nFalse\n\n\n\nLastly, the not operator only operates on a single expression for Boolean negation (i.e., flipping True to False or False to `True.\n\n# The not operator flips a True to False\nprint(not True)\nprint(not False)\n\nFalse\nTrue",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PY/PY-Data.html#lists",
    "href": "PY/PY-Data.html#lists",
    "title": "4  Data Types",
    "section": "4.5 Lists",
    "text": "4.5 Lists\nLists are one of four built-in data types that are used to store multiple items. Lists are created using square brackets [], and each item of any data type can be included with delimiter , in such ways of [item1, item2, item3, item4, ...].\n\n# A list of three integers \nint_list = [2, 4, 6, 8]\nprint( int_list )\nprint( type( int_list ) )\n\n[2, 4, 6, 8]\n&lt;class 'list'&gt;\n\n\n\n# A list of three mixed types \nmixed_list = [-0.2, 'car', False]\nprint( mixed_list )\nprint( type( mixed_list ) )\n\n[-0.2, 'car', False]\n&lt;class 'list'&gt;\n\n\n\n# An empty list\nempty_list = []\nprint( empty_list )\nprint( type( empty_list ) )\n\n[]\n&lt;class 'list'&gt;\n\n\n\n# A list of lists\nlists_list = [ int_list, mixed_list, empty_list] \nprint( lists_list )\nprint( type( lists_list ) )\n\n[[2, 4, 6, 8], [-0.2, 'car', False], []]\n&lt;class 'list'&gt;\n\n\nList items are presented in the order stored, and can be referred to by using the index.\n\nprint(int_list[0])     # first item of int_list\nprint(int_list[-1])     # the last item of int_list\n\n2\n8\n\n\nWe can change the value of any item in a list using an assignment statement that contains the item’s index number.\n\n# Changing the value of an item in a list\nAnimal = ['Cat', 'Dog', 'Bear']\nprint(Animal)\n\n['Cat', 'Dog', 'Bear']\n\n\n\n# Changing an item using an assignment state with index number\nAnimal[1] = 'Lion'\nprint(Animal)\n\n['Cat', 'Lion', 'Bear']",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PY/PY-Data.html#dictionaries",
    "href": "PY/PY-Data.html#dictionaries",
    "title": "4  Data Types",
    "section": "4.6 Dictionaries",
    "text": "4.6 Dictionaries\nDictionaries are another built-in data types storing multiple items. Dictionaries are created using curly brackets {}, and each item has a unique key paired with some value by : such that { key1 : value1, key2 : value2, key3 : value3, ...}\n\n# A dictionary of three integers \nint_dict = {\"Math\": 95, \"History\": 55, \"Art\": 70}\nprint( int_dict )\nprint( type( int_dict ) )\n\n{'Math': 95, 'History': 55, 'Art': 70}\n&lt;class 'dict'&gt;\n\n\n\n# A dictionary of mixed values\nmixed_dict = {\"Age\": 23, \"State\": \"WV\", \"Membership\": True, 'Ordered': [\"Shoes\", \"Socks\"]}\nprint( mixed_dict )\nprint( type( mixed_dict ) )\n\n{'Age': 23, 'State': 'WV', 'Membership': True, 'Ordered': ['Shoes', 'Socks']}\n&lt;class 'dict'&gt;\n\n\nDictionary items are presented in key:value pairs, and can be referred to by using the key name.\n\nprint(mixed_dict[\"Ordered\"])\n\n['Shoes', 'Socks']\n\n\nTo access a item of a list in the dictionary, an additional bracket with its index can be placed after the first indexing expression.\n\nprint(mixed_dict[\"Ordered\"][1])\n\nSocks",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PY/PY-Data.html#reference",
    "href": "PY/PY-Data.html#reference",
    "title": "4  Data Types",
    "section": "4.7 Reference",
    "text": "4.7 Reference\n\nhttps://uofsclibraries-drs.github.io\nhttps://www.w3schools.com/python-",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Types</span>"
    ]
  },
  {
    "objectID": "PY/PY-Fn-Pack.html",
    "href": "PY/PY-Fn-Pack.html",
    "title": "5  Functions and Packages",
    "section": "",
    "text": "5.1 Function\nThis section introduces functions and packages in Python.\nA function is a named block of reusable code that performs a specific task.\nPython functions take inputs (called arguments) and produce outputs (called return values) by executing a defined operation. Like mathematical functions, You can pass data, known as parameters, into a function that can return data as a result.\nFor example, a built-in function print() outputs text to the console (or to a specified file):\nprint(\"BUDA 450\")\n\nBUDA 450\nFunctions help improve code clarity, reduce redundancy, and support modular design.",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PY/PY-Fn-Pack.html#function",
    "href": "PY/PY-Fn-Pack.html#function",
    "title": "5  Functions and Packages",
    "section": "",
    "text": "5.1.1 Calling a Function\nTo call a function, you use its name, followed by parentheses (). Inside the parentheses, you may include arguments as the inputs if needed, separated by commas , if there are multiple.\nFor example, the sum() function accepts arguments for a list of numbers and a value to specify a starting value for the summation:\n\nodd_numbers = [1,3,5]\nsum(odd_numbers, start=10)\n\n19\n\n\nAs shown in this example, Python functions can accept two main types of arguments:\nPositional arguments\n\nArguments are assigned based on their position in the function call.\nTheir order matters as the position of each argument play a different role.\n\n\n# print() with two positional arguments\nWhom = \"World\"\nprint(\"Hello\", Whom)\n\nHello World\n\n\nKeyword arguments\n\nArguments are explicitly assigned using name = value syntax, like value assignments to objects.\nThis improves clarity and allows reordering or omitting optional parameters:\n\n\n# print with additional keyword argument for `sep` to specify the separator '__space__'\nprint(\"Hello\", Whom, sep='__space__') \n\nHello__space__World\n\n\nKeyword arguments often have default values, making them optional. For instance, the print() function uses a default space ' ' for sep (see the official documentation), unless it is overwritten by the user.\n\n\n\n\n\n\nTip\n\n\n\nParentheses () are what we can consider for a clear distinction between functions and variables. Even when no argument is needed for a function’s operation, empty parentheses are used, referring to a function name. Even if a function takes no arguments, always use parentheses () to call it. This distinguishes functions from variables.\n\nprint()   # calling it for its operation (display none)\n\n\n\n\n\nprint     # refers to the function object itself\n\n&lt;function print(*args, sep=' ', end='\\n', file=None, flush=False)&gt;\n\n\n\n\n\n5.1.1.1 Built-in Functions\nPython includes a rich set of built-in functions that are always available without extra external modules. These functions handle many basic tasks, from displaying output to performing calculations or type conversions.\nYou can explore the full list of built-in functions in the Python’s official library documentation1.\nHere are some other built-in function examples:\n\n# Convert a number to a string\nstr(598)                          # Output: \"598\"\n\n# Get the length of a string\nlen(\"python\")                     # Output: 6\n\n# Round a number to a specified precision\nround(3.1415, 2)                  # Output: 3.14\n\n# Find the smallest of several values\nmin(1, 6/8, 4/3)                  # Output: 0.75\n\n0.75\n\n\n\n\n\n\n\n\nWarning\n\n\n\nLearning to program in Python partly means becoming familiar with its built-in functions (and many other functions in other modules related to your tasks). You don’t need to memorize them—just be aware they exist and know how to look them up when needed, like you use a dictionary for your writing.\n\n\n\n\n5.1.1.2 Methods\nA method is a function that belongs to an object. So, a method is called on an object and is specific to the object’s type. To apply a method, you can call the method’s name (and arguments), following the name of the target object to call the method on and a period (dot) . , like object_name.method_name(arguments).\nFor example, consider a string-type class2 object my_string_object and a method lower() that can be applied to the object to make all letters in the string lowercase.\n\nmy_message = \"Hello World\"   # a string object\nprint(my_message.lower())           # a lowercase version of the string object\n\nhello world\n\n\nFor other methods available for strings, see the official documentation\n\n\n\n\n\n\nNote\n\n\n\nDot notation . is also used to access attributes of an object.\nFor instance, if the_person is a Person object with a name attribute and a say_name() method, you would use:\n\nthe_person.name for the person’s name\nthe_person.say_name() to invoke the behavior method()\n\nThink of the dot . like a possessive:\n\nthe_person.name means “the person’s name”;\nthe_person.say_name() means “the person’s say_name() action”.\n\n\n\n\n\n\n\n\n\nCautionExercise\n\n\n\nA method replace(first, second) is for replacing the values that are equal to the first argument in the object with the values in the second argument. Using this method, make my_message return \"Hi World\".\n\n\nShow the code\nmy_message.replace(\"Hello\", \"Hi\")\n\n\n\n\n\n\n\n5.1.2 Writing Functions\nWhile Python offers many built-in and third-party functions, one of the most powerful features of the language is the ability to write your own functions. Functions allow you to encapsulate reusable logic, helping you organize code into meaningful, manageable chunks.\nAs Downey puts it:\n\n“Their primary purpose is to help us organize programs into chunks that match how we think about the problem.”\n\nWhenever you find yourself repeating the same logic, or want to improve the clarity of your program, writing a function is the right move. It reduces repetition, lowers the risk of errors, and makes your code more modular and easier to debug.\nA new function can be defined with def. Here’s a simple example:\n\n# Define a function that takes two arguments and returns a full name\ndef make_full_name(first_name, last_name):\n    out = first_name + \" \" + last_name\n    print(out)\n\n# Call the function with two arguments\nmake_full_name(\"Laura\", \"Brown\")\n\nLaura Brown\n\n\n\n5.1.2.1 Components in a Function\nWriting a function in Python involves several key components. Each part plays a role in defining, organizing, and executing reusable code logic.\ndef keyword\n\nDefine a new function with the def keyword that signals to Python that what follows is a function definition.\n\nFunction name\n\nGive your function a meaningful name that reflects its purpose.\n\nOne good practice is naming functions using verbs (as they do something), and naming variables using nouns (as they represent data).\n\nNaming rules for general objects/variables also apply to functions (e.g., lowercase letters, underscores for separation).\n\nParentheses () and Parameters\n\nAttach parentheses () after the function name.\nInside the parentheses, you may include:\n\nPositional arguments: Required values, passed in order.\nKeyword arguments: Optional values, assigned with a default.\n\n\n\ndef greet_name(name, greeting=\"Hello\"):\n    out = greeting + ', ' + name + '!'\n    print(out)\n\nprint(greet_name(\"Emma\") )                \nprint(greet_name(\"Jason\", greeting=\"Hi\")) \n\nHello, Emma!\nNone\nHi, Jason!\nNone\n\n\n\n# Functions can also take no arguments—just use empty parentheses:\ndef greet(name=\"Everyone\", greeting=\"Hello\"):\n    greet_out = greeting + ', ' + name + '!'\n    print(greet_out)\n\ngreet()\n\nHello, Everyone!\n\n\nColon :\n\nEnd the function header line with a colon :, indicating that the body (block) of the function follows.\n\nFunction Body (Indented Block)\n\nKeep indentation (typically 4 spaces) for all the body of the function.\nIt contains the operations to execute when the function is called, which can include:\n\nVariable declarations\nOther function calls\nControl flow (if, for, etc.)\n\n\n(Optional) return statement\n\nUse the return keyword to specify the output of your function.\nWhen return is executed, the function ends and passes the value back to where it was called.\nThe return statement can be omitted if a function does not need to return a value.\n\n\n# Functions can also take no arguments—just use empty parentheses:\ndef greet_return(name=\"Everyone\", greeting=\"Hello\"):\n    greet_out = greeting + ', ' + name + '!'\n    print(greet_out)\n    return name   # return only the name used\n\nres = greet_return()\nprint(\"The output is\", res)\n\nHello, Everyone!\nThe output is Everyone\n\n\n\n\n5.1.2.2 Doc Strings\nFunctions are a way of abstracting behavior by organizing your code into meaningful, reusable parts. While good function and argument names help (def calc_rectangle_area(width, height) is better than def my_func(a, b, c)), naming alone isn’t always enough. To make your functions easy to understand and use (by yourself or others), it’s important to document them clearly.\nA doc string (documentation string) is a special multi-line string placed right below a function definition. typically describing:\n\nWhat the function does (at a high level), as a short abstraction (1~2 sentences);\nWhat inputs (arguments) it expects;\nWhat it returns (if anything).\n\nDoc strings are enclosed in triple quotes \"\"\" and are not assigned to any variable.\n\ndef to_celsius(degrees_fahrenheit):\n    \"\"\"Converts Fahrenheit to Celsius and returns the result.\"\"\"\n    return (degrees_fahrenheit - 32) * (5/9)\n\nIf a function contains doc strings, you can access this documentation using the built-in help() function with the function’s name:\n\nhelp(to_celsius)\n\nHelp on function to_celsius in module __main__:\n\nto_celsius(degrees_fahrenheit)\n    Converts Fahrenheit to Celsius and returns the result.\n\n\n\n\n\n\n\n\n\nCautionExercise\n\n\n\nCheck the doc string of a built-in function by calling help() with the function you choose from the official website.\n\n\nShow the code\nhelp(round)",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PY/PY-Fn-Pack.html#modules-and-packages-libraries",
    "href": "PY/PY-Fn-Pack.html#modules-and-packages-libraries",
    "title": "5  Functions and Packages",
    "section": "5.2 Modules and Packages (Libraries)",
    "text": "5.2 Modules and Packages (Libraries)\nWhile Python includes many built-in functions, additional functionality can be organized into modules and packages\n\nModule: an object that serves as an organizational unit of Python code.\nPackage: a Python module which can contain submodules or recursively, subpackages. Technically, a package is a Python module with a path attribute.\n\nFor example, Numpy is a fundamental package for many numerical operations in Python, and the package files can be found from its Github Page. In there, each .py file (e.g., numpy/numpy folder) contains functions and variables.\nTo use a function of a package’s module, you must first import it using the import keyword. This keeps the interpreter efficient by loading only the necessary tools into memory.\nFor example, math is a module that contains various useful mathematical functions. To make them available, run the import keyword with a space and module name.\n\n# Import the built-in math module\nimport math\n\nThis only needs to be done once per script execution, and so is normally done at the top of the script (in a Jupyter notebook, you can include an importing code cell, or import the module at the top of the cell in which you first need it). Then, we run the code in the module:\n\n# Call functions or access constants using dot notation\nmath.sqrt(25)      # 5.0\nprint(math.pi)     # 3.141592653589793\n\n3.141592653589793\n\n\nAs you may notice, Dot notation works here just as it does for object methods. That is, math.sqrt() means “the sqrt() function in the math module.”\n\n\n\n\n\n\nTipPackage’s calling name in your code\n\n\n\nWhen importing a package, its calling name can be customized (or shortened):\n\nimport math as m\nm.sqrt(25)\n\n5.0\n\n\n\n\n\n5.2.0.1 Importing from a Custom Module\nWith a .py file, you can manage objects (functions and/or variables). Such custom modules can be imported in the same way.\nFor example, let’s consider a my_module.py file in the same directory as your script. Then, you can import the module using the filename without .py extension, as the module name:\n\nimport my_module\nmy_module.greet_name(\"Lucas\")\n\nHello, Lucas!\n\n\n\n\n5.2.1 Importing Specific Functions\nYou can import specific functions or variables from a module directly, rather than importing the entire module. So, in the code, you don’t need to attach the module name.\n\n# import two objects (a function and a variable)\nfrom math import sqrt, pi\n\nsqrt(36)           # 6.0\nprint(pi)          # 3.141592653589793\n\n3.141592653589793\n\n\nOr you can import everything in the module:\n\nfrom math import *\n\n\n\n\n\n\n\nWarning\n\n\n\nImporting all in large or unfamiliar modules is typically not recommended because the name of some function or variable may overlap with other objects. In such cases, the previous objects are overwritten, so that you lose the objects.\n\n\n\n\n5.2.2 Standard Library vs. External Packages\nModules like math, random, and datetime are part of Python’s Standard Library (see all modules from the index. However, Python’s real power comes from thousands of additional libraries (or packages) developed by the community, such as pandas, numpy, and matplotlib.\nTo use these external libraries, you must first install them. If you’re using Anaconda, you can install packages with the conda command. For example, a package numpy can be installed by executing the following in the terminal:\nconda install numpy\nAfter installing the package to use, you can import it in the same way.\n\nimport numpy as np\n\ndata_list = [[1,2,3],[4,5,6]]  # data\nnp.array(data_list)         # a numpy ndarray object\n\narray([[1, 2, 3],\n       [4, 5, 6]])",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PY/PY-Fn-Pack.html#reference",
    "href": "PY/PY-Fn-Pack.html#reference",
    "title": "5  Functions and Packages",
    "section": "5.3 Reference",
    "text": "5.3 Reference\n\nhttps://infx511.github.io/functions.html\nhttps://www.w3schools.com/python/python_functions.asp",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PY/PY-Fn-Pack.html#footnotes",
    "href": "PY/PY-Fn-Pack.html#footnotes",
    "title": "5  Functions and Packages",
    "section": "",
    "text": "This course and materials are based on Python 3.11 (stable).↩︎\nSee the details about how the function in a class object works from the following section Classes and Methods.↩︎",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Functions and Packages</span>"
    ]
  },
  {
    "objectID": "PY/PY-Class-Method.html",
    "href": "PY/PY-Class-Method.html",
    "title": "6  Classes and Methods",
    "section": "",
    "text": "6.1 Classes\nThis section introduces classes and methods in python.\nFor example, a built-in function print() outputs text to the console (or to a specified file):\nPython is a language for object-oriented programming (OOP), allowing you to structure your code using classes and objects for better organization and reusability. It has advantages over other programming approaches:\nIn Python, a class is a blueprint for a type of objects, as it defines what an object should look like. And, an object is created based on that class as it inherits all the variables and functions defined inside that class.\nAlmost everything in Python is an object, with its properties and methods. You can create a class to store data attributes (also called the class properties) and/or methods, and use the class to handle objects of a type in a consistent and systematic way.\nFor example, you can define a class named MyCourse with an attribute named program, using class keyword:\n# Define a class\nclass MyCourse:\n    # data attribute\n    program = 'BUDA'          # class variable shared by all instances\nNow, you can create an object of the new class:\n# Create an object\nstudent_1 = MyCourse()\nprint(\"The program of student_1:\", student_1.program)\n\nThe program of student_1: BUDA\n# Add/modify an attribute and the value in the object \nstudent_1.course = \"BUDA 450\"    # a new attribute\nprint(\"The course code of student_1:\", student_1.course)\n\nThe course code of student_1: BUDA 450\nNow, you can create another object of the same class, which has the same attribute program:\n# Create another object\nstudent_2 = MyCourse()\nprint(\"The program of student_2:\", student_2.program)\n\nThe program of student_2: BUDA\nHowever, although their classes are the same, they are treated independently. So, this object student_2 doesn’t have the attribute course as it was added only to student_1. The following example returns an error message.\nprint(\"The course code of student_2:\", student_2.course)",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classes and Methods</span>"
    ]
  },
  {
    "objectID": "PY/PY-Class-Method.html#classes",
    "href": "PY/PY-Class-Method.html#classes",
    "title": "6  Classes and Methods",
    "section": "",
    "text": "Provides a clear structure to programs\nMakes code easier to maintain, reuse, and debug\nHelps keep your code DRY (Don’t Repeat Yourself)\nAllows you to build reusable applications with less code\n\n\n\n\n\nClass\nObjects\n\n\n\n\nFruit\nApple, Banana, Mango\n\n\nCar\nVolvo, Audi, Toyota\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.1.1 Method\nA method is a function that “belongs to” an object. So, a method is called on an object and is specific to the object’s type. To apply a method, you can call the method’s name (and arguments), following the name of the target object to call the method on and a period (dot) . , like object_name.method_name(arguments).\n\n# Define a class with method\nclass MyCourse:\n    # data attribute \n    program = 'BUDA'          # class variable shared by all instances\n    \n    # method\n    def add_course(self, course_code):\n        self.course = self.program + \" \" + course_code\n\nHere, self indicates the class object itself. That is, self.program call the program attribute of the object that is created through this class, locally within this class’ code block.\nAs a result, the function can utilize internally defined attribute that will be identically created in every MyCourse object.\nFor example, you can create two objects of MyCourse class, and use the same method with different arguments:\n\nstudent_3 = MyCourse()\nstudent_3.add_course(\"450\")\nprint(student_3.course)\n\nBUDA 450\n\n\n\nstudent_4 = MyCourse()\nstudent_4.add_course(\"455\")\nprint(student_4.course)\n\nBUDA 455\n\n\n\n6.1.1.1 The __init__() Method\nAlmost all classes have a built-in method called __init__(), which makes the classes much useful by having an initial setup for each object. The __init__() method is always executed when the class is being initiated — when an object of the class is created.\nFor example, the __init__() method can be used to assign initial values to object properties, or other operations that are necessary to do when the object is being created:\n\n# Define a class with __init__ method\nclass MyCourse_general:\n    def __init__(self, program):\n        self.program = program        # instance variable unique to each instance\n    \n    def add_course(self, course_code):\n        self.course = self.program + \" \" + course_code\n\nFor example, the MyCourse_general requires an argument for program attribute to initiate (i.e., create) an object. The following objects are created with different program names, while using the same method.\n\n# without the initial value, the object cannot be created\nstudent_5 = MyCourse_general(\"BUDA\")\nstudent_5.add_course(\"450\")\nprint(student_5.course)\n\nBUDA 450\n\n\n\nstudent_6 = MyCourse_general(\"MIST\")\nstudent_6.add_course(\"450\")\nprint(student_6.course)\n\nMIST 450",
    "crumbs": [
      "Python Basics",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Classes and Methods</span>"
    ]
  },
  {
    "objectID": "PD/PD-KNN.html",
    "href": "PD/PD-KNN.html",
    "title": "12  k-Nearest Neighbors",
    "section": "",
    "text": "12.1 What is kNN?\nThis section introduces k-nearest neighbors (kNN), a distance-based algorithm used in data mining tasks such as classification and regression.\nkNN is a simple but powerful algorithm:\nFor classification of new samples, kNN is based on the class labels of the k nearest neighbors. - A sample is assigned to the majority class among its k nearest neighbors.\n- If k=1, the sample takes the class of its single nearest neighbor.\nAlso, for regression (known as kNN regression or nearest neighbor smoothing), kNN is based on the target values of the k nearest neighbors. - The prediction is the average of the values of the k nearest neighbors.",
    "crumbs": [
      "Predictive Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "PD/PD-KNN.html#what-is-knn",
    "href": "PD/PD-KNN.html#what-is-knn",
    "title": "12  k-Nearest Neighbors",
    "section": "",
    "text": "As a non-parametric method that makes no assumptions about the data distribution.\nAs a lazy learning algorithm because it does not build a model during training.\n\nInstead, prediction happens (the algorithm finds its k nearest neighbors from the training data) when a test sample is given.\n\n\n\n\n\n12.1.1 The Core kNN Algorithm\nPrediction in kNN involves:\n\nCalculating the distance from the query point to all training examples.\n\nSorting distances.\n\nSelecting the k nearest neighbors.\n\nMaking a prediction1, using majority vote (classification) or averaging (regression).\n\n\n\n12.1.2 Distance Metrics\nTo identify nearest neighbors, defining “closeness” of a sample to another requires a distance measure such as Euclidean distance , Manhattan distance (L1 norm), Minkowski distance, Hamming distance and Correlation-based measures ( sometimes used for specialized data, such as gene expression or time-series).\nThe choice of distance metric can significantly affect the accuracy of the kNN algorithm.\n\n\n\n\n\n\nNoteThe Importance of Feature Scaling\n\n\n\nSince kNN is based on distance calculations, its performance can be distorted if features are measured on different scales or in different units.\n\nStandardization (Z-score normalization): rescales features so they have mean 0 and standard deviation 1.\n\nMin–max scaling: rescales features to a fixed range, typically [0, 1].\n\nScaling ensures that all features contribute equally to distance calculations, preventing variables with larger numeric ranges from dominating the results.",
    "crumbs": [
      "Predictive Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "PD/PD-KNN.html#knn-for-classification",
    "href": "PD/PD-KNN.html#knn-for-classification",
    "title": "12  k-Nearest Neighbors",
    "section": "12.2 kNN for classification",
    "text": "12.2 kNN for classification\n\n12.2.1 Packages\nLet’s import general packages first.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n12.2.2 Data\nWe can use sklearn.datasets.make_blobs() to generate a synthetic dataset with well-separated clusters. This is useful for demonstrating how k-NN works on simple 2D data.\nLet’s first create a simple data set of the input features X_tr and the class labels Y_tr, which will be used for the training:\n\nfrom sklearn.datasets import make_blobs\n\n# Define the centers of the clusters (each corresponds to a class)\ncenters = [[ 1, 2 ], [ 7, 10 ]]            # the center coordinates of each data class\n\n# Generate training data\nX_tr, y_tr = make_blobs(\n    n_samples=10,               # number of data samples to generate\n    centers=np.array(centers),  # cluster centers\n    random_state=123            # fixed seed to control the \"random\" creation for reproducibility\n)\n\n# Convert to a DataFrame for easier handling\ndf_tr = pd.DataFrame(X_tr, columns=['X1','X2'])\ndf_tr['Y'] = y_tr\ndf_tr\n\n\n\n\n\n\n\n\nX1\nX2\nY\n\n\n\n\n0\n9.205930\n12.186786\n1\n\n\n1\n-0.085631\n2.997345\n0\n\n\n2\n0.421400\n3.651437\n0\n\n\n3\n6.321114\n9.905291\n1\n\n\n4\n1.282978\n0.493705\n0\n\n\n5\n8.491390\n9.361098\n1\n\n\n6\n6.556018\n9.565649\n1\n\n\n7\n2.265936\n1.133260\n0\n\n\n8\n-1.426679\n1.571087\n0\n\n\n9\n8.004054\n10.386186\n1\n\n\n\n\n\n\n\nWe can also generate a separate set of samples to use as new (test) data with the input features X_new and the class labels Y_new. These samples will be classified later using the kNN algorithm trained on the earlier dataset.\n\n# Generate new data (same cluster centers as training set)\nX_new, y_new = make_blobs(\n    n_samples=5,                # number of new data samples\n    centers=np.array(centers),  # same cluster centers as training\n    random_state=456            # different seed for reproducibility\n)\n\n# Convert to DataFrame\ndf_new = pd.DataFrame(X_new, columns=['X1', 'X2'])\ndf_new['Y'] = y_new\ndf_new\n\n\n\n\n\n\n\n\nX1\nX2\nY\n\n\n\n\n0\n2.350509\n3.629589\n0\n\n\n1\n0.331871\n1.501790\n0\n\n\n2\n6.654189\n9.684769\n1\n\n\n3\n1.618576\n2.568692\n0\n\n\n4\n7.301966\n10.449483\n1\n\n\n\n\n\n\n\n\n12.2.2.1 Visualizing the Training and New Data\nBefore applying kNN, it is helpful to visualize the datasets to see how the training and new samples are distributed in feature space.\n\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(5, 4))\n\n# Training samples (circles), color by class label\nscatter_tr = ax.scatter(\n    df_tr[df_tr['Y']==0]['X1'], df_tr[df_tr['Y']==0]['X2'],\n    s=70, marker='^', label='Training, Y=0'\n)\nscatter_tr = ax.scatter(\n    df_tr[df_tr['Y']==1]['X1'], df_tr[df_tr['Y']==1]['X2'],\n    s=70, marker='v', label='Training, Y=1'\n)\n\n# New samples (X markers), color by class label\nscatter_new = ax.scatter(\n    df_new['X1'], df_new['X2'],\n    s=120, marker='o', label='New'\n)\n\n# Labels and title\nax.set_title(\"Training samples and new samples (X)\")\nax.set_xlabel(\"X1\")\nax.set_ylabel(\"X2\")\nax.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n12.2.3 Implementation with Scikit-learn (sklearn)\nInstead of manually coding kNN, you can use the KNeighborsClassifier available in scikit-learn.\nThe neighbors module in sklearn provides efficient implementations of nearest-neighbor algorithms and supports both NumPy arrays and SciPy sparse matrices as input.\n\n12.2.3.1 Step 1: Instantiate the KNeighborsClassifier\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Instantiate with chosen parameters\nknn = KNeighborsClassifier(\n    n_neighbors=5,       # number of neighbors\n    metric='minkowski',  # distance metric\n    p=2                  # power parameter (p=2 → Euclidean, p=1 → Manhattan)\n)\n\nThis example consider some key parameters:\n\nn_neighbors (int, default=5): The number of neighbors to consider for the classification vote.\nmetric (str or callable, default=‘minkowski’): The distance metric used. Default ‘minkowski’ with p=2 is Euclidean.\np (float, default=2): The power parameter for the Minkowski metric (1 for Manhattan, 2 for Euclidean).\n\nIf parameters are not explicitly set, the defaults are used (e.g., knn = KNeighborsClassifier()).\n\n\n12.2.3.2 Step 2: Fit the Classifier to Training Data\n\n# Train kNN classifier\nknn.fit(X_tr, y_tr)\n\nKNeighborsClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KNeighborsClassifier?Documentation for KNeighborsClassifieriFittedKNeighborsClassifier() \n\n\n\n\n12.2.3.3 Step 3: Make Predictions on New Data\n\n# Predict labels for new data samples\npredicted_labels = knn.predict(X_new)\n\nprint(\"Predictions from the classifier:\", predicted_labels)\nprint(\"True labels:                    \", y_new)\n\nPredictions from the classifier: [0 0 1 0 1]\nTrue labels:                     [0 0 1 0 1]\n\n\nC:\\Users\\saaan\\anaconda3\\envs\\buda_py311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning:\n\nCould not find the number of physical cores for the following reason:\n[WinError 2] The system cannot find the file specified\nReturning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n\n  File \"C:\\Users\\saaan\\anaconda3\\envs\\buda_py311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n    cpu_info = subprocess.run(\n               ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\saaan\\anaconda3\\envs\\buda_py311\\Lib\\subprocess.py\", line 548, in run\n    with Popen(*popenargs, **kwargs) as process:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\saaan\\anaconda3\\envs\\buda_py311\\Lib\\subprocess.py\", line 1026, in __init__\n    self._execute_child(args, executable, preexec_fn, close_fds,\n  File \"C:\\Users\\saaan\\anaconda3\\envs\\buda_py311\\Lib\\subprocess.py\", line 1538, in _execute_child\n    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n\n\n\n\n12.2.4 Manual Procedure for Classification with kNN\nTo better understand how kNN works, let’s go through manual implementation of the classification steps with kNN.\n\n12.2.4.1 Step 1: Calculate Distances\nFirst, compute the distances between each training point in X_tr and each new point in X_new.\n\nfrom sklearn.metrics import pairwise_distances\n\n# Compute Euclidean distance between all training samples and the new point\ndistances = pairwise_distances(X_tr, X_new)\n\nprint( 'Matrix shape', distances.shape, '\\n')\nprint( distances.round(3) )\n\nMatrix shape (10, 5) \n\n[[10.965 13.889  3.574 12.251  2.577]\n [ 2.517  1.553  9.495  1.757 10.493]\n [ 1.929  2.152  8.675  1.614  9.672]\n [ 7.426 10.319  0.399  8.714  1.122]\n [ 3.313  1.386 10.645  2.102 11.634]\n [ 8.4   11.329  1.865  9.663  1.612]\n [ 7.275 10.187  0.154  8.564  1.157]\n [ 2.498  1.969  9.612  1.575 10.59 ]\n [ 4.302  1.76  11.451  3.204 12.451]\n [ 8.81  11.739  1.521 10.094  0.705]]\n\n\nHere, the result is a matrix of shape (len(X_tr), len(X_new)), and its element at row i, column j is the distance between training sample i and new sample j.\n\n\n12.2.4.2 Step 2: Identify Nearest Neighbors\nFor simplicity, let’s focus on the classification of the 4th new point in X_new (i.e., j = 3). We extract the column of distances corresponding to that new point:\n\nj = 3  # index of the 4th new point\ndistances_j = distances[:, j]\ndistances_j\n\narray([12.2505377 ,  1.75728856,  1.61417649,  8.7143299 ,  2.10195063,\n        9.66293669,  8.56362865,  1.57465629,  3.20449589, 10.09393606])\n\n\nThen, rank (sort) them based on the resulted distances, by using np.argsort() that returns the indexes:\n\n# Sort indices by distance (ascending order)\nindices_sorted_by_distance = np.argsort(distances_j)\nindices_sorted_by_distance\n\narray([7, 2, 1, 4, 8, 6, 3, 5, 9, 0])\n\n\nGiven a predetermined neighbor size k (as a user parameter), define a set for the neighbors of the jth point in X_new by taking the top (i.e., closest to the jth example) k samples in X_tr:\n\n# Get indices of the k closest samples\nk = 3\nneighbor_indices = indices_sorted_by_distance[:k]\nneighbor_indices\n\narray([7, 2, 1])\n\n\n\n\n12.2.4.3 Step 3: Retrieve Neighbor Labels\nRetrieve the class labels for the nearest neighbors.\n\nneighbor_labels = y_tr[neighbor_indices]\nneighbor_labels\n\narray([0, 0, 0])\n\n\n\n\n12.2.4.4 Step 4: Plurality vote\nFinally, assign the class label of the new point by majority vote (mode) of its neighbors’ labels:\n\nfrom collections import Counter\n\n# Get the most frequent label (mode)\nmost_common = Counter(neighbor_labels).most_common(1)[0][0]\nmost_common\n\nnp.int64(0)\n\n\n\n\n\n\n\n\nNoteVoronoi Diagram\n\n\n\nWhen (k = 1), the decision boundary of the kNN classifier corresponds to the borders of a Voronoi diagram. Each region in the diagram contains all samples that are closest to a particular training sample.\nThe visualization below shows how the training data divides the input space into such regions.\n\nimport matplotlib.pyplot as plt\nfrom scipy.spatial import Voronoi, voronoi_plot_2d\n\n# Create Voronoi diagram from training data\nvor = Voronoi(X_tr)\n\n# Plot the Voronoi diagram\nfig = plt.figure(figsize=(6, 6))\nvoronoi_plot_2d(\n    vor, \n    show_vertices=False, \n    line_colors='gray', \n    line_width=1, \n    line_alpha=0.6, \n    point_size=10\n)\n\n# Overlay training samples with class-based colors\ncolors = ['blue', 'green', 'purple']\nfor i, point in enumerate(X_tr):\n    plt.scatter(\n        point[0], point[1], \n        color=colors[y_tr[i]], \n        s=70, \n        label=f'Class {y_tr[i]}' if f'Class {y_tr[i]}' not in plt.gca().get_legend_handles_labels()[1] else \"\"\n    )\n\n# Plot new data samples\nplt.scatter(\n    X_new[:, 0], X_new[:, 1], \n    c='red', marker='*', s=200, \n    label='New point'\n)\n\n# Labels and formatting\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.title('Voronoi Diagram (k=1 Decision Boundaries)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n&lt;Figure size 576x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\nThis plot visually demonstrates how kNN with k=1 partitions the input space:\n\nEach cell (region) is assigned to the class of the nearest training point.\nNew data samples fall into one of these cells and are classified accordingly.",
    "crumbs": [
      "Predictive Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "PD/PD-KNN.html#knn-for-regression",
    "href": "PD/PD-KNN.html#knn-for-regression",
    "title": "12  k-Nearest Neighbors",
    "section": "12.3 kNN for Regression",
    "text": "12.3 kNN for Regression\nWhile kNN is often introduced as a classification algorithm, it can also be applied to regression tasks. In this case, instead of predicting a class label, the algorithm predicts a numerical value for a new data point.\n\nStep 1-4. Select neighbors: Identify the k closest training samples to the query point, using a distance metric (e.g., Euclidean).\n\nStep 5. Aggregate values: Take the average (or sometimes weighted average) of the target values of these neighbors.\n\nStep 6. Prediction Assign this aggregated value as the prediction for the new point.\n\nFor a new point \\(\\mathbf{x}_{new}\\), the prediction is:\n\n\\[\n  \\hat{y}(\\mathbf{x}_{new}) = \\frac{1}{k} \\sum_{i \\in \\mathcal{N}_k(\\mathbf{x}_{new})} y_i\n  \\]\nwhere:\n\n\\(\\mathcal{N}_k(\\mathbf{x})\\) is the set of the k nearest neighbors of \\(\\mathbf{x}\\).\n\n\\(y_i\\) is the target value of neighbor \\(i\\).\n\n\n\n12.3.1 Example with Scikit-learn\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.neighbors import KNeighborsRegressor\n\n# Generate a simple regression dataset for training\nX_train, y_train = make_regression(n_samples=40, n_features=1, noise=2, random_state=1)\nX_test, y_test = make_regression(n_samples=20, n_features=1, noise=2, random_state=1)\n\n# Fit k-NN regression model\nknn_reg = KNeighborsRegressor(n_neighbors=3, weights='distance')\nknn_reg.fit(X_train, y_train)\n\n# Predict on a grid of values\nX_test = np.linspace(X_train.min()-1, X_train.max()+1, 100).reshape(-1, 1)\ny_pred = knn_reg.predict(X_test)\n\n# Plot\nfig, ax = plt.subplots()\nax.scatter(X_train, y_train, c='blue', label='Training data')\nax.plot(X_test, y_pred, c='red', label='k-NN regression (k=3)')\nax.set_title(\"k-NN Regression\")\nax.set_xlabel(\"X\")\nax.set_ylabel(\"y\")\nax.legend()\nplt.show()",
    "crumbs": [
      "Predictive Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "PD/PD-KNN.html#readingreference",
    "href": "PD/PD-KNN.html#readingreference",
    "title": "12  k-Nearest Neighbors",
    "section": "12.4 Reading/Reference",
    "text": "12.4 Reading/Reference\n\nChapter 12.1, 12.2 in Business Analytics: communicating with Numbers, 2nd ed. (Jaggia et al., 2023)\nChapter 4.3 in Introduction to Data Mining, 2nd ed. (Tan et al., 2019)",
    "crumbs": [
      "Predictive Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  },
  {
    "objectID": "PD/PD-KNN.html#footnotes",
    "href": "PD/PD-KNN.html#footnotes",
    "title": "12  k-Nearest Neighbors",
    "section": "",
    "text": "Weights can be assigned to neighbors so that closer neighbors contribute more strongly, often using inverse distance weighting.↩︎",
    "crumbs": [
      "Predictive Modeling",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>k-Nearest Neighbors</span>"
    ]
  }
]